"""Wrapper around Aviary"""
from typing import Any, Dict, List, Mapping, Optional

import os
import requests
from pydantic import Extra, Field, root_validator

from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM
from langchain.llms.utils import enforce_stop_tokens
from langchain.utils import get_from_dict_or_env

import aviary.api.sdk as aviary_sdk

TIMEOUT = 60


class Aviary(LLM):
    """Allow you to use an Aviary.

    Aviary is a backend for hosted models. You can
    find out more about aviary at
    http://github.com/ray-project/aviary

    The only dependency is the aviary sdk which can be installed via 
    `pip install git+http://github.com/ray-project/aviary.git`

    To get a list of the models supported on an
    aviary, follow the instructions on the web site to
    install the aviary CLI and then use:
    `aviary models`

    AVIARY_URL and AVIARY_TOKEN environement variables must be set.

    Example:
        .. code-block:: python

            from langchain.llms import Aviary
            os.environ["AVIARY_URL"] = "<URL>"
            os.environ["AVIARY_TOKEN"] = "<TOKEN>"
            light = Aviary(model='amazon/LightGPT')
            output = light('How do you make fried rice?')
    """

    model_name: str = "amazon/LightGPT"
    aviary_url: Optional[str] = None
    aviary_token: Optional[str] = None
    # If True the prompt template for the model will be ignored. 
    use_prompt_format: bool = True
    # API version to use for Aviary
    version: Optional[str] = None

    class Config:
        """Configuration for this pydantic object."""

        extra = Extra.forbid

    @root_validator(pre=True)
    def validate_environment(cls, values: Dict) -> Dict:
        """Validate that api key and python package exists in environment."""
        aviary_url = get_from_dict_or_env(values, "aviary_url", "AVIARY_URL")
        aviary_token = get_from_dict_or_env(values, "aviary_token", "AVIARY_TOKEN")

        # Set env viarables for aviary sdk
        os.environ["AVIARY_URL"] = aviary_url
        os.environ["AVIARY_TOKEN"] = aviary_token

        try:
            aviary_models = aviary_sdk.models()
        except requests.exceptions.RequestException as e:
            raise ValueError(e)

        if values["model_name"] not in aviary_models:
            raise ValueError(
                f"{aviary_url} does not support model {values['model']}."
            )
        
        return values

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """Get the identifying parameters."""
        return {
            "model_name": self.model_name,
            "aviary_url": self.aviary_url,
        }

    @property
    def _llm_type(self) -> str:
        """Return type of llm."""
        return f"aviary-{self.model_name.replace('/', '-')}"

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """Call out to Aviary
        Args:
            prompt: The prompt to pass into the model.

        Returns:
            The string generated by the model.

        Example:
            .. code-block:: python

                response = aviary("Tell me a joke.")
        """
        kwargs = {"use_prompt_format": self.use_prompt_format}
        if self.version:
            kwargs["version"] = self.version

        output = aviary_sdk.completions(
            model=self.model_name,
            prompt=prompt,
            **kwargs,
        )
        
        text = output["generated_text"]
        if stop:
            text = enforce_stop_tokens(text, stop)

        return text
