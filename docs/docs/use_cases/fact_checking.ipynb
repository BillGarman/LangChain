{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce748d5-9abf-4198-9390-4184811de3b9",
   "metadata": {},
   "source": [
    "# Fact checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab76dc1-b6b5-4c67-a872-8ba7a39997cc",
   "metadata": {},
   "source": [
    "## Use case\n",
    "\n",
    "`Fact-checking` is a technique to address `hallucination`. It verifies claims made by LLMs. Usually, it verifies claims against evidence from external sources.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Usually, fact-checking has these steps:\n",
    "- **Claim detection**, called also the **Fact detection**, identifies claims or facts in the LLM prime answer\n",
    "- **Claim verification** evaluates each claim and decides to support or reject the claim\n",
    "- **Final decision** based on all claim verification results decides on the result of the whole answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381696d-f4eb-45b8-8c71-604fef9d62a0",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26b003-d08e-4853-93c7-df28f038ac59",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0855aad6-86c7-488e-a1d5-f98003b3f8ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T22:30:45.505293Z",
     "iopub.status.busy": "2024-04-17T22:30:45.504765Z",
     "iopub.status.idle": "2024-04-17T22:30:59.648973Z",
     "shell.execute_reply": "2024-04-17T22:30:59.648170Z",
     "shell.execute_reply.started": "2024-04-17T22:30:45.505262Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY =  ········\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain langchain-openai\n",
    "\n",
    "## Set env var OPENAI_API_KEY or load from a .env file:\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI_API_KEY = \")\n",
    "\n",
    "# import dotenv\n",
    "# dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65df5eae-8fdd-4a76-be57-0974e96031cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T22:39:43.957406Z",
     "iopub.status.busy": "2024-04-17T22:39:43.957236Z",
     "iopub.status.idle": "2024-04-17T22:39:47.725133Z",
     "shell.execute_reply": "2024-04-17T22:39:47.724349Z",
     "shell.execute_reply.started": "2024-04-17T22:39:43.957395Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_API_KEY =  ········\n"
     ]
    }
   ],
   "source": [
    "## setup LangSmith tracing:\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass(\"LANGCHAIN_API_KEY = \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8286751c-72a7-43e5-8b70-09c92f01e08d",
   "metadata": {},
   "source": [
    "Now, we are ready to initiate the chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c7fb9e-d68b-4719-a2ac-d889060580cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T22:54:56.667171Z",
     "iopub.status.busy": "2024-04-17T22:54:56.666866Z",
     "iopub.status.idle": "2024-04-17T22:54:56.736936Z",
     "shell.execute_reply": "2024-04-17T22:54:56.736577Z",
     "shell.execute_reply.started": "2024-04-17T22:54:56.667160Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMCheckerChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7)\n",
    "checker_chain = LLMCheckerChain.from_llm(llm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e7604-29e9-4563-91cc-7bc4f518abe2",
   "metadata": {},
   "source": [
    "### Verify question\n",
    "\n",
    "We can run verification together with questioning LLM with no changes in the original prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d8c6cc-2e60-4b74-843c-0744c0900eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T22:39:53.490402Z",
     "iopub.status.busy": "2024-04-17T22:39:53.489055Z",
     "iopub.status.idle": "2024-04-17T22:39:58.596943Z",
     "shell.execute_reply": "2024-04-17T22:39:58.595380Z",
     "shell.execute_reply.started": "2024-04-17T22:39:53.490356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What type of mammal lays the biggest eggs?',\n",
       " 'result': 'Monotremes are the type of mammal that lays the biggest eggs.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What type of mammal lays the biggest eggs?\"\n",
    "checker_chain.invoke(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9608aa0-8eab-4fa8-ad14-c6b343e95e91",
   "metadata": {},
   "source": [
    "Then we can look at the `LangSmith` trace to see what is happening under the hood:\n",
    "\n",
    "Summary: \n",
    "Here we see the result of the chain. There were 4 calls to LLM. Number of calls for the chain is fixed.\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_1.1.png)\n",
    "\n",
    "1. It is the preliminary step. LLM receives the original prompt and generates an answer.\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_1.2.png)\n",
    "\n",
    "2. It is the `Claim detection` step. The chain adds this text to the result of the first call: `Make a bullet point list of the assumptions you made when producing the above statement.` The result is the list of the claims/facts.\n",
    "   \n",
    "![image.png](../../static/img/fakt_checking.example_1.3.png)\n",
    "\n",
    "3. It is the `Claim verification` step. Now the chain adds this text to the result of the second call: `For each assertion, determine whether it is true or false. If it is false, explain why.` LLM verifies each claim and decides if it is correct or not by adding True or False to each claim.\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_1.4.png)\n",
    "\n",
    "4. It is the `Final decision` step. The chain adds this text to the result of the third call: `Question: In light of the above assertions and checks, how would you answer the question '<Original prompt>'?` LLM produces the final result text.\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_1.5.png)\n",
    "\n",
    "The final result is a little bit different from the first call result. The first result provides us with two mammals but the final result provides just a single mammal. \n",
    "This difference could be important in your specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49034a8b-4918-4714-8b23-e9c620588621",
   "metadata": {},
   "source": [
    "### Explicit verification\n",
    "\n",
    "We can explicitly ask for verification in the existing text by, for example, `Is it correct?` question.\n",
    "\n",
    "The text in this example holds incorrect factual information. The chain finds that the result is wrong and provides the correct fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e67f211-1574-47c1-9a87-922b3b649324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T22:45:57.471067Z",
     "iopub.status.busy": "2024-04-17T22:45:57.470527Z",
     "iopub.status.idle": "2024-04-17T22:46:01.789690Z",
     "shell.execute_reply": "2024-04-17T22:46:01.788464Z",
     "shell.execute_reply.started": "2024-04-17T22:45:57.471023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Vancouver was established in 1786. Is it correct?',\n",
       " 'result': 'No, it is not correct. Vancouver was not established in 1786, it was established in 1886.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Vancouver was established in 1786. Is it correct?\"\n",
    "checker_chain.invoke(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a90b7125-8f05-4b03-b2b0-4b1ae5e7fdf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T23:37:38.415011Z",
     "iopub.status.busy": "2024-04-17T23:37:38.414606Z",
     "iopub.status.idle": "2024-04-17T23:37:38.423146Z",
     "shell.execute_reply": "2024-04-17T23:37:38.421899Z",
     "shell.execute_reply.started": "2024-04-17T23:37:38.414980Z"
    }
   },
   "source": [
    "Here we provide only the input and output of each call:\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_2.1.png)\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_2.2.png)\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_2.3.png)\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_2.4.png)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc74519-be05-4fea-8684-a354802ce6ae",
   "metadata": {},
   "source": [
    "### Fact checking\n",
    "\n",
    "We can just run any verification on any text with presumable facts inside.\n",
    "\n",
    "This example is similar to the previous one but does not ask explicitly to verify the text. \n",
    "Still, the chain successfully finds the wrong fact and provides us with the correct information.\n",
    "\n",
    "Note, that the result text is not the same as in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193a910b-228a-41e4-8aef-0a726afa8663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T22:45:04.283473Z",
     "iopub.status.busy": "2024-04-17T22:45:04.282977Z",
     "iopub.status.idle": "2024-04-17T22:45:10.288043Z",
     "shell.execute_reply": "2024-04-17T22:45:10.287164Z",
     "shell.execute_reply.started": "2024-04-17T22:45:04.283436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Vancouver was established in 1786.',\n",
       " 'result': 'False. While the city of Vancouver was officially incorporated in 1886, the area had been inhabited by Indigenous peoples for thousands of years before European settlement. The statement that Vancouver was established in 1786 is not accurate.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Vancouver was established in 1786.\"\n",
    "checker_chain.invoke(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f021fc5c-8ce2-4e1a-b27d-330488e45b63",
   "metadata": {},
   "source": [
    "Here we provide only the input and output of each call:\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_3.1.png)\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_3.2.png)\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_3.3.png)\n",
    "\n",
    "![image.png](../../static/img/fakt_checking.example_3.4.png)\n",
    " \n",
    "\n",
    "**Note:**\n",
    "\n",
    "- the first result immediately points out that the fact in the prompt was not correct.\n",
    "- the final result is not the same as the first result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a2d62-a864-4f4b-ac76-090ada25d27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
