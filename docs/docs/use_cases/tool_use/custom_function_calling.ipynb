{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b94240",
   "metadata": {},
   "source": [
    "# Custom function-calling chain\n",
    "\n",
    "`langchain` comes with built-in `create_openai_tools_chain` and `create_openai_functions_chain` constructors for building tool chains that make use of function-calling APIs (see [Quickstart](/docs/use_cases/tool_use/quickstart) for an example of how to use these). To better understand what's happening under the hood of these, let's built a custom function-calling chain from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e0664-2e34-477d-a2f2-09e92072839d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll need to install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30311705-ddf2-49ab-8b36-5d816bd930a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f44ad-709c-443b-bf01-2f101678bbe7",
   "metadata": {},
   "source": [
    "And set these environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c908e11-0ca4-4deb-9d66-7276e2379911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# If you'd like to use LangSmith, uncomment the below\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946881",
   "metadata": {},
   "source": [
    "## Create a tool\n",
    "\n",
    "First, we need to create a tool to call. For this example, we will create a custom tool from a function. For more information on all details related to creating custom tools, please see [this guide](/docs/modules/agents/tools/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90187d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7009e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "multiply(first_int: int, second_int: int) -> int - Multiply two integers together.\n",
      "{'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be77e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"first_int\": 4, \"second_int\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4530b0-090a-4514-b94d-18ac6395afc0",
   "metadata": {},
   "source": [
    "## Create and bind OpenAI functions\n",
    "\n",
    "For simplicity we'll use OpenAI's function calling API instead of the newer tools calling/parallel function calling API.\n",
    "\n",
    "First we need to define our OpenAI functions. `langchain` comes with utilities for converting any `langchain` Tool into an OpenAI function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe4982ad-1e93-4234-adef-3558ba6b0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "functions = [format_tool_to_openai_function(multiply)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f859fcf-c2b1-4099-b1f9-792586cc3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'description': 'multiply(first_int: int, second_int: int) -> int - Multiply two integers together.',\n",
       "  'parameters': {'title': 'multiplySchemaSchema',\n",
       "   'type': 'object',\n",
       "   'properties': {'first_int': {'title': 'First Int', 'type': 'integer'},\n",
       "    'second_int': {'title': 'Second Int', 'type': 'integer'}},\n",
       "   'required': ['first_int', 'second_int']}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe7427-1b2c-40b0-80cd-e4a1a4061505",
   "metadata": {},
   "source": [
    "Now we'll bind our functions to our model, meaning the functions will be passed in as part of the payload to the model each time it is invoked. In this case we'll also bind `function_call`, which will force the OpenAI model to always return inputs for the `multiply` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "960a6f36-c762-4a80-9abf-50bdbdf039c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "model_with_functions = model.bind(\n",
    "    functions=functions, function_call={\"name\": \"multiply\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f479264-85e2-4833-a264-759176be653f",
   "metadata": {},
   "source": [
    "## Chaining with output parser\n",
    "\n",
    "We'll chain our model together with a `JsonOutputFunctionsParser`, which returns just the `functions` part of the model output (which is in JSON) as a dictionary. We'll specify `args_only=True` in this case so that only the function arguments and not the function name is returned, since we know which function the arguments are for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e76fb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_int': 13, 'second_int': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=True)\n",
    "chain.invoke(\"what is thirteen times 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9136cd9-4f4d-4b65-9e9a-4146119349fa",
   "metadata": {},
   "source": [
    "If we specified `args_only=False`, our chain output would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7cdde16-3aec-4276-9aa2-7ff6e963c551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': {'first_int': 13, 'second_int': 4}, 'name': 'multiply'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model_with_functions | JsonOutputFunctionsParser(args_only=False)).invoke(\n",
    "    \"what is thirteen times 4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33f07c-65bc-4780-8e4b-f6cf0bc8065e",
   "metadata": {},
   "source": [
    "## Adding prompt\n",
    "\n",
    "Suppose we wanted to add some additional instructions to the model on each call. We can do this by including a prompt at the beginning of our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60999a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Always call function `multiply` with the smaller number passed in first.\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "509e1145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_int': 4, 'second_int': 13}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73d308",
   "metadata": {},
   "source": [
    "## Invoking tool\n",
    "\n",
    "And if we want our chain to actually call the tool once the model had determined the tool inputs, we can easily add that to our chain as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73681dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_tool = chain | multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7fe6a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_tool.invoke({\"input\": \"what is thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60b2cb-6ce0-48fc-8d18-d2337161a53d",
   "metadata": {},
   "source": [
    "### Multiple tools\n",
    "\n",
    "Suppose we have multiple tools we want the chain to be able to choose from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95c86d32-ee45-4c87-a28c-14eff19b49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(first_int: int, second_int: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first_int + second_int\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(base: int, exponent: int) -> int:\n",
    "    \"Exponentiate the base to the exponent power.\"\n",
    "    return base**exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748405ff-4c85-4bd7-82e1-30458b5a4106",
   "metadata": {},
   "source": [
    "With function calling, we can do this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1629e718-fa1f-41a9-a332-811d9c099192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': {'base': 17, 'exponent': 3}, 'name': 'exponentiate'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [multiply, add, exponentiate]\n",
    "model_with_functions = model.bind(\n",
    "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
    ")\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=False)\n",
    "chain.invoke(\"what 17 cubed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3aa89e-40e1-45ec-b1f3-ab28cfc8e42d",
   "metadata": {},
   "source": [
    "If we want to run the model selected tool, we can do so using a function that returns the tool based on the model output. Specifically, our function will action return it's own subchain that gets the \"arguments\" part of the model output and passes it to the chosen tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db254773-5b8e-43d0-aabe-c21566c154cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def tool_chain(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool\n",
    "\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=False) | tool_chain\n",
    "chain.invoke(\"what's 17 cubed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
