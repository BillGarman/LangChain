<!doctype html><html lang="en"><head><title data-rh="true">Information extraction with LLM | Chetan Khadke | Medium | Medium</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2023-08-02T06:25:25.026Z"/><meta data-rh="true" name="title" content="Information extraction with LLM | Chetan Khadke | Medium | Medium"/><meta data-rh="true" property="og:title" content="Information extraction with LLM"/><meta data-rh="true" property="al:android:url" content="medium://p/cc41674b380"/><meta data-rh="true" property="al:ios:url" content="medium://p/cc41674b380"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Information extraction with LLM uses advanced language models like Llama-v2 to automatically derive structured data from unstructured text, enabling efficient decision-making and knowledge discovery"/><meta data-rh="true" property="og:description" content="Information extraction with LLM uses advanced language models like Llama-v2 to automatically derive structured data from text."/><meta data-rh="true" property="og:url" content="https://khadkechetan.medium.com/information-extraction-with-llm-chetan-kkhadke-cc41674b380"/><meta data-rh="true" property="al:web:url" content="https://khadkechetan.medium.com/information-extraction-with-llm-chetan-kkhadke-cc41674b380"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Tw7ispJfNSoaTlDQ"/><meta data-rh="true" property="article:author" content="https://khadkechetan.medium.com"/><meta data-rh="true" name="author" content="Chetankumar Khadke"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Information extraction with LLM"/><meta data-rh="true" name="twitter:site" content="@Medium"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/cc41674b380"/><meta data-rh="true" property="twitter:description" content="Information extraction with LLM uses advanced language models like Llama-v2 to automatically derive structured data from text."/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Tw7ispJfNSoaTlDQ"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="9 min read"/><meta data-rh="true" name="twitter:tile:template:testing" content="2"/><meta data-rh="true" name="twitter:tile:image" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Tw7ispJfNSoaTlDQ"/><meta data-rh="true" name="twitter:tile:info1:icon" content="Person"/><meta data-rh="true" name="twitter:tile:info1:text" content="Chetankumar Khadke"/><meta data-rh="true" name="twitter:tile:info2:icon" content="Calendar"/><meta data-rh="true" name="twitter:tile:info2:text" content="Aug 2, 2023"/><meta data-rh="true" name="twitter:cta" content="Read on Medium"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://khadkechetan.medium.com"/><link data-rh="true" rel="canonical" href="https://khadkechetan.medium.com/information-extraction-with-llm-chetan-kkhadke-cc41674b380"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/cc41674b380"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fda:true\u002Fresize:fit:1200\u002F0*Tw7ispJfNSoaTlDQ"],"url":"https:\u002F\u002Fkhadkechetan.medium.com\u002Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380","dateCreated":"2023-08-02T05:58:22.667Z","datePublished":"2023-08-02T05:58:22.667Z","dateModified":"2023-10-25T13:46:15.591Z","headline":"Information extraction with LLM | Chetan Khadke | Medium | Medium","name":"Information extraction with LLM | Chetan Khadke | Medium | Medium","description":"Information extraction with LLM uses advanced language models like Llama-v2 to automatically derive structured data from unstructured text, enabling efficient decision-making and knowledge discovery","identifier":"cc41674b380","author":{"@type":"Person","name":"Chetankumar Khadke","url":"https:\u002F\u002Fkhadkechetan.medium.com"},"creator":["Chetankumar Khadke"],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fkhadkechetan.medium.com\u002F","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:616\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fkhadkechetan.medium.com\u002Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380"}</script><style type="text/css" data-fela-rehydration="512" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="512" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{fill:rgba(0, 0, 0, 1)}.av{height:22px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:#6B6B6B}.du{font-size:13px}.dv{height:100%}.eo{color:#FFFFFF}.ep{fill:#FFFFFF}.eq{background:#1A8917}.er{border-color:#1A8917}.ev:disabled{cursor:inherit !important}.ew:disabled{opacity:0.3}.ex:disabled:hover{background:#1A8917}.ey:disabled:hover{border-color:#1A8917}.ez{border-radius:99em}.fa{border-width:1px}.fb{border-style:solid}.fc{box-sizing:border-box}.fd{text-decoration:none}.fe{text-align:center}.fh{margin-right:32px}.fi{position:relative}.fj{fill:#6B6B6B}.fm{background:transparent}.fn svg{margin-left:4px}.fo svg{fill:#6B6B6B}.fq{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fr{position:absolute}.fy{margin:0 24px}.gc{background:rgba(255, 255, 255, 1)}.gd{border:1px solid #F2F2F2}.ge{box-shadow:0 1px 4px #F2F2F2}.gf{max-height:100vh}.gg{overflow-y:auto}.gh{left:0}.gi{top:calc(100vh + 100px)}.gj{bottom:calc(100vh + 100px)}.gk{width:10px}.gl{pointer-events:none}.gm{word-break:break-word}.gn{word-wrap:break-word}.go:after{display:block}.gp:after{content:""}.gq:after{clear:both}.gr{line-height:1.23}.gs{letter-spacing:0}.gt{font-style:normal}.gu{font-weight:700}.hu{@media all and (max-width: 551.98px):8px}.hv{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.hw{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.hx{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.hy{@media all and (min-width: 1080px):16px}.ie{align-items:baseline}.if{width:48px}.ig{height:48px}.ih{border:2px solid rgba(255, 255, 255, 1)}.ii{z-index:0}.ij{box-shadow:none}.ik{border:1px solid rgba(0, 0, 0, 0.05)}.il{margin-bottom:2px}.im{flex-wrap:nowrap}.in{font-size:16px}.io{line-height:24px}.iq{margin:0 8px}.ir{display:inline}.is{color:#1A8917}.it{fill:#1A8917}.iw{flex:0 0 auto}.iz{flex-wrap:wrap}.ja{padding-left:8px}.jb{padding-right:8px}.kc> *{flex-shrink:0}.kd{overflow-x:scroll}.ke::-webkit-scrollbar{display:none}.kf{scrollbar-width:none}.kg{-ms-overflow-style:none}.kh{width:74px}.ki{flex-direction:row}.kj{margin-right:4px}.km{-webkit-user-select:none}.kn{border:0}.ko{fill:rgba(117, 117, 117, 1)}.kr{outline:0}.ks{user-select:none}.kt> svg{pointer-events:none}.lc{cursor:progress}.ld{margin-left:4px}.le{margin-top:0px}.lf{opacity:1}.lg{padding:4px 0}.lj{width:16px}.ll{display:inline-flex}.lr{max-width:100%}.ls{padding:8px 2px}.lt svg{color:#6B6B6B}.mk{line-height:1.12}.ml{letter-spacing:-0.022em}.mm{font-weight:600}.nh{margin-bottom:-0.28em}.ni{line-height:1.58}.nj{letter-spacing:-0.004em}.nk{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.of{margin-bottom:-0.46em}.ol{margin-left:auto}.om{margin-right:auto}.on{max-width:6000px}.ot{clear:both}.ov{cursor:zoom-in}.ow{z-index:auto}.oy{height:auto}.oz{margin-top:10px}.pa{max-width:728px}.pd{text-decoration:underline}.pe{list-style-type:disc}.pf{margin-left:30px}.pg{padding-left:0px}.pm{list-style-type:decimal}.pn{max-width:5120px}.po{max-width:503px}.pp{box-shadow:inset 3px 0 0 0 #242424}.pq{padding-left:23px}.pr{margin-left:-20px}.ps{font-style:italic}.pt{max-width:738px}.pu{overflow-x:auto}.pv{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.pw{padding:32px}.px{border:1px solid #E5E5E5}.py{line-height:1.4}.pz{margin-top:-0.2em}.qa{margin-bottom:-0.2em}.qb{white-space:pre}.qc{min-width:fit-content}.qd{margin-top:16px}.qe{margin-bottom:26px}.qf{margin-top:6px}.qg{margin-top:8px}.qh{margin-right:8px}.qi{padding:8px 16px}.qj{border-radius:100px}.qk{transition:background 300ms ease}.qm{white-space:nowrap}.qn{border-top:none}.qt{height:52px}.qu{max-height:52px}.qv{box-sizing:content-box}.qw{position:static}.qx{z-index:1}.qz{max-width:155px}.rf{margin-right:20px}.rl{align-items:flex-end}.rm{width:76px}.rn{height:76px}.ro{border:2px solid #F9F9F9}.rp{height:72px}.rq{width:72px}.rr{width:auto}.rs{stroke:#F2F2F2}.rt{height:36px}.ru{width:36px}.rv{color:#F2F2F2}.rw{fill:#F2F2F2}.rx{background:#F2F2F2}.ry{border-color:#F2F2F2}.se{font-weight:500}.sf{font-size:24px}.sg{line-height:30px}.sh{letter-spacing:-0.016em}.si{height:0px}.sj{border-bottom:solid 1px #E5E5E5}.sp{margin-top:72px}.sq{padding:24px 0}.sr{margin-bottom:0px}.ss{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.es:hover{background:#156D12}.et:hover{border-color:#156D12}.eu:hover{cursor:pointer}.fk:hover{color:#242424}.fl:hover{fill:#242424}.fp:hover svg{fill:#242424}.fs:hover{background-color:rgba(0, 0, 0, 0.1)}.ip:hover{text-decoration:underline}.iu:hover:not(:disabled){color:#156D12}.iv:hover:not(:disabled){fill:#156D12}.kq:hover{fill:rgba(8, 8, 8, 1)}.lh:hover{fill:#000000}.li:hover p{color:#000000}.lk:hover{color:#000000}.lu:hover svg{color:#000000}.ql:hover{background-color:#F2F2F2}.rz:hover{background:#F2F2F2}.sa:hover{border-color:#F2F2F2}.sb:hover{cursor:wait}.sc:hover{color:#F2F2F2}.sd:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.kp:focus{fill:rgba(8, 8, 8, 1)}.lv:focus svg{color:#000000}.ox:focus{transform:scale(1.01)}.ku:active{border-style:none}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.el{font-size:13px}.em{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.hp{font-size:42px}.hq{margin-top:1.19em}.hr{margin-bottom:32px}.hs{line-height:52px}.ht{letter-spacing:-0.011em}.id{align-items:center}.jo{border-top:solid 1px #F2F2F2}.jp{border-bottom:solid 1px #F2F2F2}.jq{margin:32px 0 0}.jr{padding:3px 8px}.ka> *{margin-right:24px}.kb> :last-child{margin-right:0}.lb{margin-top:0px}.lq{margin:0}.nd{font-size:24px}.ne{margin-top:1.95em}.nf{line-height:30px}.ng{letter-spacing:-0.016em}.ob{font-size:20px}.oc{margin-top:0.94em}.od{line-height:32px}.oe{letter-spacing:-0.003em}.ok{margin-top:2.14em}.os{margin-top:56px}.pl{margin-top:1.14em}.qs{margin-bottom:88px}.re{display:inline-block}.rk{padding-top:72px}.so{margin-top:40px}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.la{margin-top:0px}.pb{margin-left:auto}.pc{text-align:center}.rd{display:inline-block}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.kz{margin-top:0px}.rc{display:inline-block}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.kx{margin-top:0px}.ky{margin-right:0px}.rb{display:inline-block}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.ft{margin-bottom:4px}.gv{font-size:32px}.gw{margin-top:1.01em}.gx{margin-bottom:24px}.gy{line-height:38px}.gz{letter-spacing:-0.014em}.hz{align-items:flex-start}.ix{flex-direction:column}.jc{margin:24px -24px 0}.jd{padding:0}.js> *{margin-right:8px}.jt> :last-child{margin-right:24px}.kk{margin-left:0px}.kv{margin-top:0px}.kw{margin-right:0px}.lm{margin:0}.lw{border:1px solid #F2F2F2}.lx{border-radius:99em}.ly{padding:0px 16px 0px 12px}.lz{height:38px}.ma{align-items:center}.mc svg{margin-right:8px}.mn{font-size:20px}.mo{margin-top:1.2em}.mp{line-height:24px}.mq{letter-spacing:0}.nl{font-size:18px}.nm{margin-top:0.67em}.nn{line-height:28px}.no{letter-spacing:-0.003em}.og{margin-top:1.56em}.oo{margin-top:40px}.ph{margin-top:1.34em}.qo{margin-bottom:80px}.ra{display:inline-block}.rg{padding-top:48px}.sk{margin-top:32px}.mb:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{font-size:13px}.ek{padding:5px 12px}.ff{display:flex}.fw{margin-bottom:68px}.ga{max-width:680px}.hk{font-size:42px}.hl{margin-top:1.19em}.hm{margin-bottom:32px}.hn{line-height:52px}.ho{letter-spacing:-0.011em}.ic{align-items:center}.jk{border-top:solid 1px #F2F2F2}.jl{border-bottom:solid 1px #F2F2F2}.jm{margin:32px 0 0}.jn{padding:3px 8px}.jy> *{margin-right:24px}.jz> :last-child{margin-right:0}.lp{margin:0}.mz{font-size:24px}.na{margin-top:1.95em}.nb{line-height:30px}.nc{letter-spacing:-0.016em}.nx{font-size:20px}.ny{margin-top:0.94em}.nz{line-height:32px}.oa{letter-spacing:-0.003em}.oj{margin-top:2.14em}.or{margin-top:56px}.pk{margin-top:1.14em}.qr{margin-bottom:88px}.rj{padding-top:72px}.sn{margin-top:40px}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:68px}.fz{max-width:680px}.hf{font-size:42px}.hg{margin-top:1.19em}.hh{margin-bottom:32px}.hi{line-height:52px}.hj{letter-spacing:-0.011em}.ib{align-items:center}.jg{border-top:solid 1px #F2F2F2}.jh{border-bottom:solid 1px #F2F2F2}.ji{margin:32px 0 0}.jj{padding:3px 8px}.jw> *{margin-right:24px}.jx> :last-child{margin-right:0}.lo{margin:0}.mv{font-size:24px}.mw{margin-top:1.95em}.mx{line-height:30px}.my{letter-spacing:-0.016em}.nt{font-size:20px}.nu{margin-top:0.94em}.nv{line-height:32px}.nw{letter-spacing:-0.003em}.oi{margin-top:2.14em}.oq{margin-top:56px}.pj{margin-top:1.14em}.qq{margin-bottom:88px}.ri{padding-top:72px}.sm{margin-top:40px}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.ha{font-size:32px}.hb{margin-top:1.01em}.hc{margin-bottom:24px}.hd{line-height:38px}.he{letter-spacing:-0.014em}.ia{align-items:flex-start}.iy{flex-direction:column}.je{margin:24px 0 0}.jf{padding:0}.ju> *{margin-right:8px}.jv> :last-child{margin-right:8px}.kl{margin-left:0px}.ln{margin:0}.md{border:1px solid #F2F2F2}.me{border-radius:99em}.mf{padding:0px 16px 0px 12px}.mg{height:38px}.mh{align-items:center}.mj svg{margin-right:8px}.mr{font-size:20px}.ms{margin-top:1.2em}.mt{line-height:24px}.mu{letter-spacing:0}.np{font-size:18px}.nq{margin-top:0.67em}.nr{line-height:28px}.ns{letter-spacing:-0.003em}.oh{margin-top:1.56em}.op{margin-top:40px}.pi{margin-top:1.34em}.qp{margin-bottom:80px}.rh{padding-top:48px}.sl{margin-top:32px}.mi:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="print">.qy{display:none}</style><style type="text/css" data-fela-rehydration="512" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.ou{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="dt ag du be ak b am an ao ap aq ar as at s u w i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fcc41674b380&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderUser&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="ds"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><button class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton">Sign up</button></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 3940 610" class="au av"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search" value=""/></div></div></div><div class="h k w ff fg"><div class="fh ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------" rel="noopener follow"><div class="be b bf z dt fi fj ab q fk fl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="ds l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fh ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dt fi fj ab q fk fl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="fh h k j"><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><button class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton">Sign up</button></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ax fm am ab q ao fn fo fp" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fi"><img alt="" class="l fc bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fq bx l by bz fr n ax fs"></div></div></button></div></div></div><div class="l"><div class="ft fu fv fw fx l"><div class="ab ca"><div class="ch bg fy fz ga gb"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fr gh gi gj gk gl"></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><div><h1 id="d265" class="pw-post-title gr gs gt be gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht bj" data-testid="storyTitle">Information extraction with LLM</h1><div class="hu hv hw hx hy"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="hz ia ib ic id ab"><div><div class="ab ie"><a rel="noopener follow" href="/?source=post_page-----cc41674b380--------------------------------"><div><div class="bl" aria-hidden="false"><div class="l if ig bx ih ii"><div class="l fi"><img alt="Chetankumar Khadke" class="l fc bx dc dd cw" src="https://miro.medium.com/v2/resize:fill:88:88/1*4B8jBuPizJC_-ZmO2bJXIw.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"/><div class="ij bx l dc dd fr n ik fs"></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="il ab q"><div class="ab q im"><div class="ab q"><div><div class="bl" aria-hidden="false"><p class="be b in io bj"><a class="af ag ah ai aj ak al am an ao ap aq ar ip" data-testid="authorName" rel="noopener follow" href="/?source=post_page-----cc41674b380--------------------------------">Chetankumar Khadke</a></p></div></div></div><span class="iq ir" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b in io dt"><span><a class="is it ah ai aj ak al am an ao ap aq ar ew iu iv" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1a03249ad8f9&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;user=Chetankumar+Khadke&amp;userId=1a03249ad8f9&amp;source=post_page-1a03249ad8f9----cc41674b380---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l iw"><span class="be b bf z dt"><div class="ab cm ix iy iz"><span class="be b bf z dt"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="ja jb l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div><span data-testid="storyPublishDate">Aug 2, 2023</span></div></span></div></span></div></div></div><div class="ab co jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr"><div class="h k w ff fg q"><div class="kh l"><div class="ab q ki"><div class="pw-multi-vote-icon fi kj kk kl km"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcc41674b380&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;user=Chetankumar+Khadke&amp;userId=1a03249ad8f9&amp;source=-----cc41674b380---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="kn ao ko kp kq kr am ks kt ku km"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l kv kw kx ky kz la lb"><p class="be b du z dt"><span class="lc">--</span></p></div></div></div><div><div class="bl" aria-hidden="false"><button class="ao kn lf lg ab q fj lh li" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="le"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ld le">1</span></p></button></div></div></div><div class="ab q js jt ju jv jw jx jy jz ka kb kc kd ke kf kg"><div class="lj k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc41674b380&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;source=-----cc41674b380---------------------bookmark_footer-----------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lk" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div><div class="fc ll cm"><div class="l ae"><div class="ab ca"><div class="lm ln lo lp lq lr ch bg"><div class="ab"><div class="bl bg" aria-hidden="false"><div><div class="bl" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af fj ah ai aj ak al ls an ao ap ew lt lu li lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fj ah ai aj ak al ls an ao ap ew lt lu li lv lw lx ly lz s ma mb mc md me mf mg u mh mi mj"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><h1 id="d310" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">Introduction</h1><p id="c097" class="pw-post-body-paragraph ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of gm bj">In the age of information, data extraction from unstructured sources like PDF documents has become an indispensable task for businesses, researchers, and individuals alike. Traditional manual extraction methods are time-consuming and error-prone, necessitating more efficient and accurate alternative exploration. This blog delves into the exciting world of information extraction using Large Language models, focusing on their application to process and analyze PDF files.</p><p id="84b5" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">Large Language models, with their advanced natural language processing capabilities, have proven to be transformative tools in various domains. By leveraging these powerful models, extracting valuable insights from PDF documents becomes a streamlined process. These models can interpret the context, extract essential information, and discern patterns and relationships within the text, enabling users to derive meaningful conclusions from the vast amount of unstructured data present in PDFs.<br/>As an expert in artificial intelligence and natural language processing, I can affirm that Large Language Models (LLMs) constitute a specialized category within AI, purposefully tailored for the intricate processing and interpretation of human language.</p><p id="687b" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">The advent of large language models has undoubtedly brought about a profound revolution in machine learning. These models have unleashed a new era of possibilities in various language-related tasks by harnessing the potential of cutting-edge deep learning architectures such as transformers, GPT-3, and BERT. Natural language processing and text generation have been notably transformed by the remarkable abilities exhibited by LLMs to comprehend and produce text that closely resembles a human expression.<br/>The blog explores the technical aspects of utilizing Large Language models for PDF information extraction. Furthermore, it discusses the challenges that may arise during the extraction process, such as handling PDF complexities, OCR-issue, and document layout variations. We shall embark on a captivating journey through the realm of large language models, delving into their underlying technology and shedding light on their extraordinary capabilities.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov fi ow bg ox"><div class="ol om on"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*Tw7ispJfNSoaTlDQ 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*Tw7ispJfNSoaTlDQ 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*Tw7ispJfNSoaTlDQ 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*Tw7ispJfNSoaTlDQ 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*Tw7ispJfNSoaTlDQ 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*Tw7ispJfNSoaTlDQ 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Tw7ispJfNSoaTlDQ 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*Tw7ispJfNSoaTlDQ 640w, https://miro.medium.com/v2/resize:fit:720/0*Tw7ispJfNSoaTlDQ 720w, https://miro.medium.com/v2/resize:fit:750/0*Tw7ispJfNSoaTlDQ 750w, https://miro.medium.com/v2/resize:fit:786/0*Tw7ispJfNSoaTlDQ 786w, https://miro.medium.com/v2/resize:fit:828/0*Tw7ispJfNSoaTlDQ 828w, https://miro.medium.com/v2/resize:fit:1100/0*Tw7ispJfNSoaTlDQ 1100w, https://miro.medium.com/v2/resize:fit:1400/0*Tw7ispJfNSoaTlDQ 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg lr oy c" width="700" height="467" loading="lazy" role="presentation"/></picture></div></div><figcaption class="oz fe pa ol om pb pc be b bf z dt">Photo by <a class="af pd" href="https://unsplash.com/@wesleyphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Wesley Tingey</a> on <a class="af pd" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="efba" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">Learning Objectives</h1><ul class=""><li id="1694" class="ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of pe pf pg bj">LLM use cases</li><li id="e16a" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pe pf pg bj">Extraction Challenges</li><li id="4b45" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pe pf pg bj">LlamaIndex overview and Implementation</li><li id="14f4" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pe pf pg bj">Highlights</li><li id="874b" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pe pf pg bj">Conclusion</li></ul><h1 id="2c3e" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">LLM use cases</h1><p id="c16f" class="pw-post-body-paragraph ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of gm bj">Large Language Models (LLMs) represent advanced neural network architectures that have undergone extensive training on vast quantities of textual data, enabling them to grasp the intricacies inherent in human language. A vital feature of these models is their utilization of transformer-based architectures, which excel in capturing long-range dependencies and contextual information, making them particularly adept in various language-related applications.</p><ol class=""><li id="c9c9" class="ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of pm pf pg bj">Natural Language Processing (NLP): LLMs have made significant strides in advancing NLP tasks, including sentiment analysis, named entity recognition, text classification, and part-of-speech tagging. Their performance has surpassed previous benchmarks, achieving state-of-the-art results in various language-related endeavours.</li><li id="747f" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Text Generation: Among the most remarkable feats of language models, such as GPT-3, lies their astonishing capability in text generation. Whether crafting creative stories and poems or providing human-like responses in chatbots, these models can generate coherent and contextually relevant text.</li><li id="ff28" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Machine Translation: Large language models have significantly enhanced machine translation systems through fine-tuning translation datasets. Their capacity to translate text between multiple languages exhibits greater accuracy and fluency, promising improved communication across linguistic barriers.</li><li id="4d53" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Question-Answering Systems: LLMs have been effectively used to construct sophisticated question-answering systems. These models can answer complex queries accurately, leveraging their contextual understanding to deliver insightful responses.</li></ol><h1 id="a50f" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">Challenges</h1><p id="ad6c" class="pw-post-body-paragraph ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of gm bj">Extracting information from PDF documents entails several notable challenges that require careful consideration and specialized techniques to overcome effectively. Some of the key challenges include:</p><ol class=""><li id="81f4" class="ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of pm pf pg bj">Document Format Variability: PDF documents can be generated from various sources, leading to differences in formatting and layout. This variability complicates the extraction process as there is no standardized structure to rely on.</li><li id="6724" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Text Extraction Quality: In some PDFs, the text might not be stored as selectable or machine-readable text but as images. Converting such text to a usable format through Optical Character Recognition (OCR) can lead to errors and inaccuracies.</li><li id="df79" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Complex Document Structure: PDFs often contain complex structures, such as tables, charts, and multi-column layouts, which can make it challenging to extract information, particularly when it involves maintaining the original context accurately.</li><li id="5cea" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Handling Scanned PDFs: Scanned PDFs without OCR might be particularly challenging, requiring additional preprocessing steps and specialized tools to extract text and information accurately.</li><li id="6f68" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Handling Encrypted PDFs: Encrypted PDFs add a layer of complexity, necessitating decryption before information extraction.</li></ol><p id="4760" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">Addressing these challenges often involves a combination of advanced techniques, such as OCR for text extraction, layout analysis for understanding document structures, and custom algorithms tailored to specific document types.</p><p id="56de" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">We intend to utilize LLM (Language Model) to extract data from invoice-type documents. Our approach involves exploring three specific tools: Llama-index, LangChain, and Llama-v2, to achieve this data extraction process.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov fi ow bg ox"><div class="ol om pn"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*3kuJOewIc9q2nYBw 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*3kuJOewIc9q2nYBw 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*3kuJOewIc9q2nYBw 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*3kuJOewIc9q2nYBw 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*3kuJOewIc9q2nYBw 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*3kuJOewIc9q2nYBw 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3kuJOewIc9q2nYBw 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*3kuJOewIc9q2nYBw 640w, https://miro.medium.com/v2/resize:fit:720/0*3kuJOewIc9q2nYBw 720w, https://miro.medium.com/v2/resize:fit:750/0*3kuJOewIc9q2nYBw 750w, https://miro.medium.com/v2/resize:fit:786/0*3kuJOewIc9q2nYBw 786w, https://miro.medium.com/v2/resize:fit:828/0*3kuJOewIc9q2nYBw 828w, https://miro.medium.com/v2/resize:fit:1100/0*3kuJOewIc9q2nYBw 1100w, https://miro.medium.com/v2/resize:fit:1400/0*3kuJOewIc9q2nYBw 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg lr oy c" width="700" height="394" loading="lazy" role="presentation"/></picture></div></div><figcaption class="oz fe pa ol om pb pc be b bf z dt">Photo by <a class="af pd" href="https://unsplash.com/@steve_j?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Steve Johnson</a> on <a class="af pd" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h1 id="3046" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">LlamaIndex Overview</h1><p id="0fcc" class="pw-post-body-paragraph ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of gm bj">LlamaIndex offers a comprehensive solution to develop LLM-powered applications, such as question-answering systems, chatbots, and agents, tailored to your specific data requirements.<br/>LlamaIndex’s retrieval augmented generation (RAG) paradigm seamlessly integrates Large Language Models (LLMs) with your custom data, resulting in powerful and contextually rich applications.</p><figure class="oo op oq or os ot ol om paragraph-image"><div class="ol om po"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*dg6ghMz0mYjV5bKZGbbHdw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*dg6ghMz0mYjV5bKZGbbHdw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*dg6ghMz0mYjV5bKZGbbHdw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*dg6ghMz0mYjV5bKZGbbHdw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*dg6ghMz0mYjV5bKZGbbHdw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*dg6ghMz0mYjV5bKZGbbHdw.png 1100w, https://miro.medium.com/v2/resize:fit:1006/format:webp/1*dg6ghMz0mYjV5bKZGbbHdw.png 1006w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 503px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*dg6ghMz0mYjV5bKZGbbHdw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*dg6ghMz0mYjV5bKZGbbHdw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*dg6ghMz0mYjV5bKZGbbHdw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*dg6ghMz0mYjV5bKZGbbHdw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*dg6ghMz0mYjV5bKZGbbHdw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*dg6ghMz0mYjV5bKZGbbHdw.png 1100w, https://miro.medium.com/v2/resize:fit:1006/1*dg6ghMz0mYjV5bKZGbbHdw.png 1006w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 503px"/><img alt="" class="bg lr oy c" width="503" height="414" loading="lazy" role="presentation"/></picture></div><figcaption class="oz fe pa ol om pb pc be b bf z dt"><strong class="be mm">RAG Pipeline</strong></figcaption></figure><p id="4b35" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">During the querying stage, the retrieval augmented generation (RAG) pipeline effectively retrieves the most pertinent context in response to a user query. This contextual information, alongside the query itself, is then utilized by the Large Language Model (LLM) to generate a well-informed and relevant response. By incorporating up-to-date knowledge that may be absent from its original training data, this process also mitigates the issue of hallucination, where the model generates fictitious or inaccurate information.<br/>The primary challenge in the querying stage lies in the retrieval, orchestration, and reasoning processes, mainly when dealing with multiple knowledge bases.<br/>LlamaIndex offers a set of composable modules designed to facilitate the construction and integration of RAG pipelines. These modules cater to various applications, including Q&amp;A (query engine), chatbot (chat engine), or agent components. Each building block can be customized to reflect specific ranking preferences and seamlessly combined to enable structured reasoning across multiple knowledge bases. This empowers developers to create sophisticated and flexible RAG pipelines, ensuring the resulting applications possess accurate and insightful conversational capabilities tailored to diverse user needs.</p><h1 id="e934" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">LLAMA-V2</h1><p id="320f" class="pw-post-body-paragraph ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of gm bj">Llama 2 constitutes an assemblage of expertly pretrained and finely-tuned generative text models, encompassing an impressive parameter scale spanning from 7 billion to 70 billion, thoughtfully crafted by Meta. In particular, this repository houses the 7B fine-tuned model, meticulously optimized to excel in dialogue-centric use cases and skillfully adapted for seamless integration into the Hugging Face Transformers format.</p><p id="3850" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">The versatility of Llama 2 is evident in its diverse offerings, presenting a selection of parameter sizes, including 7B, 13B, and 70B, each tailored to cater to distinct requirements. Moreover, these models are provided in both pretrained and fine-tuned variations, further amplifying their adaptability and applicability across various domains.</p><blockquote class="pp pq pr"><p id="261a" class="ni nj ps nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">To Access the Llama-v2 <br/>Step:-<br/>1. Create an account on HuggingFace<br/>2. Request for llama model access (<a class="af pd" href="https://huggingface.co/meta-llama/Llama-2-7b-hf" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/meta-llama/Llama-2-7b-hf</a>)<br/>3. It may take a day to get access.</p><p id="1e22" class="ni nj ps nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">Go to below link and request llama access<br/>Link: <a class="af pd" href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/" rel="noopener ugc nofollow" target="_blank">https://ai.meta.com/resources/models-and-libraries/llama-downloads/</a><br/> As llama 2 is private repo, login by huggingface and generate a token.<br/>Link: <a class="af pd" href="https://huggingface.co/settings/tokens" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/settings/tokens</a></p></blockquote><h1 id="9a1f" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">Implementation</h1><p id="aafb" class="pw-post-body-paragraph ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of gm bj">The invoice provided below will be the target for data extraction. Our objective is to extract relevant information related to both the seller and the client from this particular invoice.</p><figure class="oo op oq or os ot ol om paragraph-image"><div role="button" tabindex="0" class="ou ov fi ow bg ox"><div class="ol om pt"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*nHaMrQsJkKhKogZ_9-NOgg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*nHaMrQsJkKhKogZ_9-NOgg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*nHaMrQsJkKhKogZ_9-NOgg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*nHaMrQsJkKhKogZ_9-NOgg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*nHaMrQsJkKhKogZ_9-NOgg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nHaMrQsJkKhKogZ_9-NOgg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nHaMrQsJkKhKogZ_9-NOgg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*nHaMrQsJkKhKogZ_9-NOgg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*nHaMrQsJkKhKogZ_9-NOgg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*nHaMrQsJkKhKogZ_9-NOgg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*nHaMrQsJkKhKogZ_9-NOgg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*nHaMrQsJkKhKogZ_9-NOgg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*nHaMrQsJkKhKogZ_9-NOgg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*nHaMrQsJkKhKogZ_9-NOgg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg lr oy c" width="700" height="685" loading="lazy" role="presentation"/></picture></div></div><figcaption class="oz fe pa ol om pb pc be b bf z dt">Sample invoice</figcaption></figure><blockquote class="pp pq pr"><p id="cecc" class="ni nj ps nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj"><strong class="nk gu">Hardware</strong><br/>The choice of model you can utilize is contingent on the specifications of your hardware. For optimal performance and satisfactory results, a minimum of 10GB VRAM is recommended for the 7B model, although in some cases, 8GB VRAM may suffice. Moving up the scale, the 13B model can be effectively run on GPUs such as the RTX 3090 and RTX 4090. However, for the most substantial model, specifically the largest one with 70 billion parameters, exceedingly robust hardware, such as the A100 80GB, will be required to handle the computational demands effectively.</p></blockquote><ol class=""><li id="7224" class="ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of pm pf pg bj">Install the packages</li></ol><pre class="oo op oq or os pu pv pw bo px ba bj"><span id="830a" class="py ml gt pv b bf pz qa l qb qc">!pip install -q transformers einops accelerate langchain bitsandbytes sentence_transformers llama-index pypdf python-dotenv</span></pre><p id="c261" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">2. Import the packages</p><pre class="oo op oq or os pu pv pw bo px ba bj"><span id="504e" class="py ml gt pv b bf pz qa l qb qc">import logging<br/>import sys<br/>import torch<br/>from pprint import pprint<br/>from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext<br/>from llama_index.llms import HuggingFaceLLM<br/>from langchain.embeddings.huggingface import HuggingFaceEmbeddings<br/>from llama_index import LangchainEmbedding, ServiceContext<br/>from llama_index.prompts.prompts import SimpleInputPrompt<br/><br/>logging.basicConfig(stream=sys.stdout, level=logging.INFO)<br/>logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))</span></pre><p id="3b7d" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">3. Configure the Hugging Face CLI</p><pre class="oo op oq or os pu pv pw bo px ba bj"><span id="dd5a" class="py ml gt pv b bf pz qa l qb qc">!git config --global credential.helper store<br/>!huggingface-cli login</span></pre><p id="d4db" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">4. Load the dataset</p><pre class="oo op oq or os pu pv pw bo px ba bj"><span id="4f1a" class="py ml gt pv b bf pz qa l qb qc">data_location = &#x27;/content/data&#x27; #@param<br/>documents = SimpleDirectoryReader(data_location).load_data()<br/>print(documents[2])<br/></span></pre><p id="6108" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">5. Load the embeddings</p><pre class="oo op oq or os pu pv pw bo px ba bj"><span id="4d37" class="py ml gt pv b bf pz qa l qb qc"># hyperparameters<br/>context_window = 4096 #@param<br/>temperature = 0.0 #@param<br/>model_name = &#x27;meta-llama/Llama-2-7b-chat-hf&#x27; #@param<br/><br/>llm = HuggingFaceLLM(<br/>    context_window=context_window,<br/>    max_new_tokens=256,<br/>    generate_kwargs={&quot;temperature&quot;: temperature, &quot;do_sample&quot;: False},<br/>    system_prompt=system_prompt,<br/>    query_wrapper_prompt=query_wrapper_prompt,<br/>    tokenizer_name=model_name,<br/>    model_name=model_name,<br/>    device_map=&quot;auto&quot;,<br/>    # uncomment this if using CUDA to reduce memory usage<br/>    model_kwargs={&quot;torch_dtype&quot;: torch.float16 , &quot;load_in_8bit&quot;:True, &quot;use_auth_token&quot;:True},<br/><br/>)<br/>embed_model = LangchainEmbedding(<br/>  HuggingFaceEmbeddings(model_name=&quot;sentence-transformers/all-mpnet-base-v2&quot;)<br/>)<br/>service_context = ServiceContext.from_defaults(<br/>    chunk_size=1024,<br/>    llm=llm,<br/>    embed_model=embed_model<br/>)</span></pre><p id="dbf3" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj"><strong class="nk gu">Service Context:</strong><br/>The ServiceContext serves as a comprehensive collection of frequently utilized resources within the context of indexing and querying stages in a LlamaIndex pipeline or application. As a Python data class, it offers a straightforward and efficient means of constructing the context by directly passing in the desired components.<br/>Parameters:<br/>- chunk_size: The size of the text chunk for a node .</p><p id="11c4" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj"><strong class="nk gu">Lang chain Embedding:</strong><br/>The idea behind embeddings and Vector Stores is to break large data into chunks and store those to be queried when relevant.<br/>Parameters:<br/>- cache_folder:- Path to store models.<br/>- encode_kwargs:- Keyword arguments to pass when calling the encode method of the model.<br/>- model_kwargs:- Keyword arguments to pass to the model.<br/>- model_name:- Model name to use. ( ‘sentence-transformers/all-mpnet-base-v2’)</p><p id="4f86" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">6. Index and Query</p><pre class="oo op oq or os pu pv pw bo px ba bj"><span id="9dc4" class="py ml gt pv b bf pz qa l qb qc">index = VectorStoreIndex.from_documents(documents, service_context=service_context)</span></pre><pre class="qd pu pv pw bo px ba bj"><span id="a0ec" class="py ml gt pv b bf pz qa l qb qc">user_queries = [&#x27;Seller address in the document?&#x27; , &#x27;Client address in the document?&#x27;, &#x27;seller Tax Id in the document?&#x27; ] #@param<br/>answer = dict()<br/>for i, user_query in enumerate(user_queries):<br/>    query_engine = index.as_query_engine()<br/>    response = query_engine.query(user_query)<br/>    answer.update({user_query: response.response})<br/>pprint(answer)</span></pre><pre class="qd pu pv pw bo px ba bj"><span id="f2c4" class="py ml gt pv b bf pz qa l qb qc">{&#x27;Client address in the document?&#x27;: &#x27;The client address in the document is:\n&#x27;<br/>                                    &#x27;Keller-Crosby\n&#x27;<br/>                                    &#x27;280 Kim Valleys Suite 217\n&#x27;<br/>                                    &#x27;Angelaburgh, DE 97356\n&#x27;<br/>                                    &#x27;\n&#x27;<br/>                                    &#x27;\n&#x27;<br/>                                    &#x27;\n&#x27;,<br/> &#x27;Seller address in the document?&#x27;: &quot;The seller&#x27;s address in the document is:\n&quot;<br/>                                    &#x27;2969 Todd Orchard Apt. 721\n&#x27;<br/>                                    &#x27;Port James, FL 83598\n&#x27;<br/>                                    &#x27;\n&#x27;<br/>                                    &#x27;\n&#x27;<br/>                                    &#x27;\n&#x27;<br/>                                    &#x27;\n&#x27;,<br/> &#x27;seller Tax Id in the document?&#x27;: &quot;The seller&#x27;s Tax Id is 958-83-8233.&quot;}</span></pre><h1 id="1658" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">Highlights</h1><ol class=""><li id="59d5" class="ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of pm pf pg bj">The key-value approach is effective, especially in context-specific question and answer scenarios like retrieving clients’ addresses and names.</li><li id="958f" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">Entities extraction is not perfect, and the model may struggle to identify certain information, such as the client TaxId.</li><li id="d8df" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">The expected output may vary, particularly when dealing with highly generic questions.</li><li id="7423" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj">The model’s inference speed might slow down when processing specific questions due to the complexity of contextual information.</li></ol><h1 id="1143" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">Conclusion</h1><p id="e4fa" class="pw-post-body-paragraph ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of gm bj">In conclusion, applying Large Language models for information extraction has revolutionized how we interact with data and unlocked new possibilities in various domains. These sophisticated models, such as GPT-3.5, have proven invaluable tools for extracting valuable insights from vast unstructured text data.</p><p id="02cb" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">Through natural language processing (NLP) capabilities, these models can discern patterns, relationships, and crucial information hidden within texts, enabling businesses, researchers, and individuals to make data-driven decisions more efficiently and accurately.</p><p id="4afd" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">The advantages of using Large Language models for information extraction are evident, as they eliminate the need for laborious manual extraction and significantly reduce the time and resources required for analyzing large datasets. Moreover, their adaptability and continuous learning abilities allow them to stay up-to-date with the ever-evolving language and remain effective in diverse scenarios.</p><p id="47ce" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">However, it is essential to acknowledge the challenges and ethical considerations of leveraging such powerful technology. Ensuring data privacy, avoiding bias, and maintaining transparency is crucial when implementing these models in real-world applications.</p><p id="ce66" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">As the field of NLP advances, we can expect even more sophisticated language models to emerge, further enhancing information extraction capabilities and driving innovation across various industries. Embracing these advancements responsibly and ethically will be vital to harnessing the full potential of Large Language models for a brighter, more knowledge-driven future.</p><h1 id="481b" class="mk ml gt be mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bj">References</h1><ol class=""><li id="8185" class="ni nj gt nk b nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of pm pf pg bj"><a class="af pd" href="https://gpt-index.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://gpt-index.readthedocs.io/en/latest/</a></li><li id="d299" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj"><a class="af pd" href="https://huggingface.co/meta-llama/Llama-2-7b-hf" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/meta-llama/Llama-2-7b-hf</a></li><li id="ee20" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj"><a class="af pd" href="https://python.langchain.com/docs/get_started/introduction.html" rel="noopener ugc nofollow" target="_blank">https://python.langchain.com/docs/get_started/introduction.html</a></li><li id="8943" class="ni nj gt nk b nl ph nn no np pi nr ns nt pj nv nw nx pk nz oa ob pl od oe of pm pf pg bj"><a class="af pd" href="https://www.analyticsvidhya.com/blog/2023/07/llamaindex-qa-system/" rel="noopener ugc nofollow" target="_blank">https://www.analyticsvidhya.com/blog/2023/07/llamaindex-qa-system/</a></li></ol><p id="5f27" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">Please find the complete code 💻 <a class="af pd" href="https://github.com/khadkechetan/information_extraction/blob/main/LLM/llama_v2/Information_extraction_using_LLM.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="ps">here</em></a></p><blockquote class="pp pq pr"><p id="781f" class="ni nj ps nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">If you find this content valuable, I kindly request you to show your support by following and applauding 👏 the article. Additionally, you can also follow <a class="af pd" href="https://www.linkedin.com/in/khadke-chetan/" rel="noopener ugc nofollow" target="_blank">Chetan Khadke</a> on LinkedIn for more updates. Special thanks to <a class="af pd" href="https://www.linkedin.com/in/shubham-salunke-2b1471189/" rel="noopener ugc nofollow" target="_blank">Shubham Salunke</a> for the invaluable assistance provided.</p></blockquote><p id="51f1" class="pw-post-body-paragraph ni nj gt nk b nl og nn no np oh nr ns nt oi nv nw nx oj nz oa ob ok od oe of gm bj">Please checkouts my previous 📝 <a class="af pd" href="https://github.com/khadkechetan#open_book-articles" rel="noopener ugc nofollow" target="_blank">articles</a>.</p></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg fy fz ga gb"></div></div></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="qe qf ab iz"><div class="qg ab"><a class="qh ax am ao" href="https://medium.com/tag/llama-2?source=post_page-----cc41674b380---------------llama_2-----------------" rel="noopener follow"><div class="qi fi cw qj gd qk ql be b bf z bj qm">Llama 2</div></a></div><div class="qg ab"><a class="qh ax am ao" href="https://medium.com/tag/nlp?source=post_page-----cc41674b380---------------nlp-----------------" rel="noopener follow"><div class="qi fi cw qj gd qk ql be b bf z bj qm">NLP</div></a></div><div class="qg ab"><a class="qh ax am ao" href="https://medium.com/tag/text-extraction?source=post_page-----cc41674b380---------------text_extraction-----------------" rel="noopener follow"><div class="qi fi cw qj gd qk ql be b bf z bj qm">Text Extraction</div></a></div><div class="qg ab"><a class="qh ax am ao" href="https://medium.com/tag/invoice?source=post_page-----cc41674b380---------------invoice-----------------" rel="noopener follow"><div class="qi fi cw qj gd qk ql be b bf z bj qm">Invoice</div></a></div><div class="qg ab"><a class="qh ax am ao" href="https://medium.com/tag/large-language-models?source=post_page-----cc41674b380---------------large_language_models-----------------" rel="noopener follow"><div class="qi fi cw qj gd qk ql be b bf z bj qm">Large Language Models</div></a></div></div></div></div><div class="l"></div><footer class="qn qo qp qq qr qs qt qu qv ab q qw qx c"><div class="l ae"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ab co qy"><div class="ab q ki"><div class="qz l"><span class="l ra rb rc e d"><div class="ab q ki"><div class="pw-multi-vote-icon fi kj kk kl km"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcc41674b380&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;user=Chetankumar+Khadke&amp;userId=1a03249ad8f9&amp;source=-----cc41674b380---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="kn ao ko kp kq kr am ks kt ku km"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l kv kw kx ky kz la lb"><p class="be b du z dt"><span class="lc">--</span></p></div></div></span><span class="l h g f rd re"><div class="ab q ki"><div class="pw-multi-vote-icon fi kj kk kl km"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fcc41674b380&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;user=Chetankumar+Khadke&amp;userId=1a03249ad8f9&amp;source=-----cc41674b380---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="kn ao ko kp kq kr am ks kt ku km"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l kv kw kx ky kz la lb"><p class="be b du z dt"><span class="lc">--</span></p></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false"><button class="ao kn lf lg ab q fj lh li" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="le"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z dt"><span class="pw-responses-count ld le">1</span></p></button></div></div></div></div><div class="ab q"><div class="rf l iw"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc41674b380&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lk" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div><div class="rf l iw"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fj ah ai aj ak al ls an ao ap ew lt lu li lv"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="rg rh ri rj rk l bw"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ck ab rl co"><div class="ab ie"><a rel="noopener follow" href="/?source=post_page-----cc41674b380--------------------------------"><div class="l rm rn bx ro ii"><div class="l fi"><img alt="Chetankumar Khadke" class="l fc bx rp rq cw" src="https://miro.medium.com/v2/resize:fill:144:144/1*4B8jBuPizJC_-ZmO2bJXIw.jpeg" width="72" height="72" loading="lazy"/><div class="ij bx l rp rq fr n ik fs"></div></div></div></a></div><div class="j i d"><div class="ab"><span><button class="be b bf z eo qi ep eq er es et eu ev ew ex ey ez rr fa fb fc bl fd fe">Follow</button></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1f55db04bd41&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;newsletterV3=1a03249ad8f9&amp;newsletterV3Id=1f55db04bd41&amp;user=Chetankumar+Khadke&amp;userId=1a03249ad8f9&amp;source=-----cc41674b380---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z rv am rw rx ry rz sa sb sc sd ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="rs rt ru"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" rel="noopener follow" href="/?source=post_page-----cc41674b380--------------------------------"><h2 class="pw-author-name be se sf sg sh bj"><span class="gm">Written by <!-- -->Chetankumar Khadke</span></h2></a></div><div class="qg ab"><div class="l iw"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar ip" rel="noopener follow" href="/followers?source=post_page-----cc41674b380--------------------------------">154 Followers</a></span></div></div><div class="qd l"><p class="be b bf z bj"><span class="gm">As an NLP practitioner, I employ computational methods to analyze/understand complex human language, using machine learning analysis to develop algorithms.</span></p></div></div><div class="h k"><div class="ab"><span><button class="be b bf z eo qi ep eq er es et eu ev ew ex ey ez rr fa fb fc bl fd fe">Follow</button></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F1f55db04bd41&amp;operation=register&amp;redirect=https%3A%2F%2Fkhadkechetan.medium.com%2Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380&amp;newsletterV3=1a03249ad8f9&amp;newsletterV3Id=1f55db04bd41&amp;user=Chetankumar+Khadke&amp;userId=1a03249ad8f9&amp;source=-----cc41674b380---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z rv am rw rx ry rz sa sb sc sd ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="rs rt ru"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="si bg sj sk sl sm sn so"></div></div></div><div class="h k j"><div class="si bg sj sp"></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="sq ab ki iz"><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Help</p></a></div><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Status</p></a></div><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">About</p></a></div><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Careers</p></a></div><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Blog</p></a></div><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Privacy</p></a></div><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Terms</p></a></div><div class="sr ss l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Text to speech</p></a></div><div class="sr l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----cc41674b380--------------------------------" rel="noopener follow"><p class="be b du z dt">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240226-181048-210faa0661"</script><script>window.__GRAPHQL_URI__ = "https://khadkechetan.medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-cc41674b380","user-1a03249ad8f9"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"loHomepageEnabled":false,"updatedPostPreviewsEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":true,"isFirefox":false,"routingEntity":{"type":"USER","id":"1a03249ad8f9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"4dde60c6-d58d-4f3e-b70e-24e964fab8d7","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"0105c6d3585622c8","ot-tracer-traceid":"2211a313ae184b53","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fkhadkechetan.medium.com\u002Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380","host":"khadkechetan.medium.com","hostname":"khadkechetan.medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20240226-181048-210faa0661","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240226-181048-210faa0661","commit":"210faa0661e65dc2fa92d30439f2363dc26dfa36"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"isLoggedIn":false,"collectionByDomainOrSlug({\"domainOrSlug\":\"khadkechetan.medium.com\"})":null,"postResult({\"id\":\"cc41674b380\"})":{"__ref":"Post:cc41674b380"}},"LinkedAccounts:1a03249ad8f9":{"__typename":"LinkedAccounts","mastodon":null,"id":"1a03249ad8f9"},"UserViewerEdge:userId:1a03249ad8f9-viewerId:lo_22f1fbb34ef0":{"__typename":"UserViewerEdge","id":"userId:1a03249ad8f9-viewerId:lo_22f1fbb34ef0","isFollowing":false,"isUser":false},"NewsletterV3:1f55db04bd41":{"__typename":"NewsletterV3","id":"1f55db04bd41","type":"NEWSLETTER_TYPE_AUTHOR","slug":"1a03249ad8f9","name":"1a03249ad8f9","collection":null,"user":{"__ref":"User:1a03249ad8f9"}},"User:1a03249ad8f9":{"__typename":"User","id":"1a03249ad8f9","name":"Chetankumar Khadke","username":"khadkechetan","newsletterV3":{"__ref":"NewsletterV3:1f55db04bd41"},"linkedAccounts":{"__ref":"LinkedAccounts:1a03249ad8f9"},"isSuspended":false,"imageId":"1*4B8jBuPizJC_-ZmO2bJXIw.jpeg","mediumMemberAt":1705820892000,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":154},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"khadkechetan.medium.com"}},"hasSubdomain":true,"bio":"As an NLP practitioner, I employ computational methods to analyze\u002Funderstand complex human language, using machine learning analysis to develop algorithms.","isPartnerProgramEnrolled":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:1a03249ad8f9-viewerId:lo_22f1fbb34ef0"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"membership":{"__ref":"Membership:ea6153fd407c"},"twitterScreenName":""},"Paragraph:5ad14f2f1b36_0":{"__typename":"Paragraph","id":"5ad14f2f1b36_0","name":"d265","type":"H3","href":null,"layout":null,"metadata":null,"text":"Information extraction with LLM","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_1":{"__typename":"Paragraph","id":"5ad14f2f1b36_1","name":"d310","type":"H3","href":null,"layout":null,"metadata":null,"text":"Introduction","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_2":{"__typename":"Paragraph","id":"5ad14f2f1b36_2","name":"c097","type":"P","href":null,"layout":null,"metadata":null,"text":"In the age of information, data extraction from unstructured sources like PDF documents has become an indispensable task for businesses, researchers, and individuals alike. Traditional manual extraction methods are time-consuming and error-prone, necessitating more efficient and accurate alternative exploration. This blog delves into the exciting world of information extraction using Large Language models, focusing on their application to process and analyze PDF files.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_3":{"__typename":"Paragraph","id":"5ad14f2f1b36_3","name":"84b5","type":"P","href":null,"layout":null,"metadata":null,"text":"Large Language models, with their advanced natural language processing capabilities, have proven to be transformative tools in various domains. By leveraging these powerful models, extracting valuable insights from PDF documents becomes a streamlined process. These models can interpret the context, extract essential information, and discern patterns and relationships within the text, enabling users to derive meaningful conclusions from the vast amount of unstructured data present in PDFs.\nAs an expert in artificial intelligence and natural language processing, I can affirm that Large Language Models (LLMs) constitute a specialized category within AI, purposefully tailored for the intricate processing and interpretation of human language.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_4":{"__typename":"Paragraph","id":"5ad14f2f1b36_4","name":"687b","type":"P","href":null,"layout":null,"metadata":null,"text":"The advent of large language models has undoubtedly brought about a profound revolution in machine learning. These models have unleashed a new era of possibilities in various language-related tasks by harnessing the potential of cutting-edge deep learning architectures such as transformers, GPT-3, and BERT. Natural language processing and text generation have been notably transformed by the remarkable abilities exhibited by LLMs to comprehend and produce text that closely resembles a human expression.\nThe blog explores the technical aspects of utilizing Large Language models for PDF information extraction. Furthermore, it discusses the challenges that may arise during the extraction process, such as handling PDF complexities, OCR-issue, and document layout variations. We shall embark on a captivating journey through the realm of large language models, delving into their underlying technology and shedding light on their extraordinary capabilities.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*Tw7ispJfNSoaTlDQ":{"__typename":"ImageMetadata","id":"0*Tw7ispJfNSoaTlDQ","originalHeight":4000,"originalWidth":6000,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:5ad14f2f1b36_5":{"__typename":"Paragraph","id":"5ad14f2f1b36_5","name":"9870","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*Tw7ispJfNSoaTlDQ"},"text":"Photo by Wesley Tingey on Unsplash","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":9,"end":22,"href":"https:\u002F\u002Funsplash.com\u002F@wesleyphotography?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":26,"end":34,"href":"https:\u002F\u002Funsplash.com?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_6":{"__typename":"Paragraph","id":"5ad14f2f1b36_6","name":"efba","type":"H3","href":null,"layout":null,"metadata":null,"text":"Learning Objectives","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_7":{"__typename":"Paragraph","id":"5ad14f2f1b36_7","name":"1694","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LLM use cases","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_8":{"__typename":"Paragraph","id":"5ad14f2f1b36_8","name":"e16a","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Extraction Challenges","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_9":{"__typename":"Paragraph","id":"5ad14f2f1b36_9","name":"4b45","type":"ULI","href":null,"layout":null,"metadata":null,"text":"LlamaIndex overview and Implementation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_10":{"__typename":"Paragraph","id":"5ad14f2f1b36_10","name":"14f4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Highlights","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_11":{"__typename":"Paragraph","id":"5ad14f2f1b36_11","name":"874b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_12":{"__typename":"Paragraph","id":"5ad14f2f1b36_12","name":"2c3e","type":"H3","href":null,"layout":null,"metadata":null,"text":"LLM use cases","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_13":{"__typename":"Paragraph","id":"5ad14f2f1b36_13","name":"c16f","type":"P","href":null,"layout":null,"metadata":null,"text":"Large Language Models (LLMs) represent advanced neural network architectures that have undergone extensive training on vast quantities of textual data, enabling them to grasp the intricacies inherent in human language. A vital feature of these models is their utilization of transformer-based architectures, which excel in capturing long-range dependencies and contextual information, making them particularly adept in various language-related applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_14":{"__typename":"Paragraph","id":"5ad14f2f1b36_14","name":"c9c9","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Natural Language Processing (NLP): LLMs have made significant strides in advancing NLP tasks, including sentiment analysis, named entity recognition, text classification, and part-of-speech tagging. Their performance has surpassed previous benchmarks, achieving state-of-the-art results in various language-related endeavours.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_15":{"__typename":"Paragraph","id":"5ad14f2f1b36_15","name":"747f","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Text Generation: Among the most remarkable feats of language models, such as GPT-3, lies their astonishing capability in text generation. Whether crafting creative stories and poems or providing human-like responses in chatbots, these models can generate coherent and contextually relevant text.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_16":{"__typename":"Paragraph","id":"5ad14f2f1b36_16","name":"ff28","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Machine Translation: Large language models have significantly enhanced machine translation systems through fine-tuning translation datasets. Their capacity to translate text between multiple languages exhibits greater accuracy and fluency, promising improved communication across linguistic barriers.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_17":{"__typename":"Paragraph","id":"5ad14f2f1b36_17","name":"4d53","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Question-Answering Systems: LLMs have been effectively used to construct sophisticated question-answering systems. These models can answer complex queries accurately, leveraging their contextual understanding to deliver insightful responses.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_18":{"__typename":"Paragraph","id":"5ad14f2f1b36_18","name":"a50f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Challenges","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_19":{"__typename":"Paragraph","id":"5ad14f2f1b36_19","name":"ad6c","type":"P","href":null,"layout":null,"metadata":null,"text":"Extracting information from PDF documents entails several notable challenges that require careful consideration and specialized techniques to overcome effectively. Some of the key challenges include:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_20":{"__typename":"Paragraph","id":"5ad14f2f1b36_20","name":"81f4","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Document Format Variability: PDF documents can be generated from various sources, leading to differences in formatting and layout. This variability complicates the extraction process as there is no standardized structure to rely on.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_21":{"__typename":"Paragraph","id":"5ad14f2f1b36_21","name":"6724","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Text Extraction Quality: In some PDFs, the text might not be stored as selectable or machine-readable text but as images. Converting such text to a usable format through Optical Character Recognition (OCR) can lead to errors and inaccuracies.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_22":{"__typename":"Paragraph","id":"5ad14f2f1b36_22","name":"df79","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Complex Document Structure: PDFs often contain complex structures, such as tables, charts, and multi-column layouts, which can make it challenging to extract information, particularly when it involves maintaining the original context accurately.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_23":{"__typename":"Paragraph","id":"5ad14f2f1b36_23","name":"5cea","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Handling Scanned PDFs: Scanned PDFs without OCR might be particularly challenging, requiring additional preprocessing steps and specialized tools to extract text and information accurately.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_24":{"__typename":"Paragraph","id":"5ad14f2f1b36_24","name":"6f68","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Handling Encrypted PDFs: Encrypted PDFs add a layer of complexity, necessitating decryption before information extraction.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_25":{"__typename":"Paragraph","id":"5ad14f2f1b36_25","name":"4760","type":"P","href":null,"layout":null,"metadata":null,"text":"Addressing these challenges often involves a combination of advanced techniques, such as OCR for text extraction, layout analysis for understanding document structures, and custom algorithms tailored to specific document types.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_26":{"__typename":"Paragraph","id":"5ad14f2f1b36_26","name":"56de","type":"P","href":null,"layout":null,"metadata":null,"text":"We intend to utilize LLM (Language Model) to extract data from invoice-type documents. Our approach involves exploring three specific tools: Llama-index, LangChain, and Llama-v2, to achieve this data extraction process.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*3kuJOewIc9q2nYBw":{"__typename":"ImageMetadata","id":"0*3kuJOewIc9q2nYBw","originalHeight":2880,"originalWidth":5120,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:5ad14f2f1b36_27":{"__typename":"Paragraph","id":"5ad14f2f1b36_27","name":"92b2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*3kuJOewIc9q2nYBw"},"text":"Photo by Steve Johnson on Unsplash","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":9,"end":22,"href":"https:\u002F\u002Funsplash.com\u002F@steve_j?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":26,"end":34,"href":"https:\u002F\u002Funsplash.com?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_28":{"__typename":"Paragraph","id":"5ad14f2f1b36_28","name":"3046","type":"H3","href":null,"layout":null,"metadata":null,"text":"LlamaIndex Overview","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_29":{"__typename":"Paragraph","id":"5ad14f2f1b36_29","name":"0fcc","type":"P","href":null,"layout":null,"metadata":null,"text":"LlamaIndex offers a comprehensive solution to develop LLM-powered applications, such as question-answering systems, chatbots, and agents, tailored to your specific data requirements.\nLlamaIndex’s retrieval augmented generation (RAG) paradigm seamlessly integrates Large Language Models (LLMs) with your custom data, resulting in powerful and contextually rich applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*dg6ghMz0mYjV5bKZGbbHdw.png":{"__typename":"ImageMetadata","id":"1*dg6ghMz0mYjV5bKZGbbHdw.png","originalHeight":414,"originalWidth":503,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:5ad14f2f1b36_30":{"__typename":"Paragraph","id":"5ad14f2f1b36_30","name":"d7fe","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*dg6ghMz0mYjV5bKZGbbHdw.png"},"text":"RAG Pipeline","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_31":{"__typename":"Paragraph","id":"5ad14f2f1b36_31","name":"4b35","type":"P","href":null,"layout":null,"metadata":null,"text":"During the querying stage, the retrieval augmented generation (RAG) pipeline effectively retrieves the most pertinent context in response to a user query. This contextual information, alongside the query itself, is then utilized by the Large Language Model (LLM) to generate a well-informed and relevant response. By incorporating up-to-date knowledge that may be absent from its original training data, this process also mitigates the issue of hallucination, where the model generates fictitious or inaccurate information.\nThe primary challenge in the querying stage lies in the retrieval, orchestration, and reasoning processes, mainly when dealing with multiple knowledge bases.\nLlamaIndex offers a set of composable modules designed to facilitate the construction and integration of RAG pipelines. These modules cater to various applications, including Q&A (query engine), chatbot (chat engine), or agent components. Each building block can be customized to reflect specific ranking preferences and seamlessly combined to enable structured reasoning across multiple knowledge bases. This empowers developers to create sophisticated and flexible RAG pipelines, ensuring the resulting applications possess accurate and insightful conversational capabilities tailored to diverse user needs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_32":{"__typename":"Paragraph","id":"5ad14f2f1b36_32","name":"e934","type":"H3","href":null,"layout":null,"metadata":null,"text":"LLAMA-V2","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_33":{"__typename":"Paragraph","id":"5ad14f2f1b36_33","name":"320f","type":"P","href":null,"layout":null,"metadata":null,"text":"Llama 2 constitutes an assemblage of expertly pretrained and finely-tuned generative text models, encompassing an impressive parameter scale spanning from 7 billion to 70 billion, thoughtfully crafted by Meta. In particular, this repository houses the 7B fine-tuned model, meticulously optimized to excel in dialogue-centric use cases and skillfully adapted for seamless integration into the Hugging Face Transformers format.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_34":{"__typename":"Paragraph","id":"5ad14f2f1b36_34","name":"3850","type":"P","href":null,"layout":null,"metadata":null,"text":"The versatility of Llama 2 is evident in its diverse offerings, presenting a selection of parameter sizes, including 7B, 13B, and 70B, each tailored to cater to distinct requirements. Moreover, these models are provided in both pretrained and fine-tuned variations, further amplifying their adaptability and applicability across various domains.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_35":{"__typename":"Paragraph","id":"5ad14f2f1b36_35","name":"261a","type":"BQ","href":null,"layout":null,"metadata":null,"text":"To Access the Llama-v2 \nStep:-\n1. Create an account on HuggingFace\n2. Request for llama model access (https:\u002F\u002Fhuggingface.co\u002Fmeta-llama\u002FLlama-2-7b-hf)\n3. It may take a day to get access.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":102,"end":149,"href":"https:\u002F\u002Fhuggingface.co\u002Fmeta-llama\u002FLlama-2-7b-hf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_36":{"__typename":"Paragraph","id":"5ad14f2f1b36_36","name":"1e22","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Go to below link and request llama access\nLink: https:\u002F\u002Fai.meta.com\u002Fresources\u002Fmodels-and-libraries\u002Fllama-downloads\u002F\n As llama 2 is private repo, login by huggingface and generate a token.\nLink: https:\u002F\u002Fhuggingface.co\u002Fsettings\u002Ftokens","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":48,"end":115,"href":"https:\u002F\u002Fai.meta.com\u002Fresources\u002Fmodels-and-libraries\u002Fllama-downloads\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":194,"end":232,"href":"https:\u002F\u002Fhuggingface.co\u002Fsettings\u002Ftokens","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_37":{"__typename":"Paragraph","id":"5ad14f2f1b36_37","name":"9a1f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Implementation","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_38":{"__typename":"Paragraph","id":"5ad14f2f1b36_38","name":"aafb","type":"P","href":null,"layout":null,"metadata":null,"text":"The invoice provided below will be the target for data extraction. Our objective is to extract relevant information related to both the seller and the client from this particular invoice.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*nHaMrQsJkKhKogZ_9-NOgg.png":{"__typename":"ImageMetadata","id":"1*nHaMrQsJkKhKogZ_9-NOgg.png","originalHeight":722,"originalWidth":738,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:5ad14f2f1b36_39":{"__typename":"Paragraph","id":"5ad14f2f1b36_39","name":"ccd1","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*nHaMrQsJkKhKogZ_9-NOgg.png"},"text":"Sample invoice","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_40":{"__typename":"Paragraph","id":"5ad14f2f1b36_40","name":"cecc","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Hardware\nThe choice of model you can utilize is contingent on the specifications of your hardware. For optimal performance and satisfactory results, a minimum of 10GB VRAM is recommended for the 7B model, although in some cases, 8GB VRAM may suffice. Moving up the scale, the 13B model can be effectively run on GPUs such as the RTX 3090 and RTX 4090. However, for the most substantial model, specifically the largest one with 70 billion parameters, exceedingly robust hardware, such as the A100 80GB, will be required to handle the computational demands effectively.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_41":{"__typename":"Paragraph","id":"5ad14f2f1b36_41","name":"7224","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Install the packages","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_42":{"__typename":"Paragraph","id":"5ad14f2f1b36_42","name":"830a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"!pip install -q transformers einops accelerate langchain bitsandbytes sentence_transformers llama-index pypdf python-dotenv","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_43":{"__typename":"Paragraph","id":"5ad14f2f1b36_43","name":"c261","type":"P","href":null,"layout":null,"metadata":null,"text":"2. Import the packages","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_44":{"__typename":"Paragraph","id":"5ad14f2f1b36_44","name":"504e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import logging\nimport sys\nimport torch\nfrom pprint import pprint\nfrom llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\nfrom llama_index.llms import HuggingFaceLLM\nfrom langchain.embeddings.huggingface import HuggingFaceEmbeddings\nfrom llama_index import LangchainEmbedding, ServiceContext\nfrom llama_index.prompts.prompts import SimpleInputPrompt\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_45":{"__typename":"Paragraph","id":"5ad14f2f1b36_45","name":"3b7d","type":"P","href":null,"layout":null,"metadata":null,"text":"3. Configure the Hugging Face CLI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_46":{"__typename":"Paragraph","id":"5ad14f2f1b36_46","name":"dd5a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"!git config --global credential.helper store\n!huggingface-cli login","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_47":{"__typename":"Paragraph","id":"5ad14f2f1b36_47","name":"d4db","type":"P","href":null,"layout":null,"metadata":null,"text":"4. Load the dataset","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_48":{"__typename":"Paragraph","id":"5ad14f2f1b36_48","name":"4f1a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"data_location = '\u002Fcontent\u002Fdata' #@param\ndocuments = SimpleDirectoryReader(data_location).load_data()\nprint(documents[2])\n","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_49":{"__typename":"Paragraph","id":"5ad14f2f1b36_49","name":"6108","type":"P","href":null,"layout":null,"metadata":null,"text":"5. Load the embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_50":{"__typename":"Paragraph","id":"5ad14f2f1b36_50","name":"4d37","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# hyperparameters\ncontext_window = 4096 #@param\ntemperature = 0.0 #@param\nmodel_name = 'meta-llama\u002FLlama-2-7b-chat-hf' #@param\n\nllm = HuggingFaceLLM(\n    context_window=context_window,\n    max_new_tokens=256,\n    generate_kwargs={\"temperature\": temperature, \"do_sample\": False},\n    system_prompt=system_prompt,\n    query_wrapper_prompt=query_wrapper_prompt,\n    tokenizer_name=model_name,\n    model_name=model_name,\n    device_map=\"auto\",\n    # uncomment this if using CUDA to reduce memory usage\n    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True, \"use_auth_token\":True},\n\n)\nembed_model = LangchainEmbedding(\n  HuggingFaceEmbeddings(model_name=\"sentence-transformers\u002Fall-mpnet-base-v2\")\n)\nservice_context = ServiceContext.from_defaults(\n    chunk_size=1024,\n    llm=llm,\n    embed_model=embed_model\n)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_51":{"__typename":"Paragraph","id":"5ad14f2f1b36_51","name":"dbf3","type":"P","href":null,"layout":null,"metadata":null,"text":"Service Context:\nThe ServiceContext serves as a comprehensive collection of frequently utilized resources within the context of indexing and querying stages in a LlamaIndex pipeline or application. As a Python data class, it offers a straightforward and efficient means of constructing the context by directly passing in the desired components.\nParameters:\n- chunk_size: The size of the text chunk for a node .","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_52":{"__typename":"Paragraph","id":"5ad14f2f1b36_52","name":"11c4","type":"P","href":null,"layout":null,"metadata":null,"text":"Lang chain Embedding:\nThe idea behind embeddings and Vector Stores is to break large data into chunks and store those to be queried when relevant.\nParameters:\n- cache_folder:- Path to store models.\n- encode_kwargs:- Keyword arguments to pass when calling the encode method of the model.\n- model_kwargs:- Keyword arguments to pass to the model.\n- model_name:- Model name to use. ( ‘sentence-transformers\u002Fall-mpnet-base-v2’)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_53":{"__typename":"Paragraph","id":"5ad14f2f1b36_53","name":"4f86","type":"P","href":null,"layout":null,"metadata":null,"text":"6. Index and Query","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_54":{"__typename":"Paragraph","id":"5ad14f2f1b36_54","name":"9dc4","type":"PRE","href":null,"layout":null,"metadata":null,"text":"index = VectorStoreIndex.from_documents(documents, service_context=service_context)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_55":{"__typename":"Paragraph","id":"5ad14f2f1b36_55","name":"a0ec","type":"PRE","href":null,"layout":null,"metadata":null,"text":"user_queries = ['Seller address in the document?' , 'Client address in the document?', 'seller Tax Id in the document?' ] #@param\nanswer = dict()\nfor i, user_query in enumerate(user_queries):\n    query_engine = index.as_query_engine()\n    response = query_engine.query(user_query)\n    answer.update({user_query: response.response})\npprint(answer)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_56":{"__typename":"Paragraph","id":"5ad14f2f1b36_56","name":"f2c4","type":"PRE","href":null,"layout":null,"metadata":null,"text":"{'Client address in the document?': 'The client address in the document is:\\n'\n                                    'Keller-Crosby\\n'\n                                    '280 Kim Valleys Suite 217\\n'\n                                    'Angelaburgh, DE 97356\\n'\n                                    '\\n'\n                                    '\\n'\n                                    '\\n',\n 'Seller address in the document?': \"The seller's address in the document is:\\n\"\n                                    '2969 Todd Orchard Apt. 721\\n'\n                                    'Port James, FL 83598\\n'\n                                    '\\n'\n                                    '\\n'\n                                    '\\n'\n                                    '\\n',\n 'seller Tax Id in the document?': \"The seller's Tax Id is 958-83-8233.\"}","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"DISABLED","lang":null},"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_57":{"__typename":"Paragraph","id":"5ad14f2f1b36_57","name":"1658","type":"H3","href":null,"layout":null,"metadata":null,"text":"Highlights","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_58":{"__typename":"Paragraph","id":"5ad14f2f1b36_58","name":"59d5","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The key-value approach is effective, especially in context-specific question and answer scenarios like retrieving clients’ addresses and names.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_59":{"__typename":"Paragraph","id":"5ad14f2f1b36_59","name":"958f","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Entities extraction is not perfect, and the model may struggle to identify certain information, such as the client TaxId.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_60":{"__typename":"Paragraph","id":"5ad14f2f1b36_60","name":"d8df","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The expected output may vary, particularly when dealing with highly generic questions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_61":{"__typename":"Paragraph","id":"5ad14f2f1b36_61","name":"7423","type":"OLI","href":null,"layout":null,"metadata":null,"text":"The model’s inference speed might slow down when processing specific questions due to the complexity of contextual information.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_62":{"__typename":"Paragraph","id":"5ad14f2f1b36_62","name":"1143","type":"H3","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_63":{"__typename":"Paragraph","id":"5ad14f2f1b36_63","name":"e4fa","type":"P","href":null,"layout":null,"metadata":null,"text":"In conclusion, applying Large Language models for information extraction has revolutionized how we interact with data and unlocked new possibilities in various domains. These sophisticated models, such as GPT-3.5, have proven invaluable tools for extracting valuable insights from vast unstructured text data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_64":{"__typename":"Paragraph","id":"5ad14f2f1b36_64","name":"02cb","type":"P","href":null,"layout":null,"metadata":null,"text":"Through natural language processing (NLP) capabilities, these models can discern patterns, relationships, and crucial information hidden within texts, enabling businesses, researchers, and individuals to make data-driven decisions more efficiently and accurately.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_65":{"__typename":"Paragraph","id":"5ad14f2f1b36_65","name":"4afd","type":"P","href":null,"layout":null,"metadata":null,"text":"The advantages of using Large Language models for information extraction are evident, as they eliminate the need for laborious manual extraction and significantly reduce the time and resources required for analyzing large datasets. Moreover, their adaptability and continuous learning abilities allow them to stay up-to-date with the ever-evolving language and remain effective in diverse scenarios.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_66":{"__typename":"Paragraph","id":"5ad14f2f1b36_66","name":"47ce","type":"P","href":null,"layout":null,"metadata":null,"text":"However, it is essential to acknowledge the challenges and ethical considerations of leveraging such powerful technology. Ensuring data privacy, avoiding bias, and maintaining transparency is crucial when implementing these models in real-world applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_67":{"__typename":"Paragraph","id":"5ad14f2f1b36_67","name":"ce66","type":"P","href":null,"layout":null,"metadata":null,"text":"As the field of NLP advances, we can expect even more sophisticated language models to emerge, further enhancing information extraction capabilities and driving innovation across various industries. Embracing these advancements responsibly and ethically will be vital to harnessing the full potential of Large Language models for a brighter, more knowledge-driven future.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_68":{"__typename":"Paragraph","id":"5ad14f2f1b36_68","name":"481b","type":"H3","href":null,"layout":null,"metadata":null,"text":"References","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_69":{"__typename":"Paragraph","id":"5ad14f2f1b36_69","name":"8185","type":"OLI","href":null,"layout":null,"metadata":null,"text":"https:\u002F\u002Fgpt-index.readthedocs.io\u002Fen\u002Flatest\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":43,"href":"https:\u002F\u002Fgpt-index.readthedocs.io\u002Fen\u002Flatest\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_70":{"__typename":"Paragraph","id":"5ad14f2f1b36_70","name":"d299","type":"OLI","href":null,"layout":null,"metadata":null,"text":"https:\u002F\u002Fhuggingface.co\u002Fmeta-llama\u002FLlama-2-7b-hf","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":47,"href":"https:\u002F\u002Fhuggingface.co\u002Fmeta-llama\u002FLlama-2-7b-hf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_71":{"__typename":"Paragraph","id":"5ad14f2f1b36_71","name":"ee20","type":"OLI","href":null,"layout":null,"metadata":null,"text":"https:\u002F\u002Fpython.langchain.com\u002Fdocs\u002Fget_started\u002Fintroduction.html","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":63,"href":"https:\u002F\u002Fpython.langchain.com\u002Fdocs\u002Fget_started\u002Fintroduction.html","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_72":{"__typename":"Paragraph","id":"5ad14f2f1b36_72","name":"8943","type":"OLI","href":null,"layout":null,"metadata":null,"text":"https:\u002F\u002Fwww.analyticsvidhya.com\u002Fblog\u002F2023\u002F07\u002Fllamaindex-qa-system\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":66,"href":"https:\u002F\u002Fwww.analyticsvidhya.com\u002Fblog\u002F2023\u002F07\u002Fllamaindex-qa-system\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_73":{"__typename":"Paragraph","id":"5ad14f2f1b36_73","name":"5f27","type":"P","href":null,"layout":null,"metadata":null,"text":"Please find the complete code 💻 here","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":33,"end":37,"href":"https:\u002F\u002Fgithub.com\u002Fkhadkechetan\u002Finformation_extraction\u002Fblob\u002Fmain\u002FLLM\u002Fllama_v2\u002FInformation_extraction_using_LLM.ipynb","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":33,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_74":{"__typename":"Paragraph","id":"5ad14f2f1b36_74","name":"781f","type":"BQ","href":null,"layout":null,"metadata":null,"text":"If you find this content valuable, I kindly request you to show your support by following and applauding 👏 the article. Additionally, you can also follow Chetan Khadke on LinkedIn for more updates. Special thanks to Shubham Salunke for the invaluable assistance provided.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":155,"end":168,"href":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fkhadke-chetan\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":217,"end":232,"href":"https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fshubham-salunke-2b1471189\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:5ad14f2f1b36_75":{"__typename":"Paragraph","id":"5ad14f2f1b36_75","name":"51f1","type":"P","href":null,"layout":null,"metadata":null,"text":"Please checkouts my previous 📝 articles.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":32,"end":40,"href":"https:\u002F\u002Fgithub.com\u002Fkhadkechetan#open_book-articles","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Membership:ea6153fd407c":{"__typename":"Membership","tier":"MEMBER","id":"ea6153fd407c"},"Tag:llama-2":{"__typename":"Tag","id":"llama-2","displayTitle":"Llama 2","normalizedTagSlug":"llama-2"},"Tag:nlp":{"__typename":"Tag","id":"nlp","displayTitle":"NLP","normalizedTagSlug":"nlp"},"Tag:text-extraction":{"__typename":"Tag","id":"text-extraction","displayTitle":"Text Extraction","normalizedTagSlug":"text-extraction"},"Tag:invoice":{"__typename":"Tag","id":"invoice","displayTitle":"Invoice","normalizedTagSlug":"invoice"},"Tag:large-language-models":{"__typename":"Tag","id":"large-language-models","displayTitle":"Large Language Models","normalizedTagSlug":"large-language-models"},"Post:cc41674b380":{"__typename":"Post","id":"cc41674b380","collection":null,"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"868d","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:5ad14f2f1b36_0"},{"__ref":"Paragraph:5ad14f2f1b36_1"},{"__ref":"Paragraph:5ad14f2f1b36_2"},{"__ref":"Paragraph:5ad14f2f1b36_3"},{"__ref":"Paragraph:5ad14f2f1b36_4"},{"__ref":"Paragraph:5ad14f2f1b36_5"},{"__ref":"Paragraph:5ad14f2f1b36_6"},{"__ref":"Paragraph:5ad14f2f1b36_7"},{"__ref":"Paragraph:5ad14f2f1b36_8"},{"__ref":"Paragraph:5ad14f2f1b36_9"},{"__ref":"Paragraph:5ad14f2f1b36_10"},{"__ref":"Paragraph:5ad14f2f1b36_11"},{"__ref":"Paragraph:5ad14f2f1b36_12"},{"__ref":"Paragraph:5ad14f2f1b36_13"},{"__ref":"Paragraph:5ad14f2f1b36_14"},{"__ref":"Paragraph:5ad14f2f1b36_15"},{"__ref":"Paragraph:5ad14f2f1b36_16"},{"__ref":"Paragraph:5ad14f2f1b36_17"},{"__ref":"Paragraph:5ad14f2f1b36_18"},{"__ref":"Paragraph:5ad14f2f1b36_19"},{"__ref":"Paragraph:5ad14f2f1b36_20"},{"__ref":"Paragraph:5ad14f2f1b36_21"},{"__ref":"Paragraph:5ad14f2f1b36_22"},{"__ref":"Paragraph:5ad14f2f1b36_23"},{"__ref":"Paragraph:5ad14f2f1b36_24"},{"__ref":"Paragraph:5ad14f2f1b36_25"},{"__ref":"Paragraph:5ad14f2f1b36_26"},{"__ref":"Paragraph:5ad14f2f1b36_27"},{"__ref":"Paragraph:5ad14f2f1b36_28"},{"__ref":"Paragraph:5ad14f2f1b36_29"},{"__ref":"Paragraph:5ad14f2f1b36_30"},{"__ref":"Paragraph:5ad14f2f1b36_31"},{"__ref":"Paragraph:5ad14f2f1b36_32"},{"__ref":"Paragraph:5ad14f2f1b36_33"},{"__ref":"Paragraph:5ad14f2f1b36_34"},{"__ref":"Paragraph:5ad14f2f1b36_35"},{"__ref":"Paragraph:5ad14f2f1b36_36"},{"__ref":"Paragraph:5ad14f2f1b36_37"},{"__ref":"Paragraph:5ad14f2f1b36_38"},{"__ref":"Paragraph:5ad14f2f1b36_39"},{"__ref":"Paragraph:5ad14f2f1b36_40"},{"__ref":"Paragraph:5ad14f2f1b36_41"},{"__ref":"Paragraph:5ad14f2f1b36_42"},{"__ref":"Paragraph:5ad14f2f1b36_43"},{"__ref":"Paragraph:5ad14f2f1b36_44"},{"__ref":"Paragraph:5ad14f2f1b36_45"},{"__ref":"Paragraph:5ad14f2f1b36_46"},{"__ref":"Paragraph:5ad14f2f1b36_47"},{"__ref":"Paragraph:5ad14f2f1b36_48"},{"__ref":"Paragraph:5ad14f2f1b36_49"},{"__ref":"Paragraph:5ad14f2f1b36_50"},{"__ref":"Paragraph:5ad14f2f1b36_51"},{"__ref":"Paragraph:5ad14f2f1b36_52"},{"__ref":"Paragraph:5ad14f2f1b36_53"},{"__ref":"Paragraph:5ad14f2f1b36_54"},{"__ref":"Paragraph:5ad14f2f1b36_55"},{"__ref":"Paragraph:5ad14f2f1b36_56"},{"__ref":"Paragraph:5ad14f2f1b36_57"},{"__ref":"Paragraph:5ad14f2f1b36_58"},{"__ref":"Paragraph:5ad14f2f1b36_59"},{"__ref":"Paragraph:5ad14f2f1b36_60"},{"__ref":"Paragraph:5ad14f2f1b36_61"},{"__ref":"Paragraph:5ad14f2f1b36_62"},{"__ref":"Paragraph:5ad14f2f1b36_63"},{"__ref":"Paragraph:5ad14f2f1b36_64"},{"__ref":"Paragraph:5ad14f2f1b36_65"},{"__ref":"Paragraph:5ad14f2f1b36_66"},{"__ref":"Paragraph:5ad14f2f1b36_67"},{"__ref":"Paragraph:5ad14f2f1b36_68"},{"__ref":"Paragraph:5ad14f2f1b36_69"},{"__ref":"Paragraph:5ad14f2f1b36_70"},{"__ref":"Paragraph:5ad14f2f1b36_71"},{"__ref":"Paragraph:5ad14f2f1b36_72"},{"__ref":"Paragraph:5ad14f2f1b36_73"},{"__ref":"Paragraph:5ad14f2f1b36_74"},{"__ref":"Paragraph:5ad14f2f1b36_75"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:1a03249ad8f9"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fkhadkechetan.medium.com\u002Finformation-extraction-with-llm-chetan-kkhadke-cc41674b380","primaryTopic":null,"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"}],"isPublished":true,"latestPublishedVersion":"5ad14f2f1b36","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":1},"createdAt":1690632809589,"firstPublishedAt":1690955902667,"latestPublishedAt":1690957525026,"clapCount":120,"allowResponses":true,"isLimitedState":false,"title":"Information extraction with LLM","isSeries":false,"sequence":null,"uniqueSlug":"information-extraction-with-llm-chetan-kkhadke-cc41674b380","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":8.40566037735849,"previewContent":{"__typename":"PreviewContent","subtitle":"Information extraction with LLM uses advanced language models like Llama-v2 to automatically derive structured data from text."},"previewImage":{"__ref":"ImageMetadata:0*Tw7ispJfNSoaTlDQ"},"isShortform":false,"seoTitle":"Information extraction with LLM | Chetan Khadke | Medium","updatedAt":1698241575591,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"Information extraction with LLM uses advanced language models like Llama-v2 to automatically derive structured data from unstructured text, enabling efficient decision-making and knowledge discovery ","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:llama-2"},{"__ref":"Tag:nlp"},{"__ref":"Tag:text-extraction"},{"__ref":"Tag:invoice"},{"__ref":"Tag:large-language-models"}],"pendingCollection":null,"statusForCollection":null,"detectedLanguage":"en","wordCount":2042,"layerCake":6}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.f4827de3.js"></script><script src="https://cdn-client.medium.com/lite/static/js/3057.5e22bbb0.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.547286bf.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.7c58a71f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.2021fe63.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4398.db4d4378.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7883.0e445e04.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6733.1d85727b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4711.043615ac.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8695.9065ba3d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4341.e697d2a1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5971.2c86ab13.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5203.e7a22052.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5465.248bcf72.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6487.ae5ff7c0.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1711.b70f1a35.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5459.80a6ee18.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3701.ff199b61.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6804.2cda7ee2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9174.24f568ee.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7185.34588763.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4129.ee8ae2c8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2550.dc6554d7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8580.feeb2549.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8883.c8b03d13.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4078.da7800a7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9408.3df4db57.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9150.42fafb2e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5005.b5d4a37c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6605.80950b86.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2393.aaa1ee6d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2211.706ab0f5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.9f04ea44.chunk.js"></script><script>window.main();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v84a3a4012de94ce1a686ba8c167c359c1696973893317" integrity="sha512-euoFGowhlaLqXsPWQ48qSkBSCFs3DPRyiwVu3FjR96cMPx+Fr+gpWRhIafcHwqwCqWS42RZhIudOvEI+Ckf6MA==" data-cf-beacon='{"rayId":"85cdfaf1e87b7bcb","version":"2024.2.1","token":"0b5f665943484354a59c39c6833f7078"}' crossorigin="anonymous"></script>
</body></html>