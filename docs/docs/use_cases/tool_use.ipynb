{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b94240",
   "metadata": {},
   "source": [
    "# Tool use\n",
    "\n",
    "*Last updated: 2024-01-09*\n",
    "\n",
    "An exciting use case for LLMs is building natural language interfaces for other \"tools\" (whether those are APIs, functions, databases, etc). LangChain is great for building such interfaces because it has:\n",
    "\n",
    "- Good model output parsing, which is necessary for returning structured information to pass into a tool\n",
    "- Large collection of built-in tools\n",
    "- Provides a lot of flexibility in how you call these tools\n",
    "\n",
    "In this guide, we will go over two main ways to call tools: chains and agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b79a42-0349-42c6-9ce8-72220e838e8d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's first install all the packages needed for this guide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2274266-755a-4e90-b257-5180fb089af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9c6fc-8264-462f-b8d7-9c7bbec22ef9",
   "metadata": {},
   "source": [
    "And set required environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a81b7a-4fd9-4f28-bc32-7b98b522e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# If you'd like to use LangSmith, uncomment the below\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946881",
   "metadata": {},
   "source": [
    "## Create a tool\n",
    "\n",
    "First, we need to create a tool to call. For this example, we will create a custom tool from a function. For more information on all details related to creating custom tools, please see [this guide](/docs/modules/agents/tools/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90187d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7009e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "multiply(first_int: int, second_int: int) -> int - Multiply two integers together.\n",
      "{'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be77e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"first_int\": 4, \"second_int\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba4d63",
   "metadata": {},
   "source": [
    "## Chains\n",
    "\n",
    "If we know that we only need to use a tool a fixed number of times, we can create a chain for doing so. Let's create a simple chain that just multiplies user-specified numbers.\n",
    "\n",
    "### Function calling\n",
    "One of the most reliable ways to use tools with LLMs is with function calling. This only works with models that explicitly support function calling, like OpenAI models.\n",
    "\n",
    "For this example we'll use an OpenAI chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f8e4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8253c1-8046-4376-a5dc-03b985865a92",
   "metadata": {},
   "source": [
    "Next we define our OpenAI functions. `langchain` comes with utilities for converting any `langchain` Tool into an OpenAI function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe4982ad-1e93-4234-adef-3558ba6b0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "functions = [format_tool_to_openai_function(multiply)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f859fcf-c2b1-4099-b1f9-792586cc3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'description': 'multiply(first_int: int, second_int: int) -> int - Multiply two integers together.',\n",
       "  'parameters': {'title': 'multiplySchemaSchema',\n",
       "   'type': 'object',\n",
       "   'properties': {'first_int': {'title': 'First Int', 'type': 'integer'},\n",
       "    'second_int': {'title': 'Second Int', 'type': 'integer'}},\n",
       "   'required': ['first_int', 'second_int']}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe7427-1b2c-40b0-80cd-e4a1a4061505",
   "metadata": {},
   "source": [
    "Now we'll bind our functions to our model, meaning the functions will be passed in as part of the payload to the model each time it is invoked. In this case we'll also bind `function_call`, which will force the OpenAI model to always return inputs for the `multiply` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "960a6f36-c762-4a80-9abf-50bdbdf039c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(\n",
    "    functions=functions, function_call={\"name\": \"multiply\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f479264-85e2-4833-a264-759176be653f",
   "metadata": {},
   "source": [
    "We'll chain our model together with a `JsonOutputFunctionsParser`, which returns just the `functions` part of the model output (which is in JSON) as a dictionary. We'll specify `args_only=True` in this case so that only the function arguments and not the function name is returned, since we know which function the arguments are for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e76fb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_int': 13, 'second_int': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=True)\n",
    "chain.invoke(\"what is thirteen times 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9136cd9-4f4d-4b65-9e9a-4146119349fa",
   "metadata": {},
   "source": [
    "If we specified `args_only=False`, our chain output would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7cdde16-3aec-4276-9aa2-7ff6e963c551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': {'first_int': 13, 'second_int': 4}, 'name': 'multiply'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model_with_functions | JsonOutputFunctionsParser(args_only=False)).invoke(\n",
    "    \"what is thirteen times 4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33f07c-65bc-4780-8e4b-f6cf0bc8065e",
   "metadata": {},
   "source": [
    "Suppose we wanted to add some additional instructions to the model on each call. We can do this by including a prompt at the beginning of our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60999a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Always call function `multiply` with the smaller number passed in first.\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "509e1145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_int': 4, 'second_int': 13}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73d308",
   "metadata": {},
   "source": [
    "And if we want our chain to actually call the tool once the model had determined the tool inputs, we can easily add that to our chain as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73681dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_tool = chain | multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7fe6a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_tool.invoke({\"input\": \"what is thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd690e-e54d-4209-91a4-181f69a452ac",
   "metadata": {},
   "source": [
    "### Without function calling\n",
    "\n",
    "There's plenty of models that do not support function calling. If we want to use one of these, we'll need to do a bit more manual prompting to get our model to return structured outputs containing tool inputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c64818f0-9364-423c-922e-bdfb8f01e726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply: multiply(first_int: int, second_int: int) -> int - Multiply two integers together.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "\n",
    "rendered_tools = render_text_description([multiply])\n",
    "rendered_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63552d4d-8bd6-4aca-8805-56e236f6552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f129f5bd-127c-4c95-8f34-8f437da7ca8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply', 'arguments': {'first_int': 13, 'second_int': 4}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model | JsonOutputParser()\n",
    "chain.invoke({\"input\": \"what's thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0555b384-fde6-4404-86e0-7ea199003d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = prompt | model | JsonOutputParser() | itemgetter(\"arguments\") | multiply\n",
    "chain.invoke({\"input\": \"what's thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60b2cb-6ce0-48fc-8d18-d2337161a53d",
   "metadata": {},
   "source": [
    "### Multiple tools\n",
    "\n",
    "Suppose we have multiple tools we want the chain to be able to choose from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95c86d32-ee45-4c87-a28c-14eff19b49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(first_int: int, second_int: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first_int + second_int\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(base: int, exponent: int) -> int:\n",
    "    \"Exponentiate the base to the exponent power.\"\n",
    "    return base**exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748405ff-4c85-4bd7-82e1-30458b5a4106",
   "metadata": {},
   "source": [
    "With function calling, we can do this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1629e718-fa1f-41a9-a332-811d9c099192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': {'base': 17, 'exponent': 3}, 'name': 'exponentiate'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [multiply, add, exponentiate]\n",
    "model_with_functions = model.bind(\n",
    "    functions=[format_tool_to_openai_function(t) for t in tools]\n",
    ")\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=False)\n",
    "chain.invoke(\"what 17 cubed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3aa89e-40e1-45ec-b1f3-ab28cfc8e42d",
   "metadata": {},
   "source": [
    "If we want to run the model selected tool, we can do so using a function that returns the tool based on the model output. Specifically, our function will action return it's own subchain that gets the \"arguments\" part of the model output and passes it to the chosen tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db254773-5b8e-43d0-aabe-c21566c154cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tool_chain(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool\n",
    "\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=False) | tool_chain\n",
    "chain.invoke(\"what's 17 cubed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eaccbd-d01e-43f8-bef4-34dbe6a28eb3",
   "metadata": {},
   "source": [
    "Without function calling we could do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad9f5cff-b86a-45fc-9ce4-b0aa9025a378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1135"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_tools = render_text_description(tools)\n",
    "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'arguments' keys.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")\n",
    "\n",
    "chain = prompt | model | JsonOutputParser() | tool_chain\n",
    "chain.invoke({\"input\": \"what's 3 plus 1132\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521d3d5",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be481e-cf98-4d99-a9e8-02d8d84cd8d8",
   "metadata": {},
   "source": [
    "Chains are great when we know the specific sequence of tool usage needed for any user input. But for certain use cases, how many times we use tools depends on the input. In these cases, we want to let the model itself decide how many times to use tools and in what order. [Agents](/docs/modules/agents/) let us do just this.\n",
    "\n",
    "LangChain comes with a number of built-in agents that are optimized for different use cases. Read about all the [agent types here](/docs/modules/agents/agent_types/).\n",
    "\n",
    "As an example, let's try out the OpenAI tools agent, which makes use of the new OpenAI tool-calling API (this is only available in the latest OpenAI models, and differs from function-calling in that the model can return multiple function invocations at once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "21723cf4-9421-4a8d-92a6-eeeb8f4367f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6be83879-9da3-4dd9-b147-a79f76affd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "17b09ac6-c9b7-4340-a8a0-3d3061f7888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "# Only certain models support this\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(model, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "675091d2-cac9-45c4-a5d7-b760ee6c1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4698601-4df6-42ac-8d21-a50b05fb3aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'first_int': 39, 'second_int': 7}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m273\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': 273, 'exponent': 4}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m5554571841\u001b[0m\u001b[32;1m\u001b[1;3m39 multiplied by 7 is 273, and 273 raised to the power of 4 is 5,554,571,841.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's 39 multiplied by seven, all raised to the power of 4\",\n",
       " 'output': '39 multiplied by 7 is 273, and 273 raised to the power of 4 is 5,554,571,841.'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"What's 39 multiplied by seven, all raised to the power of 4\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6099ab6-2fa6-452d-b73c-7fb65daab451",
   "metadata": {},
   "source": [
    "We can see that in this case our agent used two tools — first it multiplied, and then it used the output of that multiplication to exponentiate. With an agent, we can ask questions that require arbitrarily-many uses of our tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f7dbb240-809e-4e41-8f63-1a4636e8e26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': 3, 'exponent': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'first_int': 12, 'second_int': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'first_int': 243, 'second_int': 15}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m3645\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': 3645, 'exponent': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m13286025\u001b[0m\u001b[32;1m\u001b[1;3mThe result of raising 3 to the fifth power and multiplying that by the sum of twelve and three, then squaring the whole result is 13,286,025.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result',\n",
       " 'output': 'The result of raising 3 to the fifth power and multiplying that by the sum of twelve and three, then squaring the whole result is 13,286,025.'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb63c0e-1d8b-4cc1-948f-2d2fd08416fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
