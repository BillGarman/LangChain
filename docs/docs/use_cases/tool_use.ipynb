{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b94240",
   "metadata": {},
   "source": [
    "# Tool use\n",
    "\n",
    "*Last updated: 2024-01-09*\n",
    "\n",
    "An exciting use case for LLMs is building natural language interfaces for other \"tools\" (whether those are APIs, functions, databases, etc). LangChain is great for building such interfaces because it has:\n",
    "\n",
    "- Good model output parsing, which is necessary for returning structured information to pass into a tool\n",
    "- Large collection of built-in tools\n",
    "- Provides a lot of flexibility in how you call these tools\n",
    "\n",
    "In this guide, we will go over two main ways to call tools: chains and agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b79a42-0349-42c6-9ce8-72220e838e8d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's first install all the packages needed for this guide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2274266-755a-4e90-b257-5180fb089af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946881",
   "metadata": {},
   "source": [
    "## Create a tool\n",
    "\n",
    "First, we need to create a tool to call. For this example, we will create a custom tool from a function. For more information on all details related to creating custom tools, please see [this guide](/docs/modules/agents/tools/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90187d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7009e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "multiply(first_int: int, second_int: int) -> int - Multiply two integers together.\n",
      "{'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be77e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({\"first_int\": 4, \"second_int\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba4d63",
   "metadata": {},
   "source": [
    "## Chains\n",
    "\n",
    "If we know that we only need to use a tool a fixed number of times, we can create a chain for doing so. Let's create a simple chain that just multiplies user-specified numbers.\n",
    "\n",
    "### Function calling\n",
    "One of the most reliable ways to use tools with LLMs is with function calling. This only works with models that explicitly support function calling, like OpenAI models.\n",
    "\n",
    "For this example we'll use an OpenAI chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f8e4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8253c1-8046-4376-a5dc-03b985865a92",
   "metadata": {},
   "source": [
    "Next we define our OpenAI functions. `langchain` comes with utilities for converting any `langchain` Tool into an OpenAI function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe4982ad-1e93-4234-adef-3558ba6b0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "functions = [format_tool_to_openai_function(multiply)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f859fcf-c2b1-4099-b1f9-792586cc3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'description': 'multiply(first_int: int, second_int: int) -> int - Multiply two integers together.',\n",
       "  'parameters': {'title': 'multiplySchemaSchema',\n",
       "   'type': 'object',\n",
       "   'properties': {'first_int': {'title': 'First Int', 'type': 'integer'},\n",
       "    'second_int': {'title': 'Second Int', 'type': 'integer'}},\n",
       "   'required': ['first_int', 'second_int']}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe7427-1b2c-40b0-80cd-e4a1a4061505",
   "metadata": {},
   "source": [
    "Now we'll bind our functions to our model, meaning the functions will be passed in as part of the payload to the model each time it is invoked. In this case we'll also bind `function_call`, which will force the OpenAI model to always return inputs for the `multiply` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "960a6f36-c762-4a80-9abf-50bdbdf039c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(functions=functions, function_call={\"name\": \"multiply\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f479264-85e2-4833-a264-759176be653f",
   "metadata": {},
   "source": [
    "We'll chain our model together with a `JsonOutputFunctionsParser`, which returns just the `functions` part of the model output (which is in JSON) as a dictionary. We'll specify `args_only=True` in this case so that only the function arguments and not the function name is returned, since we know which function the arguments are for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e76fb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_int': 13, 'second_int': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=True)\n",
    "chain.invoke(\"what is thirteen times 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9136cd9-4f4d-4b65-9e9a-4146119349fa",
   "metadata": {},
   "source": [
    "If we specified `args_only=False`, our chain output would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7cdde16-3aec-4276-9aa2-7ff6e963c551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': {'first_int': 13, 'second_int': 4}, 'name': 'multiply'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model_with_functions | JsonOutputFunctionsParser(args_only=False)).invoke(\"what is thirteen times 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33f07c-65bc-4780-8e4b-f6cf0bc8065e",
   "metadata": {},
   "source": [
    "Suppose we wanted to add some additional instructions to the model on each call. We can do this by including a prompt at the beginning of our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60999a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Always call function `multiply` with the smaller number passed in first.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model_with_functions | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "509e1145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_int': 4, 'second_int': 13}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73d308",
   "metadata": {},
   "source": [
    "And if we want our chain to actually call the tool once the model had determined the tool inputs, we can easily add that to our chain as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73681dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_tool = chain | multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7fe6a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_tool.invoke({\"input\": \"what is thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd690e-e54d-4209-91a4-181f69a452ac",
   "metadata": {},
   "source": [
    "### Without function calling\n",
    "\n",
    "There's plenty of models that do not support function calling. If we want to use one of these, we'll need to do a bit more manual prompting to get our model to return structured outputs containing tool inputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c64818f0-9364-423c-922e-bdfb8f01e726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply: multiply(first_int: int, second_int: int) -> int - Multiply two integers together.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "\n",
    "rendered_tools = render_text_description([multiply])\n",
    "rendered_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63552d4d-8bd6-4aca-8805-56e236f6552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. Return your response as a JSON blob with 'name' and 'argument' keys.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f129f5bd-127c-4c95-8f34-8f437da7ca8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply', 'argument': {'first_int': 13, 'second_int': 4}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model | JsonOutputParser()\n",
    "chain.invoke({\"input\": \"what's thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0555b384-fde6-4404-86e0-7ea199003d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = prompt | model | JsonOutputParser() | itemgetter(\"argument\") | multiply\n",
    "chain.invoke({\"input\": \"what's thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60b2cb-6ce0-48fc-8d18-d2337161a53d",
   "metadata": {},
   "source": [
    "### Multiple tools\n",
    "\n",
    "Suppose we have multiple tools we want the chain to be able to choose from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95c86d32-ee45-4c87-a28c-14eff19b49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(first_int: int, second_int: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first_int + second_int\n",
    "\n",
    "@tool\n",
    "def exponentiate(base: int, exponent: int) -> int:\n",
    "    \"Exponentiate the base to the exponent power.\"\n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748405ff-4c85-4bd7-82e1-30458b5a4106",
   "metadata": {},
   "source": [
    "With function calling, we can do this like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1629e718-fa1f-41a9-a332-811d9c099192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': {'base': 17, 'exponent': 3}, 'name': 'exponentiate'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [multiply, add, exponentiate]\n",
    "model_with_functions = model.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=False)\n",
    "chain.invoke(\"what 17 cubed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db254773-5b8e-43d0-aabe-c21566c154cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tool(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool\n",
    "\n",
    "chain = model_with_functions | JsonOutputFunctionsParser(args_only=False) | get_tool\n",
    "chain.invoke(\"what's 17 cubed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521d3d5",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54c766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
