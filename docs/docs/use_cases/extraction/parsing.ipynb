{
 "cells": [
  {
   "cell_type": "raw",
   "id": "df29b30a-fd27-4e08-8269-870df5631f9e",
   "metadata": {},
   "source": [
    "---\n",
    "title: Parsing\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed451cd3-0ad0-4cfc-9e96-d3dc126a3861",
   "metadata": {},
   "source": [
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/extraction.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3af798f-2acc-4b4b-9635-782ad6868473",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "LLMs that are able to follow prompt instructions well can be asked to extract information and output it in a given format.\n",
    "\n",
    "We can then parse out the information from the text.\n",
    "\n",
    ":::{.callout-tip}\n",
    "All the same considerations for extraction quality apply for parsing approach. Review the [guidelines](/docs/use_cases/extraction/guidelines) for extraction quality. \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c082a2c-2445-49bf-ba01-ec8c8570d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic.chat_models import ChatAnthropic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24cccd2-0642-49c3-ab5e-864ea06b7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatAnthropic(model_name='claude-2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c415c-5c79-40fa-8079-5a2e88a1233c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98691fd-d1bd-4703-a228-a7b20b938cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc5150-4b96-4dfe-85e6-49e84ea3eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [('system', 'You are an expert extraction algorithm. '\n",
    "    'Only extract relevant information from the text. '\n",
    "    'Do not extract information that does not match the description'),\n",
    "     ('human', '{text}')]\n",
    "     )\n",
    "\n",
    "runnable = create_structured_output_runnable(Person, llm, prompt=prompt)\n",
    "\n",
    "text = \"Earth has only 1 moon.\"\n",
    "runnable.invoke({'text': text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a7dcf-5dc3-430d-852b-43ee2ef82d68",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[Output parsers](/docs/modules/model_io/output_parsers/) are classes that help structure language model responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f027d-ab93-4457-a327-faf7d0bffceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    person_name: str\n",
    "    person_height: int\n",
    "    person_hair_color: str\n",
    "    dog_breed: Optional[str]\n",
    "    dog_name: Optional[str]\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: Sequence[Person]\n",
    "\n",
    "\n",
    "# Run\n",
    "query = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blond.\"\"\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Run\n",
    "_input = prompt.format_prompt(query=query)\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727f3bf2-31b1-4b07-94f5-9568acf3ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic.chat_models import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf79a9-5162-4f91-b1ba-a4aa86a23e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826899df",
   "metadata": {},
   "source": [
    "We can see from the [LangSmith trace](https://smith.langchain.com/public/aec42dd3-d471-4d34-801b-20dd88444931/r) that we get the same output as above.\n",
    "\n",
    "![Image description](../../static/img/extraction_trace_parsing.png)\n",
    "\n",
    "We can see that we provide a two-shot prompt in order to instruct the LLM to output in our desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c350e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why couldn't the bicycle find its way home?\", punchline='Because it lost its bearings!')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Run\n",
    "_input = prompt.format_prompt(query=joke_query)\n",
    "model = ChatOpenAI(temperature=0)\n",
    "output = model.invoke(_input.to_string())\n",
    "parser.parse(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3601bde",
   "metadata": {},
   "source": [
    "As we can see, we get an output of the `Joke` class, which respects our originally desired schema: 'setup' and 'punchline'.\n",
    "\n",
    "We can look at the [LangSmith trace](https://smith.langchain.com/public/557ad630-af35-43e9-b043-93800539025f/r) to see exactly what is going on under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ae371",
   "metadata": {},
   "source": [
    "[Kor](https://eyurtsev.github.io/kor/) is another library for extraction where schema and examples can be provided to the LLM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
