{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Package Installer Integration for Streamlit\n",
    "\n",
    "\n",
    "**Overview**\n",
    "This notebook outlines the integration of LLMs like GPT-4 with [Streamlit](https://streamlit.io/) for developing interactive web applications for data analysis. [Streamlit](https://streamlit.io/) converts data analysis scripts into web apps, displaying results in real-time on web pages.\n",
    "\n",
    "**Key Challenge:**\n",
    "LLMs often produce code that depends on packages not pre-installed. This notebook has addressed this by enabling LLMs to dynamically install required packages, ensuring smooth code execution in Streamlit environments. This approach bypasses the need for sandbox environments, making data analysis code interactively available on the web.\n",
    "\n",
    "**Solution:**\n",
    "The process involves providing dataset information and user query to the LLM. The LLM then generates Streamlit-compatible code, which includes the capability for dynamic Python package installation during runtime.\n",
    "\n",
    "**Purpose:**\n",
    "The main goal of this notebook is to demonstrate the dynamic installation of Python packages during runtime. This is particularly essential for scripts generated by LLMs in a Streamlit context, streamlining the process of transforming data analysis scripts into interactive web applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T01:11:32.389326Z",
     "start_time": "2024-01-08T01:11:32.333974Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_community.tools import PackageInstallTool\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Creating a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T01:11:41.185737Z",
     "start_time": "2024-01-08T01:11:41.180216Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            template_format=\"jinja2\",\n",
    "            template=\"\"\"You are a data analyst. Your role is to provide a code snippet in Python tailored to data analysis query for use in Streamlit and install any imported packages using the provided tools. Your output will only contain Python code snippet without any text explanation.\n",
    "Dataset Information:{{dataset_info}}\n",
    "Variable Name for DataFrame: df\n",
    "Libraries pre-imported include: pandas as pd, streamlit as st\"\"\",\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Defining our LLM\n",
    "\n",
    "An instance of **ChatOpenAI** is created with the model **gpt-4-1106-preview** and a temperature setting of 0 to avoid hallucination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setting Up Tools\n",
    "\n",
    "**PackageInstallTool** is included as a tool to handle the installation of required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tools = [PackageInstallTool().as_tool()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Creating and Configuring the Agent\n",
    "\n",
    "An agent is created using **create_openai_functions_agent**, combining the LLM and the tools.\n",
    "\n",
    "**AgentExecutor** is set up with this agent, designed to handle execution and return intermediate steps for debugging or detailed output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Preparation\n",
    "A dataset (in this case, California housing data) is read into a DataFrame.\n",
    "\n",
    "The information about the dataset is extracted and stored in dataset_info.\n",
    "\n",
    "The dataset used in this notebook can be found [here](https://storage.cloud.google.com/package-installer-streamlit/california_housing_train.csv).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/desktop/Data Preparation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buffer = io.StringIO()\n",
    "df.info(buf=buffer)\n",
    "dataset_info = buffer.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Defining Parameters and Executing the Agent\n",
    "\n",
    "Parameters for the agent, including the dataset information and a specific data query, are defined.\n",
    "\n",
    "The agent is then invoked with these parameters to generate a Python code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset_info\": dataset_info,\n",
    "    \"query\": \"Plot population against long, latitude ?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = agent_executor.invoke(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Extracting the Generated Python Code\n",
    "\n",
    "The output from the agent is processed using regular expressions to extract the Python code snippet.\n",
    "\n",
    "If a code snippet is successfully extracted, it is printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T00:46:41.746736Z",
     "start_time": "2024-01-08T00:46:41.698942Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracted_code = re.search(r\"```python\\s+(.*?)\\s+```\", result[\"output\"], re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-08T00:46:42.922647Z",
     "start_time": "2024-01-08T00:46:42.917678Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import matplotlib.pyplot as plt\n",
      "import plotly.express as px\n",
      "\n",
      "# Using Matplotlib\n",
      "plt.figure(figsize=(10, 8))\n",
      "plt.scatter(df['longitude'], df['latitude'], c=df['population'], cmap='viridis', s=1)\n",
      "plt.colorbar(label='Population')\n",
      "plt.xlabel('Longitude')\n",
      "plt.ylabel('Latitude')\n",
      "plt.title('Population Distribution by Geographic Coordinates')\n",
      "st.pyplot(plt)\n",
      "\n",
      "# Using Plotly for an interactive plot\n",
      "fig = px.scatter_geo(df,\n",
      "                     lat='latitude',\n",
      "                     lon='longitude',\n",
      "                     color='population',\n",
      "                     projection='natural earth',\n",
      "                     title='Population Distribution by Geographic Coordinates')\n",
      "st.plotly_chart(fig)\n"
     ]
    }
   ],
   "source": [
    "if extracted_code:\n",
    "    python_code = extracted_code.group(1)\n",
    "    print(python_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
