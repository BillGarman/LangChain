{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# Runhouse\n",
    "\n",
    "The [Runhouse](https://www.run.house/) allows remote compute and data across environments and users. See the [Runhouse docs](https://www.run.house/docs).\n",
    "\n",
    "This example goes over how to use LangChain and [Runhouse](https://github.com/run-house/runhouse) to interact with models hosted on your own GPU, or on-demand GPUs on AWS, GCP, AWS, or Lambda.\n",
    "\n",
    "**Note**: Code uses `SelfHosted` name instead of the `Runhouse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066fede-2300-4173-9722-6f01f4fa34b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet \"runhouse[sky]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb585dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import runhouse as rh\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import SelfHostedHuggingFaceLLM, SelfHostedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6866e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For an on-demand A100 with GCP, Azure, or Lambda\n",
    "gpu = rh.cluster(name=\"langchain-rh-a10x\", instance_type=\"g5.4xlarge\")\n",
    "gpu.up_if_not()\n",
    "# For an on-demand A10G with AWS (no single A100s on AWS)\n",
    "# gpu = rh.cluster(name='rh-a10x', instance_type='g5.2xlarge', provider='aws')\n",
    "\n",
    "# For an existing cluster\n",
    "# gpu = rh.cluster(ips=['<ip of the cluster>'],\n",
    "#                  ssh_creds={'ssh_user': '...', 'ssh_private_key':'<path_to_key>'},\n",
    "#                  name='rh-a10x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7dcb5-7a74-4513-9ad6-aee1b4193b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_env = rh.env(\n",
    "    name=\"model_env\",\n",
    "    reqs=[\"transformers\", \"torch\", \"accelerate\", \"huggingface-hub\"],\n",
    "    secrets=[\"huggingface\"],  # need for downloading google/gemma-2b-it\n",
    ").to(system=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628d8b2-ec20-49d6-9782-2dcd64640328",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu.run(commands=[\"pip install langchain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228abaf-0eb3-4828-a153-640d60790ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SelfHostedHuggingFaceLLM(\n",
    "    model_id=\"google/gemma-2b-it\",\n",
    "    hardware=gpu,\n",
    "    env=model_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035dea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b4f06a-c698-4e69-9fee-f2efbe35976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a641dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb6fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 13:58:18.040352 | Calling LangchainLLMModelPipeline.interface_fn\n",
      "INFO | 2024-03-24 14:00:22.353148 | Time to call LangchainLLMModelPipeline.interface_fn: 124.31 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the capital of Germany?',\n",
       " 'text': '\\n\\nThe word \"Germany\" refers to a country in Western Europe that is located between the River Rhine and the River Danube.\\n\\nThe capital city of Germany is Berlin.\\n\\nTherefore, the capital of Germany is Berlin.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of Germany?\"\n",
    "\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3729af-ebe2-4fd9-baa8-eb9e28f1122b",
   "metadata": {},
   "source": [
    "You can also execute the prediction function of the model directly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1528e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:00:22.377121 | Calling LangchainLLMModelPipeline.interface_fn\n",
      "INFO | 2024-03-24 14:04:15.849123 | Time to call LangchainLLMModelPipeline.interface_fn: 233.47 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sunday.\\n\\nBright lights paint the stadium floor,\\nA symphony of cheers and roars.\\nFamilies gather, hand in hand,\\nTo watch their heroes on the grandest stage.\\n\\nThe crowd roars loud, a thunderous beat,\\nAs the game unfolds, a thrilling feat.\\nThe halftime show ignites the sky,\\nA spectacle that leaves a joyous cry.\\n\\nSuper Bowl Sunday, a spectacle to behold,\\nA moment to cherish, a story to be told.\\nThe anticipation hangs in air,\\nAs the excitement reaches its peak.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Write me a short poem about Super Bowl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a652034-d090-47ad-ae3d-6b8796248eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
