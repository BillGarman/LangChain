{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCI Data Science Model Deployment Endpoint\n",
    "\n",
    "[OCI Data Science](https://docs.oracle.com/en-us/iaas/data-science/using/home.htm) is a fully managed and serverless platform for data science teams to build, train, and manage machine learning models in the Oracle Cloud Infrastructure.\n",
    "\n",
    "This notebooks goes over how to use an LLM hosted on a [OCI Data Science Model Deployment](https://docs.oracle.com/en-us/iaas/data-science/using/model-dep-about.htm).\n",
    "\n",
    "To authenticate, [oracle-ads](https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html) has been used to automatically load credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install oracle_ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "### Deploy model\n",
    "Check [Oracle GitHub samples repository](https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/model-deployment/containers/llama2) on how to deploy your llm on OCI Data Science Model deployment.\n",
    "\n",
    "### Policies\n",
    "Make sure to have the required [policies](https://docs.oracle.com/en-us/iaas/data-science/using/model-dep-policies-auth.htm#model_dep_policies_auth__predict-endpoint) to access the OCI Data Science Model Deployment endpoint.\n",
    "\n",
    "## Set up\n",
    "\n",
    "### vLLM\n",
    "After having deployed model, you have to set up following required parameters of the `OCIModelDeploymentVLLM` call:\n",
    "- `endpoint`: The model HTTP endpoint from the deployed model, e.g. `https://<MD_OCID>/predict`. \n",
    "- `model`: The location of the model.\n",
    "\n",
    "### Text generation inference (TGI)\n",
    "You have to set up following required parameters of the `OCIModelDeploymentTGI` call:\n",
    "- `endpoint`: The model HTTP endpoint from the deployed model, e.g. `https://<MD_OCID>/predict`. \n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OCIModelDeploymentVLLM\n",
    "\n",
    "# Create an instance of OCI Model Deployment\n",
    "# Replace the endpoint uri and model name with your own\n",
    "llm = OCIModelDeploymentVLLM(\n",
    "    endpoint=\"<oci_model_deployment_endpoint>\",\n",
    "    model=\"/opt/ds/model/deployed_model\"\n",
    "    )\n",
    "\n",
    "# Run the LLM\n",
    "llm(\"Who is the first president of United States?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OCIModelDeploymentTGI\n",
    "\n",
    "# Create an instance of OCI Model Deployment\n",
    "# Replace the endpoint uri and model name with your own\n",
    "llm = OCIModelDeploymentTGI(endpoint=\"<oci_model_deployment_endpoint>\")\n",
    "\n",
    "# Run the LLM\n",
    "llm(\"Who is the first president of United States?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
