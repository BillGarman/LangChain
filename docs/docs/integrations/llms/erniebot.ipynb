{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# ERNIE Bot\n",
    "\n",
    "[ERNIE Bot](https://yiyan.baidu.com/) (Chinese: 文心一言), full name Enhanced Representation through Knowledge Integration Bot, is an AI chatbot service product of Baidu.\n",
    "\n",
    "This notebook goes over how to use LangChain to interact with ERNIE Bot large language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702ce85",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "First we'll need to install the `erniebot` Python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install erniebot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9b0aa",
   "metadata": {},
   "source": [
    "## Access token configuration\n",
    "\n",
    "To use ERNIE Bot, you should have an [AI Studio](https://aistudio.baidu.com/index) account and an access token. [Check here](https://aistudio.baidu.com/usercenter/token) to get or manage the access tokens of your AI Studio account.\n",
    "\n",
    "You can set the access token as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"EB_ACCESS_TOKEN\"] = \"{YOUR-ACCESS-TOKEN}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6664d",
   "metadata": {},
   "source": [
    "Or, you can pass the token in directly via the `aistudio_access_token` parameter when instantiating the `langchain.llms.ErnieBot` class. \n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "from langchain.llms import ErnieBot\n",
    "\n",
    "llm = ErnieBot(aistudio_access_token=\"{YOUR-ACCESS-TOKEN}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a3275",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "To start, let's create a `langchain.llms.ErnieBot` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e63413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import ErnieBot\n",
    "\n",
    "llm = ErnieBot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121880da",
   "metadata": {},
   "source": [
    "### Simple use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What does SFINAE mean in C++ template metaprogramming?\"\n",
    "\n",
    "print(llm(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674953c4",
   "metadata": {},
   "source": [
    "### Using in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035dea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"Tell me a joke about {content}.\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641dbd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f844993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = \"rabbits\"\n",
    "\n",
    "print(llm_chain.run(content=content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45741060",
   "metadata": {},
   "source": [
    "### Asynchronous calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Please write a Python program that checks if an integer is a prime number.\"\n",
    "\n",
    "answer = await llm.agenerate([question])\n",
    "# If you are not running the code in a Jupyter Notebook, use `answer = asyncio.run(llm.agenerate([question]))`.\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f673e",
   "metadata": {},
   "source": [
    "### Streaming calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb087ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the difference between capybara and kiwi?\"\n",
    "\n",
    "for chunk in llm.stream(question):\n",
    "    sys.stdout.write(chunk)\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('langchain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b27f8d187b3aeb02225dbf7258288e436f3e05f3f87e803cced6d97b886ed77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
