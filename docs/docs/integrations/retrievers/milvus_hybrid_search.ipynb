{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fc6205b",
   "metadata": {},
   "source": [
    "# Milvus Hybrid Search\n",
    "\n",
    ">[Milvus](https://milvus.io/docs/overview.md) is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.\n",
    "\n",
    "This notebook shows how to use functionality related to the Milvus>=2.4 vector database's [hybrid_search](https://milvus.io/api-reference/pymilvus/v2.4.x/ORM/Collection/hybrid_search.md). Beside `hybrid_search`, `MilvusHybridSearchRetriever` also supports normal single (dense or sparse) vector search, and Milvus's [scalar filtering query](https://milvus.io/docs/get-and-scalar-query.md). Note that you can also use langchain's [Milvus](https://python.langchain.com/docs/integrations/vectorstores/milvus/) vector store to do normal single vector search.\n",
    "\n",
    "To run, you should have a [Milvus instance up and running](https://milvus.io/docs/install_standalone-docker.md), Please make sure your Milvus instance version>=2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51489529-5dcd-4b86-bda6-de0a39d8ffd1",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1435c804-069d-4ade-9a7b-006b97b767c1",
   "metadata": {},
   "source": [
    "First, you need to install `pymilvus` python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a737220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet pymilvus>=2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c3d16",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2ed9a",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0da28",
   "metadata": {},
   "source": [
    "Milvus vector database support both dense vector search and [sparse vector search](https://milvus.io/docs/sparse_vector.md). To use sparse vector search, we need a sparse embedding model, which embed text to sparse vector. Sparse vector is a high dimension vector, but almost all element is `0.0`. Let's first define a simple sparse embedding model, we will use a realworld [BGE-M3](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3) sparse embedding model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0109a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import random\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_community.retrievers.milvus_hybrid_search import SparseEmbeddings\n",
    "\n",
    "class FakeSparseEmbeddings(SparseEmbeddings):\n",
    "    def embed_documents(self, texts: List[str]) -> List[Dict[int, float]]:\n",
    "        n = 100\n",
    "        sparse_vectors = []\n",
    "        for text in texts:\n",
    "            vector_dict = {}\n",
    "            k = random.randint(0, 4)\n",
    "            for i in range(k):\n",
    "                vector_dict[random.randint(0, n)] = random.random()\n",
    "            # Hack: This maybe Milvus's bug, which cannot accept an all zero sparse vector.\n",
    "            if not vector_dict:\n",
    "                vector_dict = {0: 0.000001}\n",
    "            sparse_vectors.append(vector_dict)\n",
    "        return sparse_vectors\n",
    "\n",
    "    def embed_query(self, text: str) -> List[Dict[int, float]]:\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef059b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_embeddings = FakeSparseEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc04986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 1e-06}, {0: 1e-06}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_embeddings.embed_documents([\"text-a\", \"text-b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95523571",
   "metadata": {},
   "source": [
    "To use hybrid search, we need one more embedding model, so we define a normal dense embedding as following.\n",
    "\n",
    "Note: to use hybrid search, you can use more than two embedding model, no matter they are sparse or dense embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccb9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDenseEmbeddings(Embeddings):\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [[random.random() for i in range(3)] for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1169bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embeddings = FakeDenseEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3860365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8816866061850618, 0.5076061045442858, 0.42096944725175933],\n",
       " [0.59377710604117, 0.5369374928633824, 0.1301035265644469]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_embeddings.embed_documents([\"text-a\", \"text-b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2473e5",
   "metadata": {},
   "source": [
    "Now, we can use hybrid search by using `MilvusHybridSearchRetriever`, the process of hybrid search under the hood is independent perform vector search for each embedding model, then a rerank model will combine these results to the final result. At the writing time, milvus support RRF (Reciprocal Rank Fusion) and Weighted rerank model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170bf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers.milvus_hybrid_search import MilvusHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef94739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MilvusHybridSearchRetriever(\n",
    "    embedding_functions={\n",
    "        \"dense\": FakeDenseEmbeddings()\n",
    "    },\n",
    "    sparse_embedding_functions={\n",
    "        \"sparse\": FakeSparseEmbeddings()\n",
    "    },\n",
    "    drop_old=True  # drop the aleady exist collection named \"LangChainCollection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f2c180f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_a', 'id_b', 'id_c', 'id_d', 'id_e']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_texts(\n",
    "    [\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "    ids=[\"id_a\", \"id_b\", \"id_c\", \"id_d\", \"id_e\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c687ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(query=\"d\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0330b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='b'),\n",
       " Document(page_content='d'),\n",
       " Document(page_content='a')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e73100",
   "metadata": {},
   "source": [
    "To inspect the detail of search and rerank params, you can use the debug mode like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c9cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from langchain_community.retrievers.milvus_hybrid_search import logger\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87549b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vector search reqs:\n",
      "anns_field: dense, param: {'param': {'metric_type': 'L2', 'params': {'ef': 10}}}, limit: 3, expr: None\n",
      "anns_field: sparse, param: {'param': {'metric_type': 'IP', 'params': {'drop_ratio_search': 0.0}}}, limit: 3, expr: None\n",
      "rerank: {'strategy': 'rrf', 'params': {'k': 60.0}}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(query=\"d\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a269023",
   "metadata": {},
   "source": [
    "### Try different index and search type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040a56e",
   "metadata": {},
   "source": [
    "TODO: `MilvusHybridSearchRetriever.search_params` is unmatched to `MilvusHybridSearchRetriever.get_relevant_documents`'s param `search_params`, confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b16c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vector search reqs:\n",
      "anns_field: dense, param: {'metric_type': 'L2', 'params': {'ef': 2}}, limit: 2, expr: None\n",
      "anns_field: sparse, param: {'param': {'metric_type': 'IP', 'params': {'drop_ratio_search': 0.0}}}, limit: 3, expr: None\n",
      "rerank: {'strategy': 'rrf', 'params': {'k': 60.0}}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\n",
    "    query=\"d\",\n",
    "    k=3,\n",
    "    search_params={\n",
    "        \"dense\": {\n",
    "            \"param\": {\"metric_type\": \"L2\", \"params\": {'ef': 2}},\n",
    "            \"limit\": 2,\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c6ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using previous connection: 51880f1947ce401eab1b8ef93726d97d\n"
     ]
    }
   ],
   "source": [
    "retriever = MilvusHybridSearchRetriever(\n",
    "    embedding_functions={\n",
    "        \"dense\": FakeDenseEmbeddings()\n",
    "    },\n",
    "    sparse_embedding_functions={\n",
    "        \"sparse\": FakeSparseEmbeddings()\n",
    "    },\n",
    "    drop_old=True,  # drop the aleady exist collection named \"LangChainCollection\",\n",
    "    index_params={\n",
    "        \"dense\": {\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"index_type\": \"FLAT\",\n",
    "            \"params\": {}\n",
    "        }\n",
    "    },\n",
    "    search_params={\n",
    "        \"dense\": {\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {},\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c875be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully created an index on collection: LangChainCollection, field_name: dense\n",
      "Successfully created an index on collection: LangChainCollection, field_name: sparse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id_a', 'id_b', 'id_c', 'id_d', 'id_e']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.add_texts(\n",
    "    [\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "    ids=[\"id_a\", \"id_b\", \"id_c\", \"id_d\", \"id_e\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51335005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vector search reqs:\n",
      "anns_field: dense, param: {'metric_type': 'COSINE', 'params': {}}, limit: 2, expr: None\n",
      "anns_field: sparse, param: {'param': {'metric_type': 'IP', 'params': {'drop_ratio_search': 0.0}}}, limit: 2, expr: None\n",
      "rerank: {'strategy': 'rrf', 'params': {'k': 60.0}}\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\n",
    "    query=\"d\",\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b253dd0",
   "metadata": {},
   "source": [
    "### Using subset of vector fields to retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216fd6b",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45708671",
   "metadata": {},
   "source": [
    "### A realworld example: BGE-M3 dense and sparse hybrid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ebdf4",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
