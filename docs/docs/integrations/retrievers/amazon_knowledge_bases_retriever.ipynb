{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6636c27-35da-4ba7-8313-eca21660cab3",
   "metadata": {},
   "source": [
    "# Knowledge Bases for Amazon Bedrock\n",
    "\n",
    "> With knowledge bases for Amazon Bedrock, from within the managed service you can connect FMs to your data sources for retrieval augmented generation (RAG), extending the FM’s already powerful capabilities and making it more knowledgeable about your specific domain and organization.\n",
    "\n",
    "> With knowledge bases for Amazon Bedrock, you can integrate FMs with your organization’s data sources to deliver more accurate and relevant responses. You can quickly add a knowledge base by specifying a data source such as Amazon Simple Storage Service (Amazon S3) to ingest data from, an embeddings FM such as Amazon Titan Embeddings to convert the data to vector format, and a destination vector database such as the vector engine for Amazon OpenSearch Serverless, Pinecone, and Redis Enterprise Cloud to store the vector data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34c8cbe-c6e5-4398-adf1-4925204bcaed",
   "metadata": {},
   "source": [
    "## Using the Knowledge Bases Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c97d36-911c-4fe0-a478-546192728f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30337664-8844-4dfe-97db-077abb51af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import AmazonKnowledgeBasesRetriever\n",
    "\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "    knowledge_base_id=\"PUIJP4EQUA\",\n",
    "    retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 4}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fefa50-f0fb-40e3-b4e4-67c5b232a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown?\"\n",
    "\n",
    "retriever.get_relevant_documents(\n",
    "    query=query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9b61b-597b-4aba-95fb-49d11e84510e",
   "metadata": {},
   "source": [
    "### Using in a QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd71709-aaed-42b5-a990-e3067bfa7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Bedrock\n",
    "\n",
    "model_kwargs_claude = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 10,\n",
    "    \"max_tokens_to_sample\": 3000\n",
    "}\n",
    "\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    model_kwargs=model_kwargs_claude\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "qa(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
