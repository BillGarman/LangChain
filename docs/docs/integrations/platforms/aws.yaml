version: 0.0.1
name: aws
company:
  name: AWS
  url: <COMPANY_URL>
  description: >
    The `LangChain` integrations related to [Amazon AWS](https://aws.amazon.com/) platform.

components:
  - type: llm
    integrations:
      - name: Bedrock
        description: >
          [Amazon Bedrock](https://aws.amazon.com/bedrock/) is a fully managed service that offers a choice of 
          high-performing foundation models (FMs) from leading AI companies like `AI21 Labs`, `Anthropic`, `Cohere`, 
          `Meta`, `Stability AI`, and `Amazon` via a single API, along with a broad set of capabilities you need to 
          build generative AI applications with security, privacy, and responsible AI. Using `Amazon Bedrock`, 
          you can easily experiment with and evaluate top FMs for your use case, privately customize them with 
          your data using techniques such as fine-tuning and `Retrieval Augmented Generation` (`RAG`), and build 
          agents that execute tasks using your enterprise systems and data sources. Since `Amazon Bedrock` is 
          serverless, you don't have to manage any infrastructure, and you can securely integrate and deploy 
          generative AI capabilities into your applications using the AWS services you are already familiar with.

        example_path: /docs/integrations/llms/bedrock
        import_code: >
          from langchain_community.llms.bedrock import Bedrock
        
      - name: Amazon API Gateway
        description: >
          [Amazon API Gateway](https://aws.amazon.com/api-gateway/) is a fully managed service that makes it easy for 
          developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the "front door" 
          for applications to access data, business logic, or functionality from your backend services. Using 
          `API Gateway`, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication 
          applications. `API Gateway` supports containerized and serverless workloads, as well as web applications.
          
          `API Gateway` handles all the tasks involved in accepting and processing up to hundreds of thousands of 
          concurrent API calls, including traffic management, CORS support, authorization and access control, 
          throttling, monitoring, and API version management. `API Gateway` has no minimum fees or startup costs. 
          You pay for the API calls you receive and the amount of data transferred out and, with the `API Gateway` 
          tiered pricing model, you can reduce your cost as your API usage scales.

        example_path: /docs/integrations/llms/amazon_api_gateway
        import_code: >
          from langchain_community.llms import AmazonAPIGateway
        
      - name: SageMaker Endpoint
        description: >
          [Amazon SageMaker](https://aws.amazon.com/sagemaker/) is a system that can build, train, and deploy 
          machine learning (ML) models with fully managed infrastructure, tools, and workflows.
          
          We use `SageMaker` to host our model and expose it as the `SageMaker Endpoint`.

        example_path: /docs/integrations/llms/sagemaker
        import_code: >
          from langchain_community.llms import SagemakerEndpoint
          from langchain_community.llms.sagemaker_endpoint import LLMContentHandler

  - type: chat_model
    integrations:
      - name: Bedrock Chat
        example_path: /docs/integrations/chat/bedrock
        import_code: >
          from langchain_community.chat_models import BedrockChat

  - type: embedding
    integrations:
      - name: SageMaker Endpoint
        example_path: /docs/integrations/text_embedding/sagemaker-endpoint
        import_code: >
          from langchain_community.embeddings import SagemakerEndpointEmbeddings
          from langchain_community.llms.sagemaker_endpoint import ContentHandlerBase

  - type: chain
    integrations:
      - name: Amazon Comprehend Moderation Chain
        description: >
          [Amazon Comprehend](https://aws.amazon.com/comprehend/) is a natural-language processing (NLP) service that 
          uses machine learning to uncover valuable insights and connections in text.
        example_path: /docs/guides/safety/amazon_comprehend_chain
        import_code: >
          from langchain_community.embeddings import SagemakerEndpointEmbeddings
          from langchain_community.llms.sagemaker_endpoint import ContentHandlerBase
        packages:
          - pip_name: boto3
          - pip_name: nltk

  - type: document_loader
    integrations:
      - name: AWS S3 Directory
        description: >
          [Amazon Simple Storage Service (Amazon S3)](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-folders.html)
          is an object storage service.
          [AWS S3 Directory](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-folders.html)
        example_path: /docs/integrations/document_loaders/aws_s3_directory
        import_code: >
          from langchain_community.document_loaders import S3DirectoryLoader
      - name: AWS S3 File
        description: >
          [Amazon Simple Storage Service (Amazon S3)](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-folders.html)
          is an object storage service.
          [AWS S3 Buckets](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingBucket.html)
        example_path: /docs/integrations/document_loaders/aws_s3_file
        import_code: >
          from langchain_community.document_loaders import S3FileLoader
      - name: Amazon Textract
        description: >
          [Amazon Textract](https://docs.aws.amazon.com/managedservices/latest/userguide/textract.html) is a machine 
          learning (ML) service that automatically extracts text, handwriting, and data from scanned documents.
        example_path: /docs/integrations/document_loaders/amazon_textract
        import_code: >
          from langchain_community.document_loaders import AmazonTextractPDFLoader

  - type: memory
    integrations:
      - name: AWS DynamoDB
        description: >
          [AWS DynamoDB](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/dynamodb/index.html) 
          is a fully managed `NoSQL` database service that provides fast and predictable performance 
          with seamless scalability.
         
          We have to configure the [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).         example_path: /docs/integrations/document_loaders/aws_s3_directory
        example_path: /docs/integrations/memory/aws_dynamodb
        import_code: >
          from langchain.memory import DynamoDBChatMessageHistory
        packages:
          - pip_name: boto3

  - type: retriever
    integrations:
      - name: Amazon Kendra
        description: >
          [Amazon Kendra](https://docs.aws.amazon.com/kendra/latest/dg/what-is-kendra.html) is an intelligent search service 
          provided by `Amazon Web Services` (`AWS`). It utilizes advanced natural language processing (NLP) and machine 
          learning algorithms to enable powerful search capabilities across various data sources within an organization. 
          `Kendra` is designed to help users find the information they need quickly and accurately, 
          improving productivity and decision-making.
          
          With `Kendra`, we can search across a wide range of content types, including documents, FAQs, knowledge bases, 
          manuals, and websites. It supports multiple languages and can understand complex queries, synonyms, and 
          contextual meanings to provide highly relevant search results.
        example_path: /docs/integrations/retrievers/amazon_kendra_retriever
        import_code: >
          from langchain.retrievers import AmazonKendraRetriever        
        packages:
          - pip_name: boto3

      - name: Amazon Bedrock (Knowledge Bases)
        description: >
          [Knowledge bases for Amazon Bedrock](https://aws.amazon.com/bedrock/knowledge-bases/) is an 
          `Amazon Web Services` (`AWS`) offering which lets you quickly build RAG applications by using your 
          private data to customize foundation model response.
        example_path: /docs/integrations/retrievers/bedrock
        import_code: >
          from langchain.retrievers import AmazonKnowledgeBasesRetriever        
        packages:
          - pip_name: boto3

  - type: vectorstore
    integrations:
      - name: Amazon OpenSearch Service
        description: >
          [Amazon OpenSearch Service](https://aws.amazon.com/opensearch-service/) performs 
          interactive log analytics, real-time application monitoring, website search, and more. `OpenSearch` is 
          an open source, 
          distributed search and analytics suite derived from `Elasticsearch`. `Amazon OpenSearch Service` offers the 
          latest versions of `OpenSearch`, support for many versions of `Elasticsearch`, as well as 
          visualization capabilities powered by `OpenSearch Dashboards` and `Kibana`.
        example_path: /docs/integrations/vectorstores/opensearch#using-aos-amazon-opensearch-service
        import_code: >
          from langchain_community.vectorstores import OpenSearchVectorSearch        
        packages:
          - pip_name: boto3
          - pip_name: requests
          - pip_name: requests-aws4auth

  - type: tool
    integrations:
      - name: AWS Lambda
        description: >
          [`Amazon AWS Lambda`](https://aws.amazon.com/pm/lambda/) is a serverless computing service provided by 
          `Amazon Web Services` (`AWS`). It helps developers to build and run applications and services without 
          provisioning or managing servers. This serverless architecture enables you to focus on writing and 
          deploying code, while AWS automatically takes care of scaling, patching, and managing the 
          infrastructure required to run your applications.
        example_path: /docs/integrations/tools/awslambda
        packages:
          - pip_name: boto3

  - type: callback
    integrations:
      - name: SageMaker Tracking
        description: >
          [Amazon SageMaker](https://aws.amazon.com/sagemaker/) is a fully managed service that is used to quickly 
          and easily build, train and deploy machine learning (ML) models.
          
          [Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) is a capability 
          of `Amazon SageMaker` that lets you organize, track, 
          compare and evaluate ML experiments and model versions.
        example_path: /docs/integrations/callbacks/sagemaker_tracking
        import_code: >
          from langchain.callbacks import SageMakerCallbackHandler
        packages:
          - pip_name: google-search-results
          - pip_name: sagemaker
