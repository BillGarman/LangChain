# Microsoft

All functionality related to Microsoft Azure

## LLM
### Azure OpenAI

>[Microsoft Azure](https://en.wikipedia.org/wiki/Microsoft_Azure), often referred to as `Azure` is a cloud computing platform run by `Microsoft`, which offers access, management, and development of applications and services through global data centers. It provides a range of capabilities, including software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS). `Microsoft Azure` supports many programming languages, tools, and frameworks, including Microsoft-specific and third-party software and systems.

>[Azure OpenAI](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/) is an `Azure` service with powerful language models from `OpenAI` including the `GPT-3`, `Codex` and `Embeddings model` series for content generation, summarization, semantic search, and natural language to code translation.

```bash
pip install openai tiktoken
```

Set the environment variables to get access to the `Azure OpenAI` service.

```python
import os

os.environ["OPENAI_API_TYPE"] = "azure"
os.environ["OPENAI_API_BASE"] = "https://<your-endpoint.openai.azure.com/"
os.environ["OPENAI_API_KEY"] = "your AzureOpenAI key"
os.environ["OPENAI_API_VERSION"] = "2023-05-15"
```

See a [usage example](/docs/integrations/llms/azure_openai_example).

```python
from langchain.llms import AzureOpenAI
```

## Text Embedding Models
### Azure OpenAI

See a [usage example](/docs/integrations/text_embedding/azureopenai)

```python
from langchain.embeddings import OpenAIEmbeddings
```

## Chat Models
### Azure OpenAI

See a [usage example](/docs/integrations/chat/azure_chat_openai)

```python
from langchain.chat_models import AzureChatOpenAI
```

## Document loaders

### Azure Blob Storage

>[Azure Blob Storage](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction) is Microsoft's object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data.

>[Azure Files](https://learn.microsoft.com/en-us/azure/storage/files/storage-files-introduction) offers fully managed
> file shares in the cloud that are accessible via the industry standard Server Message Block (`SMB`) protocol,
> Network File System (`NFS`) protocol, and `Azure Files REST API`. `Azure Files` are based on the `Azure Blob Storage`.

`Azure Blob Storage` is designed for:
- Serving images or documents directly to a browser.
- Storing files for distributed access.
- Streaming video and audio.
- Writing to log files.
- Storing data for backup and restore, disaster recovery, and archiving.
- Storing data for analysis by an on-premises or Azure-hosted service.

```bash
pip install azure-storage-blob
```

See a [usage example for the Azure Blob Storage](/docs/integrations/document_loaders/azure_blob_storage_container.html).

```python
from langchain.document_loaders import AzureBlobStorageContainerLoader
```

See a [usage example for the Azure Files](/docs/integrations/document_loaders/azure_blob_storage_file.html).

```python
from langchain.document_loaders import AzureBlobStorageFileLoader
```

### Microsoft OneDrive

>[Microsoft OneDrive](https://en.wikipedia.org/wiki/OneDrive) (formerly `SkyDrive`) is a file-hosting service operated by Microsoft.

First, you need to install a python package.

```bash
pip install o365
```

See a [usage example](/docs/integrations/document_loaders/microsoft_onedrive).

```python
from langchain.document_loaders import OneDriveLoader
```

### Microsoft Word

>[Microsoft Word](https://www.microsoft.com/en-us/microsoft-365/word) is a word processor developed by Microsoft.

See a [usage example](/docs/integrations/document_loaders/microsoft_word).

```python
from langchain.document_loaders import UnstructuredWordDocumentLoader
```


## Retriever
### Azure Cognitive Search

>[Azure Cognitive Search](https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search) (formerly known as `Azure Search`) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.

>Search is foundational to any app that surfaces text to users, where common scenarios include catalog or document search, online retail apps, or data exploration over proprietary content. When you create a search service, you'll work with the following capabilities:
>- A search engine for full text search over a search index containing user-owned content
>- Rich indexing, with lexical analysis and optional AI enrichment for content extraction and transformation
>- Rich query syntax for text search, fuzzy search, autocomplete, geo-search and more
>- Programmability through REST APIs and client libraries in Azure SDKs
>- Azure integration at the data layer, machine learning layer, and AI (Cognitive Services)

See [set up instructions](https://learn.microsoft.com/en-us/azure/search/search-create-service-portal).

See a [usage example](/docs/integrations/retrievers/azure_cognitive_search).

```python
from langchain.retrievers import AzureCognitiveSearchRetriever
```

# Azure Cosmos DB

>[Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/) makes it easy to create a database with full native MongoDB support.
> You can apply your MongoDB experience and continue to use your favorite MongoDB drivers, SDKs, and tools by pointing your application to the API for MongoDB vCore account's connection string.
> Use vector search in Azure Cosmos DB for MongoDB vCore to seamlessly integrate your AI-based applications with your data that's stored in Azure Cosmos DB.

## Installation and Setup

See [detail configuration instructions](/docs/integrations/vectorstores/azure_cosmos_db).

We need to install `pymongo` python package.

```bash
pip install pymongo
```

#### Deploy Azure Cosmos DB on Microsoft Azure

Azure Cosmos DB for MongoDB vCore provides developers with a fully managed MongoDB-compatible database service for building modern applications with a familiar architecture.

With Cosmos DB for MongoDB vCore, developers can enjoy the benefits of native Azure integrations, low total cost of ownership (TCO), and the familiar vCore architecture when migrating existing applications or building new ones.

[Sign Up](https://azure.microsoft.com/en-us/free/) for free to get started today.

## Vector Store

See a [usage example](/docs/integrations/vectorstores/azure_cosmos_db).

```python

from langchain.docstore.document import Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores.azure_cosmos_db_vector_search import AzureCosmosDBVectorSearch, CosmosDBSimilarityType

import os

# OpenAI Settings
model_deployment = os.getenv("OPENAI_EMBEDDINGS_DEPLOYMENT", "smart-agent-embedding-ada")
model_name = os.getenv("OPENAI_EMBEDDINGS_MODEL_NAME", "text-embedding-ada-002")

# Mongo DB Settings
CONNECTION_STRING = os.environ.get("MONGODB_VCORE_URI")
INDEX_NAME = "izzy-test-index"
NAMESPACE = "izzy_test_db.izzy_test_collection"
DB_NAME, COLLECTION_NAME = NAMESPACE.split(".")

num_lists = 100
dimensions = 1536
similarity_algorithm = CosmosDBSimilarityType.COS

def prepare_collection() -> Any:
    from pymongo import MongoClient

    test_client: MongoClient = MongoClient(CONNECTION_STRING)
    return test_client[DB_NAME][COLLECTION_NAME]


def azure_openai_embeddings() -> Any:
    openai_embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=model_deployment, model=model_name, chunk_size=1)
    return openai_embeddings


collection = prepare_collection()
embeddings = azure_openai_embeddings()

def load_from_documents() -> Any:

    documents = [
        Document(page_content="Dogs are tough.", metadata={"a": 1}),
        Document(page_content="Cats have fluff.", metadata={"b": 1}),
        Document(page_content="What is a sandwich?", metadata={"c": 1}),
        Document(page_content="That fence is purple.", metadata={"d": 1, "e": 2}),
    ]

    vectorstore = AzureCosmosDBVectorSearch.from_documents(
        documents,
        embeddings,
        collection=collection,
        index_name=INDEX_NAME,
    )

def load_from_texts() -> Any:
    texts = [
        "Dogs are tough. Hello",
        "Cats have fluff. Hola",
        "What is a sandwich? Burger?",
        "That fence is purple. Really?",
    ]
    vectorstore = AzureCosmosDBVectorSearch.from_texts(
        texts,
        embeddings,
        collection=collection,
        index_name=INDEX_NAME,
    )

def load_from_texts_with_metadata() -> Any:

    test_metadata_list = [{"a": 1}, {"b": 1}, {"c": 1}, {"d": 1, "e": 2}]

    texts = [
        "Dogs are tough. Hello",
        "Cats have fluff. Hola",
        "What is a sandwich? Burger?",
        "That fence is purple. Really?",
    ]
    vectorstore = AzureCosmosDBVectorSearch.from_texts(
        texts,
        embeddings,
        metadatas=test_metadata_list,
        collection=collection,
        index_name=INDEX_NAME,
    )

def create_index() -> Any:
    vectorstore = AzureCosmosDBVectorSearch.from_connection_string(CONNECTION_STRING, NAMESPACE, embeddings, index_name=INDEX_NAME)
    vectorstore.create_index(num_lists, dimensions, similarity_algorithm)


def search_similar() -> Any:
    vectorstore = AzureCosmosDBVectorSearch.from_connection_string(CONNECTION_STRING, NAMESPACE, embeddings, index_name=INDEX_NAME)

    output = vectorstore.similarity_search("Sandwich", k=7)
    print(output)

# Uncomment function calls below to invoke:
# load_from_documents()
# load_from_texts()
# load_from_texts_with_metadata()
# create_index()
# search_similar()
```