{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "683953b3",
   "metadata": {},
   "source": [
    "# Weaviate v4 (beta)\n",
    "\n",
    ">[Weaviate](https://weaviate.io/) is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML-models, and scale seamlessly into billions of data objects.\n",
    "\n",
    "This notebook shows how to use the functionality related to the `Weaviate` vector database.\n",
    "\n",
    "`Weaviate` can be deployed in many different ways depending on your requirements. For example, you can either connect to a [Weaviate Cloud Services](https://console.weaviate.cloud) instance or a [local Docker instance](https://weaviate.io/developers/weaviate/installation/docker-compose). \n",
    "See the `Weaviate` [installation instructions](https://weaviate.io/developers/weaviate/installation) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb59dec",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Install the `weaviate-client` package and set the relevant environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ab167c-fffc-4d30-b1c1-37cc1b641698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre weaviate-client>=4.0.0b0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34828d-e627-4d85-aabd-eeb15d9f4b00",
   "metadata": {},
   "source": [
    "We want to use `OpenAIEmbeddings` so we have to get the OpenAI API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37697b9f-fbb2-430e-b95d-28d6eb83486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fea2dbae-a609-4458-a05f-f1c8e1f37c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEAVIATE_URL = getpass.getpass(\"WEAVIATE_URL:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b7ce2d-3c09-4d1c-b66b-5769ce6746ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WEAVIATE_API_KEY\"] = getpass.getpass(\"WEAVIATE_API_KEY:\")\n",
    "WEAVIATE_API_KEY = os.environ[\"WEAVIATE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b867eb31",
   "metadata": {},
   "source": [
    "## Similarity search\n",
    "Below you can see a minimal example of how to approach a simple similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac9563e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.weaviate_v4 import Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c3999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../../modules/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e9e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Weaviate.from_documents(docs, embeddings, weaviate_url=WEAVIATE_URL, by_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4170176",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf3b890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. source=../../modules/state_of_the_union.txt\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7826d0ea",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13989a7c",
   "metadata": {},
   "source": [
    "Weaviate instances have authentication enabled by default. You can use either a username/password combination or API key.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6604f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain.vectorstores.weaviate.Weaviate object at 0x107f46550>\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from weaviate.auth import AuthApiKey, AuthClientPassword\n",
    "from weaviate.connect.connection import ConnectionParams, ProtocolParams\n",
    "\n",
    "client = weaviate.client.WeaviateClient(\n",
    "    connection_params=ConnectionParams(\n",
    "        http=ProtocolParams(host=WEAVIATE_URL, port=8080, secure=False),\n",
    "        grpc=ProtocolParams(host=WEAVIATE_URL, port=50051, secure=False),\n",
    "    ),\n",
    "    auth_client_secret=AuthApiKey(WEAVIATE_API_KEY),\n",
    ")\n",
    "\n",
    "# client = weaviate.client.WeaviateClient(\n",
    "#     connection_params=ConnectionParams(\n",
    "#         http=ProtocolParams(host=WEAVIATE_URL, port=8080, secure=False),\n",
    "#         grpc=ProtocolParams(host=WEAVIATE_URL, port=50051, secure=False),\n",
    "#     ),\n",
    "#     auth_client_secret=AuthClientPassword(\n",
    "#         username = \"WCS_USERNAME\",  # Replace w/ your WCS username\n",
    "#         password = \"WCS_PASSWORD\",  # Replace w/ your WCS password\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    documents, embeddings, client=client, by_text=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a15863ee",
   "metadata": {},
   "source": [
    "## Similarity search with score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64e03db8",
   "metadata": {},
   "source": [
    "Sometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result. \n",
    "The returned distance score is cosine distance. Therefore, a lower score is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "102105a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(page_content='text=Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. source=../../modules/state_of_the_union.txt'),\n",
       " 0.8153536875568572)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = db.similarity_search_with_score(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3487b",
   "metadata": {},
   "source": [
    "## Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c0fcc",
   "metadata": {},
   "source": [
    "Anything uploaded to Weaviate is automatically persistent into the database. You do not need to call any specific method or pass any parameters for this to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e2e75",
   "metadata": {},
   "source": [
    "## Retriever options\n",
    "\n",
    "This section goes over different options for how to use Weaviate as a retriever.\n",
    "\n",
    "### Maximal marginal relevance search (MMR)\n",
    "\n",
    "In addition to using similarity search in the retriever object, you can also use `mmr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7df7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='text=Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. source=../../modules/state_of_the_union.txt')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\")\n",
    "retriever.get_relevant_documents(query)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508016e8",
   "metadata": {},
   "source": [
    "## Use cases\n",
    "As the following example shows, LLMs don't have access to knowledge outside of their training data. Thus, vector stores come in handy to provide LLMs with additional context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5299b13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI language model, I don't have real-time information or the ability to browse the internet. Therefore, I cannot provide you with the most recent statements made by the president about Justice Breyer. However, it's worth noting that the president's opinions on Justice Breyer may vary depending on the specific context and time period. It would be best to refer to reliable news sources or official statements to get the most accurate and up-to-date information on this matter.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm.predict(\"What did the president say about Justice Breyer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7a6cb",
   "metadata": {},
   "source": [
    "### Question Answering with Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349acb9",
   "metadata": {},
   "source": [
    "This section goes over how to do question-answering with sources over an Index. It does this by using the `RetrievalQAWithSourcesChain`, which does the lookup of the documents from an Index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e824f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/langchain_core/prompts/prompt.py:205: DeprecationWarning: `input_variables' is deprecated and ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61209cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../modules/state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(state_of_the_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4abc3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Weaviate.from_texts(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    weaviate_url=WEAVIATE_URL,\n",
    "    by_text=False,\n",
    "    metadatas=[{\"source\": f\"{i}-pl\"} for i in range(len(texts))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7062393",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    OpenAI(temperature=0), chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05007f8a",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30f285a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../modules/state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(state_of_the_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08490f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Weaviate.from_texts(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    weaviate_url=WEAVIATE_URL,\n",
    "    by_text=False,\n",
    "    metadatas=[{\"source\": f\"{i}-pl\"} for i in range(len(texts))],\n",
    ")\n",
    "\n",
    "retriever = docsearch.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "499cb1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\\n\"))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28d95686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c697d0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The president thanked Justice Breyer for his service and dedication to the country.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What did the president say about Justice Breyer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
