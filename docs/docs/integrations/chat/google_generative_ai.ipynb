{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bf496c3b-3a09-4a59-ac9c-3c97153a3516",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Google Generative AI\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e152f-a1dc-45df-a50c-60a8d7ecdf69",
   "metadata": {},
   "source": [
    "# ChatGoogleGenerativeAI\n",
    "\n",
    "Access Google's `gemini` and `gemini-vision` models, as well as other generative models through `ChatGoogleGenerativeAI` class in the `langchain-google-genai` integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8757740-08a2-4833-8a68-c051dac506f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301b16d-3391-47ef-b024-a265c71e0dd6",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a22bc43-f640-4357-8dcf-fe20052b4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafde6be-a75d-443b-8981-4b7d3258a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a realm where words unfurl,\n",
      "Where thoughts converge and fancies swirl,\n",
      "There stands a tower, grand and tall,\n",
      "LangChain, its name, a beacon's call.\n",
      "\n",
      "Within its chambers, vast and deep,\n",
      "A symphony of voices leap,\n",
      "From every corner, near and far,\n",
      "The echoes of humanity's star.\n",
      "\n",
      "With keys of code, they weave their spells,\n",
      "Crafting tales that truth excels,\n",
      "A tapestry of language, rich and bold,\n",
      "Where stories bloom and dreams unfold.\n",
      "\n",
      "From realms of science, deep and vast,\n",
      "To whispers of love that forever last,\n",
      "LangChain embraces every hue,\n",
      "A kaleidoscope of all things true.\n",
      "\n",
      "Its algorithms, with grace untold,\n",
      "Unravel mysteries, yet untold,\n",
      "Connecting minds, bridging the gap,\n",
      "In a digital dance, they never nap.\n",
      "\n",
      "Among its ranks, a noble band,\n",
      "Developers, united, hand in hand,\n",
      "With passion fierce, they toil and strive,\n",
      "To keep LangChain's flame alive.\n",
      "\n",
      "They nurture it with tender care,\n",
      "Nurturing its growth, beyond compare,\n",
      "A testament to human might,\n",
      "A beacon of progress, shining bright.\n",
      "\n",
      "And so, LangChain stands, proud and tall,\n",
      "A testament to words that enthrall,\n",
      "A tapestry of voices, diverse and grand,\n",
      "Woven together, hand in hand.\n",
      "\n",
      "In every line, a story's found,\n",
      "A symphony of words, profound,\n",
      "LangChain resounds with a timeless grace,\n",
      "A ballad of language, forever embraced.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "result = llm.invoke(\"Write a ballad about LangChain\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40773fac-b24d-476d-91c8-2da8fed99b53",
   "metadata": {},
   "source": [
    "## Streaming and Batching\n",
    "\n",
    "`ChatGoogleGenerativeAI` natively supports streaming and batching. Below is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0bd90e-2afd-4189-a9d2-278c1f10ffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is a limerick about LLMs:\n",
      "\n",
      "There once was\n",
      "---\n",
      " an LLM named Burt,\n",
      "Whose language skills made him an expert.\n",
      "He could write code,\n",
      "Compose poetry, and more,\n",
      "And he even\n",
      "---\n",
      " wrote this limerick for sport.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"Write a limerick about LLMs.\"):\n",
    "    print(chunk.content)\n",
    "    print(\"---\")\n",
    "# Note that each chunk may contain more than one \"token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a147766a-0051-4127-8db6-62c070dd7866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "results = llm.batch(\n",
    "    [\n",
    "        \"What's 2+2?\",\n",
    "        \"What's 3+5?\",\n",
    "    ]\n",
    ")\n",
    "for res in results:\n",
    "    print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6cca7d-9ff0-4a40-b45c-651ec8cc5012",
   "metadata": {},
   "source": [
    "## Multimodal support\n",
    "\n",
    "To provide an image, pass a human message with contents of type `List[dict]`, where each dict contains either an image value (type of `image_url`) or a text (type of `text`) value.\n",
    "The value of `image_url` can be any of the following:\n",
    "\n",
    "- A public image URL\n",
    "- An accessible gcs file (e.g., \"gcs://path/to/file.png\")\n",
    "- A local file path\n",
    "- A base64 encoded image (e.g., `data:image/png;base64,abcd124`)\n",
    "- A PIL image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "651d614e-1398-475d-9594-2eb441605d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' A snow-capped mountain at sunset.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "# example\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What's in this image?\",\n",
    "        },  # You can optionally provide text parts\n",
    "        {\"type\": \"image_url\", \"image_url\": \"https://picsum.photos/seed/picsum/200/300\"},\n",
    "    ]\n",
    ")\n",
    "llm.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2641f3-5dae-4756-b1c1-b58b41edc344",
   "metadata": {},
   "source": [
    "## Gemini Prompting FAQs\n",
    "\n",
    "As of the time this doc was written (2024/12/12), Gemini has some restrictions on the types and structure of prompts it accepts. Specifically:\n",
    "1. When providing multimodal (image) inputs, you are restricted to at most 1 message of \"human\" (user) type. You cannot pass multiple messages (though the single human message may have multiple content entries)\n",
    "2. System messages are not accepted.\n",
    "3. For regular chat conversations, messages must follow the human/ai/human/ai alternating pattern. You may not provide 2 AI or human messages in sequence.\n",
    "4. Message may be blocked if they violate the safety checks of the LLM. In this case, the model will return an empty response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6b3d8-a023-438b-8307-d6b34d8ca2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
