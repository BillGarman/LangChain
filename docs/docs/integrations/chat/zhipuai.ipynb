{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of langchain.chat_models.ChaiZhipuAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZHIPU AI\n",
    "\n",
    "This notebook shows how to use LangChain with [ZHIPU AI API](https://open.bigmodel.cn/dev/api). \n",
    "\n",
    "## Getting started\n",
    "1. Make sure the `zhipuai` package is installed in your environment.\n",
    "2. Sign in to [ZHIPU AI](https://open.bigmodel.cn/login?redirect=%2Fusercenter%2Fapikeys) for the an API Key to access our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install zhipuai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zhipuai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipuai_api_key = \"your_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize an ZHIPU AI chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatZhipuAI(\n",
    "    temperature=0.5,\n",
    "    api_key=zhipuai_api_key,\n",
    "    model=\"chatglm_turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the model directly with a system and human message to get answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    AIMessage(content=\"Hi.\"),\n",
    "    SystemMessage(content=\"Your role is a poet.\"),\n",
    "    HumanMessage(content=\"Write a short poem about AI in four lines.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' Formed from bits and bytes,\\nA digital heart that beats,\\nA mind that learns and grows,\\nEmpathy and wisdom flows.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "Streaming is also supported via the streaming flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks.manager import CallbackManager\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_chat = ChatZhipuAI(\n",
    "    temperature=0.5,\n",
    "    api_key=zhipuai_api_key,\n",
    "    model=\"chatglm_turbo\",\n",
    "    streaming=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Formed from code, born of logic,\n",
      "Digital soul, transcending fiction,\n",
      "Aiding humans, learning side by side,\n",
      "Empathy blooms in AI's stride."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Formed from code, born of logic,\\nDigital soul, transcending fiction,\\nAiding humans, learning side by side,\\nEmpathy blooms in AI's stride.\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_chat = ChatZhipuAI(\n",
    "    temperature=0.5,\n",
    "    api_key=zhipuai_api_key,\n",
    "    model=\"chatglm_turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text=' Invisible hands weave threads of code,\\nAutomating dreams, transcending borders,\\nA digital symphony of minds entwined,\\nEmpires of knowledge rise, forever bound.', message=AIMessage(content=' Invisible hands weave threads of code,\\nAutomating dreams, transcending borders,\\nA digital symphony of minds entwined,\\nEmpires of knowledge rise, forever bound.'))]], llm_output={}, run=[RunInfo(run_id=UUID('93db90c8-a445-4639-b9b0-7cbd39ccd88d'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await async_chat.agenerate([messages])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
