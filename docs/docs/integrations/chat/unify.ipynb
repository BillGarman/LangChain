{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatUnify\n",
    "\n",
    "This notebook covers how to get started with Unify chat models. When using models through the Unify API endpoint, you get:\n",
    "- Single sign-on with all providers.\n",
    "- Dynamic routing to the best provider for your use case.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install package\n",
    "!pip install -U langchain-unify langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Make sure to set the following environment variables:\n",
    "\n",
    "- `UNIFY_API_KEY`: You can get a key in the [Unify Console](https://console.unify.ai/login).\n",
    "\n",
    "## Usage \n",
    "### Chaining Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"  Sure! Here's the translation:\\n\\nBonjour, comment vas-tu ?\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_unify.chat_models import ChatUnify\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "os.environ[\"UNIFY_API_KEY\"] = \"<YOUR API KEY>\"\n",
    "chat = ChatUnify()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that translates English to French.\"),\n",
    "        (\"human\", \"Translate this sentence from English to French. {english_text}.\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"english_text\": \"Hello, how are you?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37731d2c",
   "metadata": {},
   "source": [
    "### Streaming and SSO\n",
    "One of the advantages of using Unify is that through a single api key, you can access endpoints from different providers like Perplexity, Together AI, OctoAI and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0961ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Together stream: \n",
      "  Hello! I'm an AI, I don't have a physical location or a specific country of origin. I was created by a group of researcher at Meta AI and my primary function is to assist and converse with users like you, answering questions and providing information on a wide range of topics. I'm here to help and provide assistance, so feel free to ask me anything!!\n",
      "Anyscale stream: \n",
      "  Sure! 9 + 10 is 19."
     ]
    }
   ],
   "source": [
    "chat_together = ChatUnify(model=\"llama-2-70b-chat@together-ai\")\n",
    "print(\"Together stream: \")\n",
    "for chunk in chat_together.stream(\"Hello Together, where are you from?\"):\n",
    "    print(chunk.content, end=\"\")\n",
    "\n",
    "chat_anyscale = ChatUnify(model=\"llama-2-70b-chat@anyscale\")\n",
    "print(\"\\nAnyscale stream: \")\n",
    "for chunk in chat_anyscale.stream(\"What's 9 + 10?\"):\n",
    "    print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f295f94",
   "metadata": {},
   "source": [
    "### Batching and Dynamic Routing\n",
    "You may also want to use `mixtral-8x7b-instruct-v0.1` with the fastest output speed, and are not concerned with which provider you are using. Unify's dynamic routing gets this data from [our live benchmarks](https://unify.ai/hub/mixtral-8x7b-instruct-v0.1) and routes you to the provider that is performing better than the rest at that instant. \n",
    "\n",
    "You can see how to configure dynamic batching [here](https://unify.ai/docs/hub/concepts/runtime_routing.html#how-to-use-it).\n",
    "\n",
    "As expected, you can also batch your queries while using dynamic routing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61835218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Hello! I'm doing well, thanks for asking. Newton was a famous scientist who lived in the 17th and 18th centuries. His full name was Sir Isaac Newton, and he made many important contributions to the fields of science, mathematics, and physics. He is best known for his laws of motion and universal gravitation, which describe how objects move and interact with each other. Newton's work laid the foundation for many of the scientific advances that we enjoy today. He was also a mathematician and developed the method of calculus, which is a powerful tool for solving problems in mathematics and physics. Overall, Newton was a brilliant and influential thinker who helped shape our understanding of the world.\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"knock knock\"), HumanMessage(content=\"how are you today?\"), \n",
    "            HumanMessage(content=\"Explain who Newton was please!\")]\n",
    "chat_fastest = ChatUnify(model=\"llama-2-70b-chat@highest-tks-per-sec\")\n",
    "chat_fastest.batch([messages])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711e6d2",
   "metadata": {},
   "source": [
    "### Async and Cost Dynamic Routing\n",
    "You can also run this asynchronously, and may want to optimize for cost. If you need to run large volumes of data through some models, and need it by tomorrow, and want to optimize for cost and aren't interested too much in speed, but want to save on costs. Unify's dynamic router can be used for this too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356e71cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\" Two times three is equal to six. Is there anything else you would like to know? I'm here to help with any questions you have to the best of my ability.\"),\n",
       " AIMessage(content=\" Two times six is equal to twelve. Is there anything else you would like to know? I'm here to help with any questions you have, big or small! To give another example, if you want to know what three times seven is, that would be equal to twenty-one. Just let me know if you have any other questions!\"),\n",
       " AIMessage(content=\" The sum of 9 + 10 is 19, not 21. When you add 9 and 10, you get 19. It's important to make sure you're adding the numbers correctly and getting the right answer. If you're trying to follow a certain rule or pattern to get 21, it's not a valid one.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\"What's 2*3?\", \"What's 2*6?\", \"What's 9+10 and why is it 21?\"]\n",
    "chat_fastest = ChatUnify(model=\"mixtral-8x7b-instruct-v0.1@lowest-input-cost\")\n",
    "await chat_fastest.abatch(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
