# NVIDIA AI Playground

> [NVIDIA AI Playground](https://www.nvidia.com/en-us/research/ai-playground/) gives users easy access to hosted endpoints for generative AI models like Llama-2, Mistral, etc. This example demonstrates how to use LangChain to interact with supported AI Playground models.

## Setup and Authentication

- Create a free account at [NVIDIA GPU Cloud](https://catalog.ngc.nvidia.com/).
- Navigate to `Catalog > AI Foundation Models > (Model with API endpoint)`.
- Select `API` and generate the key `NVAPI_KEY`.

```python
# Imports and Authentication
from langchain.llms import NVAIPlayLLM
from langchain.llms.nv_aiplay import GeneralLLM, NVCRModel
import getpass, os

# Authentication with NVAPI Key
if os.environ.get("NVAPI_KEY", "").startswith("nvapi-"):
    print("Valid NVAPI_KEY in environment.")
else:
    nvapi_key = getpass.getpass("NVAPI Key: ")
    assert nvapi_key.startswith("nvapi-"), "Invalid key"
    os.environ["NVAPI_KEY"] = nvapi_key
```

## Using NVIDIA AI Playground Models

A selection of NVIDIA AI Playground models are supported directly in LangChain with familiar APIs. Lower than that, the `NVCRModel` class provides a lightweight low-assumptions interface for sending requests directly to the NVCF endpoints. 

The active models which are supported can be found [in NGC](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/). In addition, a selection of models can be retrieved from `langchain.<llms/chat_models>.nv_aiplay` which pull in default model options based on their use cases. 

Additional models will be supported as APIs become more stable and must-have model support can be implemented as necessary by leaning on `NVCRModel`'s request specification and general abstraction.

**The following may be useful examples to help you get started:**
- **[`NVAIPlayLLM` Model](/docs/integrations/llms/nv_aiplay).**
- **[`NVAIPlayChat` Model](/docs/integrations/chat/nv_aiplay).**
- **[`NVAIPlayEmbedding` Model for RAG Workflows](/docs/integrations/text_embeddings/nv_aiplay).**
