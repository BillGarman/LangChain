{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85fb2c03-ab88-4c8c-97e3-a7f2954555ab",
   "metadata": {},
   "source": [
    "# OpenAPI\n",
    "\n",
    "We can construct agents to consume arbitrary APIs, here APIs conformant to the `OpenAPI`/`Swagger` specification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389367b",
   "metadata": {},
   "source": [
    "## 1st example: hierarchical planning agent\n",
    "\n",
    "In this example, we'll consider an approach called hierarchical planning, common in robotics and appearing in recent works for LLMs X robotics. We'll see it's a viable approach to start working with a massive API spec AND to assist with user queries that require multiple steps against the API.\n",
    "\n",
    "The idea is simple: to get coherent agent behavior over long sequences behavior & to save on tokens, we'll separate concerns: a \"planner\" will be responsible for what endpoints to call and a \"controller\" will be responsible for how to call them.\n",
    "\n",
    "In the initial implementation, the planner is an LLM chain that has the name and a short description for each endpoint in context. The controller is an LLM agent that is instantiated with documentation for only the endpoints for a particular plan. There's a lot left to get this working very robustly :)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spotipy | tail -n 1\n",
    "!pip install keyring | tail -n 1\n",
    "!pip install tiktoken | tail -n 1\n",
    "!pip install langchain | tail -n 1\n",
    "!pip install openai | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keyring\n",
    "import getpass\n",
    "\n",
    "def get_or_set_credential(service_name, credential_name):\n",
    "    \"\"\"Fetch a credential from keyring or prompt the user to enter it.\"\"\"\n",
    "    credential = keyring.get_password(service_name, credential_name)\n",
    "    if not credential:\n",
    "        credential = getpass.getpass(f\"Enter {credential_name}: \")\n",
    "        keyring.set_password(service_name, credential_name, credential)\n",
    "    return credential\n",
    "\n",
    "#OpenAI\n",
    "## Define the common service name\n",
    "service_name = 'OpenAI'\n",
    "credentials = ['OPENAI_API_KEY']\n",
    "# Fetch or set each credential and set environment variables\n",
    "for cred in credentials:\n",
    "    os.environ[cred] = get_or_set_credential(service_name, cred)\n",
    "\n",
    "#SpotifyAPI\n",
    "## Define the common service name\n",
    "service_name = 'SpotifyAPI'\n",
    "credentials = ['SPOTIPY_CLIENT_ID', 'SPOTIPY_CLIENT_SECRET', 'SPOTIPY_REDIRECT_URI']\n",
    "# Fetch or set each credential and set environment variables\n",
    "for cred in credentials:\n",
    "    os.environ[cred] = get_or_set_credential(service_name, cred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ecf6e",
   "metadata": {},
   "source": [
    "### To start, let's collect some OpenAPI specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb15cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/openai/openai-openapi/master/openapi.yaml\n",
    "!mv openapi.yaml openai_openapi.yaml\n",
    "!wget https://www.klarna.com/us/shopping/public/openai/v0/api-docs\n",
    "!mv api-docs klarna_openapi.yaml\n",
    "!wget https://raw.githubusercontent.com/APIs-guru/openapi-directory/main/APIs/spotify.com/1.0.0/openapi.yaml\n",
    "!mv openapi.yaml spotify_openapi.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits.openapi.spec import reduce_openapi_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai_openapi.yaml\") as f:\n",
    "    raw_openai_api_spec = yaml.load(f, Loader=yaml.Loader)\n",
    "openai_api_spec = reduce_openapi_spec(raw_openai_api_spec)\n",
    "\n",
    "with open(\"klarna_openapi.yaml\") as f:\n",
    "    raw_klarna_api_spec = yaml.load(f, Loader=yaml.Loader)\n",
    "klarna_api_spec = reduce_openapi_spec(raw_klarna_api_spec)\n",
    "\n",
    "with open(\"spotify_openapi.yaml\") as f:\n",
    "    raw_spotify_api_spec = yaml.load(f, Loader=yaml.Loader)\n",
    "spotify_api_spec = reduce_openapi_spec(raw_spotify_api_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba833d49",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We'll work with the Spotify API as one of the examples of a somewhat complex API. There's a bit of auth-related setup to do if you want to replicate this.\n",
    "\n",
    "- You'll have to set up an application in the Spotify developer console, documented [here](https://developer.spotify.com/documentation/general/guides/authorization/), to get credentials: `CLIENT_ID`, `CLIENT_SECRET`, and `REDIRECT_URI`.\n",
    "- To get an access tokens (and keep them fresh), you can implement the oauth flows, or you can use `spotipy`. If you've set your Spotify creedentials as environment variables `SPOTIPY_CLIENT_ID`, `SPOTIPY_CLIENT_SECRET`, and `SPOTIPY_REDIRECT_URI`, you can use the helper functions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy.util as util\n",
    "from langchain.requests import RequestsWrapper\n",
    "\n",
    "\n",
    "def construct_spotify_auth_headers(raw_spec: dict):\n",
    "    scopes = list(\n",
    "        raw_spec[\"components\"][\"securitySchemes\"][\"oauth_2_0\"][\"flows\"][\n",
    "            \"authorizationCode\"\n",
    "        ][\"scopes\"].keys()\n",
    "    )\n",
    "    access_token = util.prompt_for_user_token(scope=\",\".join(scopes))\n",
    "    return {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "\n",
    "\n",
    "# Get API credentials.\n",
    "headers = construct_spotify_auth_headers(raw_spotify_api_spec)\n",
    "requests_wrapper = RequestsWrapper(headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76349780",
   "metadata": {},
   "source": [
    "### How big is this spec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = [\n",
    "    (route, operation)\n",
    "    for route, operations in raw_spotify_api_spec[\"paths\"].items()\n",
    "    for operation in operations\n",
    "    if operation in [\"get\", \"post\"]\n",
    "]\n",
    "len(endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb829190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "\n",
    "\n",
    "def count_tokens(s):\n",
    "    return len(enc.encode(s))\n",
    "\n",
    "\n",
    "count_tokens(yaml.dump(raw_spotify_api_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc4964e",
   "metadata": {},
   "source": [
    "### Let's see some examples!\n",
    "\n",
    "Starting with gpt-3.5-turbo. (May switch to gpt-4 when I'm feeling rich and require additional robustness.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38762cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_agent = planner.create_openapi_agent(spotify_api_spec, requests_wrapper, llm)\n",
    "user_query = (\n",
    "    \"make me a playlist with the first song from kind of blue. call it machine blues.\"\n",
    ")\n",
    "spotify_agent.run(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96184181",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"give me a song I'd like, make it blues-ey\"\n",
    "spotify_agent.run(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5317926",
   "metadata": {},
   "source": [
    "#### Try another API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\"}\n",
    "openai_requests_wrapper = RequestsWrapper(headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta!\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.25)\n",
    "openai_agent = planner.create_openapi_agent(\n",
    "    openai_api_spec, openai_requests_wrapper, llm\n",
    ")\n",
    "user_query = \"generate a short piece of advice\"\n",
    "openai_agent.run(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bc6ec",
   "metadata": {},
   "source": [
    "Takes awhile to get there!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461229e4",
   "metadata": {},
   "source": [
    "## 2nd example: \"json explorer\" agent\n",
    "\n",
    "Here's an agent that's not particularly practical, but neat! The agent has access to 2 toolkits. One comprises tools to interact with json: one tool to list the keys of a json object and another tool to get the value for a given key. The other toolkit comprises `requests` wrappers to send GET and POST requests. This agent consumes a lot calls to the language model, but does a surprisingly decent job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openapi_agent\n",
    "from langchain.agents.agent_toolkits import OpenAPIToolkit\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.tools.json.tool import JsonSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd1ba0-3937-4359-a41e-68605f0596a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"openai_openapi.yaml\") as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "json_spec = JsonSpec(dict_=data, max_value_length=4000)\n",
    "\n",
    "\n",
    "openapi_toolkit = OpenAPIToolkit.from_llm(\n",
    "    OpenAI(temperature=0), json_spec, openai_requests_wrapper, verbose=True\n",
    ")\n",
    "openapi_agent_executor = create_openapi_agent(\n",
    "    llm=OpenAI(temperature=0), toolkit=openapi_toolkit, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548db7f7-337b-4ba8-905c-e7fd58c01799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openapi_agent_executor.run(\n",
    "    \"Make a post request to openai /completions. The prompt should be 'tell me a joke.'\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
