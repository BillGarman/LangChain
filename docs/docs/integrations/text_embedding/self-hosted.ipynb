{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec4efda",
   "metadata": {},
   "source": [
    "# Self Hosted\n",
    "Let's load the `SelfHostedEmbeddings`, `SelfHostedHuggingFaceEmbeddings`, and `SelfHostedHuggingFaceInstructEmbeddings` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d338722a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import runhouse as rh\n",
    "from langchain_community.embeddings import (\n",
    "    SelfHostedEmbeddings,\n",
    "    SelfHostedHuggingFaceEmbeddings,\n",
    "    SelfHostedHuggingFaceInstructEmbeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146559e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For an on-demand A100 with GCP, Azure, or Lambda\n",
    "gpu = rh.cluster(name=\"langchain-rh-a10x\", instance_type=\"g5.4xlarge\")\n",
    "gpu.up_if_not()\n",
    "\n",
    "# For an on-demand A10G with AWS (no single A100s on AWS)\n",
    "# gpu = rh.cluster(name='rh-a10x', instance_type='g5.2xlarge', provider='aws')\n",
    "\n",
    "# For an existing cluster\n",
    "# gpu = rh.cluster(ips=['<ip of the cluster>'],\n",
    "#                  ssh_creds={'ssh_user': '...', 'ssh_private_key':'<path_to_key>'},\n",
    "#                  name='my-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c421e-7372-4e66-8623-285b96fb0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_env = rh.env(\n",
    "    name=\"embeddings_env\",\n",
    "    reqs=[\n",
    "        \"transformers\",\n",
    "        \"torch\",\n",
    "        \"accelerate\",\n",
    "        \"huggingface-hub\",\n",
    "        \"sentence_transformers\",\n",
    "    ],\n",
    "    secrets=[\"huggingface\"],  # need for downloading models from huggingface\n",
    ").to(system=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1173b-cb05-4dec-b1b6-c5be98ece4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu.run(commands=[\"pip install langchain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1230f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:10.464618 | Calling file_20240324_162817.exists_in_system\n",
      "INFO | 2024-03-24 14:32:11.620303 | Time to call file_20240324_162817.exists_in_system: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:11.623120 | Calling file_20240324_162817.resolved_state\n",
      "INFO | 2024-03-24 14:32:12.780336 | Time to call file_20240324_162817.resolved_state: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:12.782881 | Calling huggingface._write_to_file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mSecrets already exist in .cache/huggingface/token.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:13.936439 | Time to call huggingface._write_to_file: 1.15 seconds\n",
      "INFO | 2024-03-24 14:32:14.288792 | Calling embeddings_env.install\n",
      "INFO | 2024-03-24 14:32:15.546474 | Time to call embeddings_env.install: 1.26 seconds\n",
      "INFO | 2024-03-24 14:32:15.560158 | Sending module ModelPipeline to langchain-rh-a10x\n",
      "INFO | 2024-03-24 14:32:16.029876 | Calling ModelPipeline._remote_init\n",
      "INFO | 2024-03-24 14:32:17.192264 | Time to call ModelPipeline._remote_init: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:17.200112 | Calling file_20240324_163213.exists_in_system\n",
      "INFO | 2024-03-24 14:32:18.358517 | Time to call file_20240324_163213.exists_in_system: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:18.363241 | Calling file_20240324_163213.resolved_state\n",
      "INFO | 2024-03-24 14:32:19.523382 | Time to call file_20240324_163213.resolved_state: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:19.533506 | Calling ModelPipeline.load_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mLoad pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "\u001b[0m\u001b[36mUse pytorch device_name: cuda\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:32.750978 | Time to call ModelPipeline.load_model: 13.22 seconds\n",
      "INFO | 2024-03-24 14:32:32.930918 | Calling file_20240324_162817.exists_in_system\n",
      "INFO | 2024-03-24 14:32:34.087356 | Time to call file_20240324_162817.exists_in_system: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:34.092653 | Calling file_20240324_162817.resolved_state\n",
      "INFO | 2024-03-24 14:32:35.309964 | Time to call file_20240324_162817.resolved_state: 1.22 seconds\n",
      "INFO | 2024-03-24 14:32:35.321040 | Calling huggingface._write_to_file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mSecrets already exist in .cache/huggingface/token.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:36.542381 | Time to call huggingface._write_to_file: 1.22 seconds\n",
      "INFO | 2024-03-24 14:32:36.884326 | Calling embeddings_env.install\n",
      "INFO | 2024-03-24 14:32:38.044046 | Time to call embeddings_env.install: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:38.058226 | Sending module TextModelEmbedding to langchain-rh-a10x\n",
      "INFO | 2024-03-24 14:32:38.413637 | Calling TextModelEmbedding._remote_init\n",
      "INFO | 2024-03-24 14:32:39.576731 | Time to call TextModelEmbedding._remote_init: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:39.582776 | Calling TextModelEmbedding.load_embedding_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mLoad pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "\u001b[0m\u001b[36mUse pytorch device_name: cuda\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:41.865010 | Time to call TextModelEmbedding.load_embedding_model: 2.28 seconds\n"
     ]
    }
   ],
   "source": [
    "embeddings = SelfHostedHuggingFaceEmbeddings(hardware=gpu, env=embedding_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2684e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a test document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dc5e606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:41.888804 | Calling TextModelEmbedding.embed_documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:43.055540 | Time to call TextModelEmbedding.embed_documents: 1.17 seconds\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9cc54",
   "metadata": {},
   "source": [
    "And similarly for SelfHostedHuggingFaceInstructEmbeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a17ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:43.231198 | Calling file_20240324_162817.exists_in_system\n",
      "INFO | 2024-03-24 14:32:44.390289 | Time to call file_20240324_162817.exists_in_system: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:44.393713 | Calling file_20240324_162817.resolved_state\n",
      "INFO | 2024-03-24 14:32:45.652348 | Time to call file_20240324_162817.resolved_state: 1.26 seconds\n",
      "INFO | 2024-03-24 14:32:45.663049 | Calling huggingface._write_to_file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mSecrets already exist in .cache/huggingface/token.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:32:46.825030 | Time to call huggingface._write_to_file: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:47.167111 | Calling embeddings_env.install\n",
      "INFO | 2024-03-24 14:32:48.326555 | Time to call embeddings_env.install: 1.16 seconds\n",
      "INFO | 2024-03-24 14:32:48.338368 | Sending module ModelPipeline to langchain-rh-a10x\n",
      "INFO | 2024-03-24 14:32:48.694761 | Calling ModelPipeline._remote_init\n",
      "INFO | 2024-03-24 14:32:49.953124 | Time to call ModelPipeline._remote_init: 1.26 seconds\n",
      "INFO | 2024-03-24 14:32:49.959748 | Calling file_20240324_163246.exists_in_system\n",
      "INFO | 2024-03-24 14:32:51.183328 | Time to call file_20240324_163246.exists_in_system: 1.22 seconds\n",
      "INFO | 2024-03-24 14:32:51.186637 | Calling file_20240324_163246.resolved_state\n",
      "INFO | 2024-03-24 14:32:52.413447 | Time to call file_20240324_163246.resolved_state: 1.23 seconds\n",
      "INFO | 2024-03-24 14:32:52.419721 | Calling ModelPipeline.load_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mLoad pretrained SentenceTransformer: hkunlp/instructor-large\n",
      "\u001b[0m\u001b[36mUse pytorch device_name: cuda\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:33:03.599422 | Time to call ModelPipeline.load_model: 11.18 seconds\n",
      "INFO | 2024-03-24 14:33:03.775977 | Calling file_20240324_162817.exists_in_system\n",
      "INFO | 2024-03-24 14:33:05.005037 | Time to call file_20240324_162817.exists_in_system: 1.23 seconds\n",
      "INFO | 2024-03-24 14:33:05.011337 | Calling file_20240324_162817.resolved_state\n",
      "INFO | 2024-03-24 14:33:06.264976 | Time to call file_20240324_162817.resolved_state: 1.25 seconds\n",
      "INFO | 2024-03-24 14:33:06.278060 | Calling huggingface._write_to_file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mSecrets already exist in .cache/huggingface/token.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:33:07.441389 | Time to call huggingface._write_to_file: 1.16 seconds\n",
      "INFO | 2024-03-24 14:33:07.784795 | Calling embeddings_env.install\n",
      "INFO | 2024-03-24 14:33:09.000101 | Time to call embeddings_env.install: 1.22 seconds\n",
      "INFO | 2024-03-24 14:33:09.012592 | Sending module TextModelEmbedding to langchain-rh-a10x\n",
      "INFO | 2024-03-24 14:33:09.410513 | Calling TextModelEmbedding._remote_init\n",
      "INFO | 2024-03-24 14:33:10.567109 | Time to call TextModelEmbedding._remote_init: 1.16 seconds\n",
      "INFO | 2024-03-24 14:33:10.574694 | Calling TextModelEmbedding.load_embedding_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mLoad pretrained SentenceTransformer: hkunlp/instructor-large\n",
      "\u001b[0m\u001b[36mUse pytorch device_name: cuda\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:33:12.741675 | Time to call TextModelEmbedding.load_embedding_model: 2.17 seconds\n"
     ]
    }
   ],
   "source": [
    "embeddings = SelfHostedHuggingFaceInstructEmbeddings(hardware=gpu, env=embedding_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaad49f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:33:12.757713 | Calling TextModelEmbedding.embed_documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO | 2024-03-24 14:33:14.025257 | Time to call TextModelEmbedding.embed_documents: 1.27 seconds\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680a179-e123-44bd-8b1b-f39a886090b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7377c2ccc78bc62c2683122d48c8cd1fb85a53850a1b1fc29736ed39852c9885"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
