# Tiktoken

>[tiktoken](https://github.com/openai/tiktoken) is a fast `BPE` tokeniser created by `OpenAI`.


1. How the text is split: by `tiktoken` tokens
2. How the chunk size is measured: by `tiktoken` tokens

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! Instead, edit the notebook w/the location & name as this file. -->


```python
#!pip install tiktoken
```


```python
# This is a long document we can split up.
with open('../../../state_of_the_union.txt') as f:
    state_of_the_union = f.read()
```


```python
from langchain.text_splitter import TokenTextSplitter
```


```python
text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)
```


```python
texts = text_splitter.split_text(state_of_the_union)
print(texts[0])
```

<CodeOutputBlock lang="python">

```
    Madam Speaker, Madam Vice President, our
```

</CodeOutputBlock>
