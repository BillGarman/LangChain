{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5715368",
   "metadata": {},
   "source": [
    "# Tracking token usage\n",
    "\n",
    "This notebook goes over how to track your token usage for specific calls. It is currently only implemented for the OpenAI API and AWS Bedrock."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## OpenAI\n",
    "\n",
    "Let's first look at an extremely simple example of tracking token usage for a single LLM call.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bed332b518694574"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9455db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c55cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31667d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 24\n",
      "\tPrompt Tokens: 11\n",
      "\tCompletion Tokens: 13\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0011099999999999999\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a joke\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab6d27",
   "metadata": {},
   "source": [
    "Anything inside the context manager will get tracked. Here's an example of using it to track multiple calls in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09420f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me a joke\")\n",
    "    result2 = llm.invoke(\"Tell me a joke\")\n",
    "    print(cb.total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8186e7b",
   "metadata": {},
   "source": [
    "If a chain or agent with multiple steps in it is used, it will track all those steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d1125c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f98c536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `Search` with `Olivia Wilde's current boyfriend`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m['Things are looking golden for Olivia Wilde, as the actress has jumped back into the dating pool following her split from Harry Styles — read ...', \"“I did not want service to take place at the home of Olivia's current partner because Otis and Daisy might be present,” Sudeikis wrote in his ...\", \"February 2021: Olivia Wilde praises Harry Styles' modesty. One month after the duo made headlines with their budding romance, Wilde gave her new beau major ...\", 'An insider revealed to People that the new couple had been dating for some time. \"They were in Montecito, California this weekend for a wedding, ...', 'A source told People last year that Wilde and Styles were still friends despite deciding to take a break. \"He\\'s still touring and is now going ...', \"... love life. “He's your typical average Joe.” The source adds, “She's not giving too much away right now and wants to keep the relationship ...\", \"Multiple sources said the two were “taking a break” from dating because of distance and different priorities. “He's still touring and is now ...\", 'Comments. Filed under. celebrity couples · celebrity dating · harry styles · jason sudeikis · olivia wilde ... Now Holds A Darker MeaningNYPost.', '... dating during filming. The 39-year-old did however look very cosy with the comedian, although his relationship status is unknown. Olivia ...']\u001B[0m\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `Search` with `Harry Styles current age`\n",
      "responded: Olivia Wilde's current boyfriend is Harry Styles. Let me find out his age for you.\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m29 years\u001B[0m\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `Calculator` with `29 ^ 0.23`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[33;1m\u001B[1;3mAnswer: 2.169459462491557\u001B[0m\u001B[32;1m\u001B[1;3mHarry Styles' current age (29 years) raised to the 0.23 power is approximately 2.17.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Total Tokens: 1929\n",
      "Prompt Tokens: 1799\n",
      "Completion Tokens: 130\n",
      "Total Cost (USD): $0.06176999999999999\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = agent.run(\n",
    "        \"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\"\n",
    "    )\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bedrock"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e05f351842da43b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_bedrock_token_count_callback\n",
    "from langchain.llms import Bedrock\n",
    "import anthropic"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5b3ca852abec060"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2:1\",\n",
    "    region_name=\"us-east-1\",\n",
    "    model_kwargs={\"temperature\": 0.0},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7f7a1ae5039b413"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The square root of 4 is 2.\n",
      " The square root of 4 is 2.\n",
      "58 34 24\n"
     ]
    }
   ],
   "source": [
    "with get_bedrock_token_count_callback() as cb:\n",
    "    text = \"\\n\\nHuman: What is the square root of 4?\\n\\nAssistant: \"\n",
    "    answer = llm(text)\n",
    "    print(answer)  # check if invocations return same response\n",
    "    answer = llm(text)\n",
    "    print(answer)  # check if invocations return same response\n",
    "\n",
    "    total_tokens = cb.total_tokens\n",
    "    print(cb.total_tokens, cb.prompt_tokens, cb.completion_tokens)\n",
    "    client = anthropic.Anthropic()  # check token count with Anthropic's own token counter\n",
    "    assert cb.prompt_tokens == client.count_tokens(text) * 2, \"Input token count does not match\"\n",
    "    \n",
    "    # to check total token count we need to include the generation stop sequence that is not included in answers\n",
    "    total_token_count = client.count_tokens(text + \"The square root of 4 is 2.\" + \"\\n\\nHuman: \") * 2\n",
    "    assert cb.total_tokens == total_token_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50c7e207973858f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
