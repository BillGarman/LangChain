{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9af580",
   "metadata": {},
   "source": [
    "# Custom callback handlers\n",
    "\n",
    "To create a custom callback handler we need to determine the [event(s)](/modules/callbacks/) we want our callback handler to handle as well as what we want our callback handler to do when the event is triggered. Then all we need to do is attach the callback handler to the object either as a constructer callback or a request callback (see [callback types](/modules/callbacks/))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d5e5f",
   "metadata": {},
   "source": [
    "In the example below, we'll implement streaming with a custom handler.\n",
    "\n",
    "In our custom callback handler `MyCustomHandler`, we implement the `on_llm_new_token` to print the token we have just received. We then attach our custom handler to the model object as a constructor callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "class MyCustomHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"My streaming handler, token: {token}\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {animal}\")\n",
    "\n",
    "# To enable streaming, we pass in `streaming=True` to the ChatModel constructor\n",
    "# Additionally, we pass in our custom handler as a list to the callbacks parameter\n",
    "model = OpenAI(streaming=True, callbacks=[MyCustomHandler()])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"animal\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c058d7",
   "metadata": {},
   "source": [
    "Example output -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "My streaming handler, token: \n",
    "\n",
    "My streaming handler, token: Why\n",
    "My streaming handler, token:  did\n",
    "My streaming handler, token:  the\n",
    "My streaming handler, token:  bear\n",
    "My streaming handler, token:  refuse\n",
    "My streaming handler, token:  to\n",
    "My streaming handler, token:  wear\n",
    "My streaming handler, token:  pants\n",
    "My streaming handler, token: ?\n",
    "\n",
    "\n",
    "My streaming handler, token: Because\n",
    "My streaming handler, token:  he wanted\n",
    "My streaming handler, token:  to\n",
    "My streaming handler, token:  show off his bear legs\n",
    "My streaming handler, token: !\n",
    "My streaming handler, token:\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
