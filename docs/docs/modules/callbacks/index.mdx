---
sidebar_position: 5
sidebar_class_name: hidden
---
# Callbacks

:::info
Head to [Integrations](/docs/integrations/callbacks/) for documentation on built-in callbacks integrations with 3rd-party tools.
:::

LangChain provides a system of callbacks that provides a set of hooks to allow you entry into various stages of your application. This is useful for logging, tracing, debugging and monitoring.

## Concepts

Concepts include the hooks or events that provide entry to the application and the
callbacks handler object which subscribes to one or more of these events.
We also discuss the types of callbacks and tags, useful for filtering of specific flows.

### Events

| Event Name       | Event Trigger                   | Associated Method     |
|------------------|---------------------------------|-----------------------|
| LLM start        | When a llm starts               | `on_llm_start`        |
| LLM new token    | When a llm receives a new token | `on_llm_new_token`    |
| LLM ends         | When a llm ends                 | `on_llm_end`          |
| LLM errors       | When a llm errors               | `on_llm_error`        |
| Chat model start | When a chat model starts        | `on_chat_model_start` |
| Chain start      | When a chain starts running     | `on_chain_start`      |
| Chain end        | When a chain ends               | `on_chain_end`        |
| Chain error      | When a chain errors             | `on_chain_error`      |
| Tool start       | When a tool starts running      | `on_tool_start`       |
| Tool end         | When a tool ends                | `on_tool_end`         |
| Tool error       | When a tool errors              | `on_tool_error`       |
| Agent action     | When an agent takes an action   | `on_agent_action`     |
| Agent finish     | When an agent ends              | `on_agent_finish`     |
| Retriever start  | When a retriever starts         | `on_retriever_start`  |
| Retriever end    | When a retriever ends           | `on_retriever_end`    |
| Retriever error  | When a retriever errors         | `on_retriever_error`  |
| Text             | When arbitrary text is run      | `on_text`             |
| Retry            | When a retry event is run       | `on_retry`            |


### Callback Handlers

Callback handlers are objects that implement the associated method (see table above) for each event you are interested in. Handlers register for these events using the `callbacks` argument available throughout the API. When the event is triggered, the callbacks system will call the appropriate method on every registered handler.


### Types

The callbacks are available on most objects throughout the API (Models, Tools, Agents, etc.) in two different places:

- **Request time callbacks**: Passed at the time of the request in addition to the input data.
    Available on all standard LCEL methods. These callbacks are INHERITED by all children
    of the object they are defined on. For example, `chain.invoke({"number": 25}, {"callbacks": [handler]})`.
- **Constructor callbacks**: `chain = TheNameOfSomeChain(callbacks=[handler])`. These callbacks
are passed as arguments to the constructor of the object. The callbacks are SCOPED
to the object they are defined on, and are not inherited by any children of the object.

:::warning
Constructor callbacks are scoped only to the object they are defined on. You should
generally avoid using them!

While they can be useful if you don't want to add logic to filter callbacks triggered
by children of the object, most of the time they end up being more confusing than helpful.
:::

### Tags

All standard LCEL methods accept a `RunnableConfig` object as a 2nd argument.

The config object includes a standard field called "tags".

You would declare it like this:

```python
chain.invoke({"number": 25}, {"tags": ["tag1", "tag2"]})
```

This is useful for filtering your logs, e.g. if you want to log all requests made to a specific chain, you can add a tag, and then filter your logs by that tag. You can pass tags to both constructor and request callbacks.

These tags are then passed to the tags argument of the "start" callback methods, ie. `on_llm_start`, `on_chat_model_start`, `on_chain_start`,  `on_tool_start` and `on_retriever_start`.

## Quick start

Let us understand what callbacks can do by examining one of the built-in callback handlers
provided by LangChain called `ConsoleCallbackHandler`.

```python
from langchain_core.tracers.stdout import ConsoleCallbackHandler
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

prompt = PromptTemplate.from_template("1 + {number} = ")
model = ChatOpenAI()
chain = prompt | model
chain.invoke({"number": 25}, {'callbacks': [ConsoleCallbackHandler()]})
```

<details> <summary>Console output</summary>


<CodeOutputBlock lang="python">

```
[chain/start] [1:chain:RunnableSequence] Entering Chain run with input:
{
    "number": 25
}
[chain/start] [1:chain:RunnableSequence > 2:prompt:PromptTemplate] Entering Prompt run with input:
{
    "number": 25
}
[chain/end] [1:chain:RunnableSequence > 2:prompt:PromptTemplate] [0ms] Exiting Prompt run with output:
[outputs]
[llm/start] [1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:
{
    "prompts": [
    "Human: 1 + 25 ="
    ]
}
[llm/end] [1:chain:RunnableSequence > 3:llm:ChatOpenAI] [371ms] Exiting LLM run with output:
{
    "generations": [
    [
{
    "text": "26",
    "generation_info": {
    "finish_reason": "stop",
    "logprobs": null
},
    "type": "ChatGeneration",
    "message": {
    "lc": 1,
    "type": "constructor",
    "id": [
    "langchain",
    "schema",
    "messages",
    "AIMessage"
    ],
    "kwargs": {
    "content": "26",
    "additional_kwargs": {},
    "name": null,
    "id": "run-a74e2a93-7269-4cd7-9008-e2518841b4f6-0",
    "tool_calls": [],
    "invalid_tool_calls": []
}
}
}
    ]
    ],
    "llm_output": {
    "token_usage": {
    "completion_tokens": 1,
    "prompt_tokens": 13,
    "total_tokens": 14
},
    "model_name": "gpt-3.5-turbo",
    "system_fingerprint": "fp_c2295e73ad"
},
    "run": null
}
[chain/end] [1:chain:RunnableSequence] [372ms] Exiting Chain run with output:
[outputs]
AIMessage(content='26', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 13, 'total_tokens': 14}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-a74e2a93-7269-4cd7-9008-e2518841b4f6-0')

```

</CodeOutputBlock>

</details>

:::hint
`ConsoleCallbackHandler` is the callback handler that's used by LangChain
when the debug flag is set to True!

Doing the following:

```python
from langchain_core.globals import set_debug
set_debug(True)
```

will automatically add the `ConsoleCallbackHandler` to all chains that are run!
:::


We can also pass the callback handler via the constructor (do we recommend against doing that in general).

```python
from langchain_core.prompts import PromptTemplate
from langchain_core.tracers.stdout import ConsoleCallbackHandler
from langchain_openai import ChatOpenAI

prompt = PromptTemplate.from_template("1 + {number} = ")
model = ChatOpenAI(callbacks=[ConsoleCallbackHandler()])
chain = prompt | model
chain.invoke({"number": 25})
```


In the above examples, the prints are due to the `StdOutCallbackHandler` implementing the `on_chain_start`, `on_chain_end`, `on_llm_start` and `on_llm_end` methods to provide helpful debugging information.

## More topics

This was a quick introduction to callbacks in LangChain, but there is a lot more to explore.

**Callbacks integration with 3rd-party tools:** For documentation on built-in callbacks integrations with 3rd-party tools, see [this page](https://python.langchain.com/docs/integrations/callbacks/)

**Async callbacks:** If you are planning to use the async API, it is recommended to use the `AsyncCallbackHandler `, [this page](https://python.langchain.com/docs/modules/callbacks/async_callbacks/)

**Logging to a file:** LangChain provides a built-in callback handler to log events to a file, see [this page](https://python.langchain.com/docs/modules/callbacks/filecallbackhandler/)

**Multiple callback handlers:** We saw a simple example of the difference between the two types of callback handlers. For a more elaborate example with agents see [this page](https://python.langchain.com/docs/modules/callbacks/multiple_callbacks/) 

**Custom callback handlers:** Although built-in handlers are useful, it’s highly likely that you’ll have to define your own handlers. See [this guide](https://python.langchain.com/docs/modules/callbacks/custom_callbacks/) for instructions on how to do so.

**Token counting:** Token counting (for Open AI models) is accomplished through the the context manager `get_openai_callback`, that uses a callback handler under the hood, see [this page](https://python.langchain.com/docs/modules/callbacks/token_counting/)
