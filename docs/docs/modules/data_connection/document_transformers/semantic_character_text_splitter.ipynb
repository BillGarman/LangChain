{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b2f74d-9446-4fcf-bb4b-242e6b6f321a",
   "metadata": {},
   "source": [
    "# Split by Number of Characters\n",
    "[These notes](https://pypi.org/project/semantic-text-splitter/) from Pinecone provide some useful knowledge about this how it works.\n",
    "This is the simplest method. This splits based on characters (by default \"\\n\\n\") and measure chunk length by number of characters.\n",
    "\n",
    "Large language models (LLMs) can be used for many tasks, but often have a limited context size that can be smaller than documents you might want to use. To use documents of larger length, you often have to split your text into chunks to fit within this context size.\n",
    "\n",
    "This crate provides methods for splitting longer pieces of text into smaller chunks, aiming to maximize a desired chunk size, but still splitting at semantically sensible boundaries whenever possible.\n",
    "\n",
    "1. max_characters: Maximum number of characters in a chunk.\n",
    "2. trim_chunks: It can set, the splitter not trim whitespace for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8698ce-44b2-4944-b9a9-254344b537af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "313fb032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a long document we can split up.\n",
    "with open(\"../../state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a88ff70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import SemanticCharacterTextSplitter\n",
    "\n",
    "text_splitter = SemanticCharacterTextSplitter(\n",
    "    max_characters=200,\n",
    "    trim_chunks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295ec095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.'\n",
      "page_content='Last year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans.'\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.create_documents([state_of_the_union])\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1affda60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.',\n",
       " 'Last year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(state_of_the_union)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d7bf2-69b4-449a-849e-490aa935e443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
