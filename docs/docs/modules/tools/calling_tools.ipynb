{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d04afd-a425-4c92-9c66-fab0fc5ec6ce",
   "metadata": {},
   "source": [
    "# Calling Tools\n",
    "\n",
    "Tool calling is a common feature of LLM applications. A [tool call](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.tool.ToolCall.html#langchain_core.messages.tool.ToolCall) represents a call to a specific tool, and includes a name, arguments dict, and (optionally) an identifier. The arguments dict is structured `{argument_name: argument_value}`.\n",
    "\n",
    "Many LLM providers, including Anthropic, Cohere, Google, Mistral, OpenAI, and others, support variants of a tool calling feature. These features typically allow requests to the LLM to include available tools and their schemas, and for responses to include calls to these tools. For instance, given a search engine tool, an LLM might handle a query by first issuing a call to the search engine. The system calling the LLM can receive the tool call, execute it, and return the output to the LLM to inform its response. LangChain includes a suite of [built-in tools](https://python.langchain.com/docs/integrations/tools/) and supports several methods for defining your own [custom tools](docs/modules/tools/custom_tools).\n",
    "\n",
    "Providers adopt different conventions for formatting tool schemas and tool calls. For instance, Anthropic returns tool calls as parsed structures within a larger content block:\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"text\": \"<thinking>\\nI should use a tool.\\n</thinking>\",\n",
    "    \"type\": \"text\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"id_value\",\n",
    "    \"input\": {\"arg_name\": \"arg_value\"},\n",
    "    \"name\": \"tool_name\",\n",
    "    \"type\": \"tool_use\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "whereas OpenAI separates tool calls into a distinct parameter, with arguments as JSON strings:\n",
    "```\n",
    "{\n",
    "  \"tool_calls\": [\n",
    "    {\n",
    "      \"id\": \"id_value\",\n",
    "      \"function\": {\n",
    "        \"arguments\": '{\"arg_name\": \"arg_value\"}',\n",
    "        \"name\": \"tool_name\"\n",
    "      },\n",
    "      \"type\": \"function\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "LangChain implements standard interfaces for defining tools, passing them to LLMs, and representing tool calls.\n",
    "\n",
    "## Passing tools to LLMs\n",
    "\n",
    "Chat models supporting tool calling features implement a `.bind_tools` method, which receives a list of LangChain [tool objects](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool) and binds them to the chat model in its expected format. Subsequent invocations of the chat model will include tool schemas in its calls to the LLM.\n",
    "\n",
    "For example, if we define some custom tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf137e1-905a-4477-941e-abcdfbe63e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "\n",
    "tools = [get_word_length, magic_function]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb2a5f-ba80-41b0-8876-3b29c61ed7ea",
   "metadata": {},
   "source": [
    "we can bind them to chat models as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52908d14-b5af-4de9-9b7e-0139b707e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_anthropic = ChatAnthropic(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    temperature=0,\n",
    ").bind_tools(tools)\n",
    "\n",
    "llm_openai = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo-2024-04-09\",\n",
    "    temperature=0,\n",
    ").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38715940-55bc-4123-a7fb-bd875550ecdb",
   "metadata": {},
   "source": [
    "## Tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcca9ef-e697-4951-b13b-b1dd274144ca",
   "metadata": {},
   "source": [
    "If tool calls are included in a LLM response, they are attached to the corresponding [message](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage) or [message chunk](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) as a list of [tool call](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.tool.ToolCall.html#langchain_core.messages.tool.ToolCall) objects in the `.tool_calls` attribute. A `ToolCall` is a typed dict that includes a tool name, dict of argument values, and (optionally) an identifier. Messages with no tool calls default to an empty list for this attribute.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3c5344-1d07-4d59-992c-2d8f80c9e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"how long is the word chrysanthemum? \"\n",
    "    \"Also, what is the value of magic_function(3)?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87fef1b3-a32d-4d2b-a731-f05a48291b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_word_length',\n",
       "  'args': {'word': 'chrysanthemum'},\n",
       "  'id': 'toolu_01J2Ph5ruNo4vAYoSg4mf8t8'},\n",
       " {'name': 'magic_function',\n",
       "  'args': {'input': 3},\n",
       "  'id': 'toolu_01XkZpimZsjZtuEVRnM8JDEt'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_anthropic.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d14fc42-3394-4513-9bfa-1fb4bd96d176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_word_length',\n",
       "  'args': {'word': 'chrysanthemum'},\n",
       "  'id': 'call_tdd4aenF3EyCRl9t61HH6J56'},\n",
       " {'name': 'magic_function',\n",
       "  'args': {'input': 3},\n",
       "  'id': 'call_yiao3eVlh6TFB8vZPDydP5ev'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_openai.invoke(query).tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8385261-0b0a-41c3-bcc7-6debc7a60fd4",
   "metadata": {},
   "source": [
    "The `.tool_calls` attribute should contain valid tool calls. Note that on occasion, model providers may output malformed tool calls (e.g., arguments that are not valid JSON). When parsing fails in these cases, instances of [InvalidToolCall](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.tool.InvalidToolCall.html#langchain_core.messages.tool.InvalidToolCall) are populated in the `.invalid_tool_calls` attribute. An `InvalidToolCall` can have a name, string arguments, identifier, and error message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26824fc1-2517-4d86-b0e0-a8211e038a8d",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "When tools are called in a streaming context, [message chunks](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) will be populated with [tool call chunk](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.tool.ToolCallChunk.html#langchain_core.messages.tool.ToolCallChunk) objects in a list via the `.tool_call_chunks` attribute. A `ToolCallChunk` includes optional string fields for the tool `name`, `args`, and `id`, and includes an optional integer field `index` that can be used to join chunks together. Fields are optional because portions of a tool call may be streamed across different chunks (e.g., a chunk that includes a substring of the arguments may have null values for the tool name and id).\n",
    "\n",
    "Because message chunks inherit from their parent message class, an [AIMessageChunk](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) with tool call chunks will also include `.tool_calls` and `.invalid_tool_calls` fields. These fields are parsed best-effort from the message's tool call chunks.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a96016c-6a73-4649-812a-3ee64a6d7da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'get_word_length', 'args': '', 'id': 'call_D53nh457zwyII8EhMu5ELw72', 'index': 0}]\n",
      "[{'name': None, 'args': '{\"wo', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': 'rd\": ', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': '\"chrys', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': 'anth', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': 'emum\"', 'id': None, 'index': 0}]\n",
      "[{'name': None, 'args': '}', 'id': None, 'index': 0}]\n",
      "[{'name': 'magic_function', 'args': '', 'id': 'call_xCuQPAUsMA47wCQez18QGxIn', 'index': 1}]\n",
      "[{'name': None, 'args': '{\"in', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': 'put\":', 'id': None, 'index': 1}]\n",
      "[{'name': None, 'args': ' 3}', 'id': None, 'index': 1}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "async for chunk in llm_openai.astream(query):\n",
    "    print(chunk.tool_call_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac9e0b8-46b2-4277-a05a-396164f58e57",
   "metadata": {},
   "source": [
    "Note that adding message chunks will merge their corresponding tool call chunks. This is the principle by which LangChain's various [tool output parsers](https://python.langchain.com/docs/modules/model_io/output_parsers/types/openai_tools/) support streaming.\n",
    "\n",
    "For example, below we accumulate tool call chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e6a190-bed6-44b9-8894-83e447a80ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'get_word_length', 'args': '', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}]\n",
      "[{'name': 'get_word_length', 'args': '{\"wo', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": ', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrys', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanth', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanthemum\"', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanthemum\"}', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanthemum\"}', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}, {'name': 'magic_function', 'args': '', 'id': 'call_yiao3eVlh6TFB8vZPDydP5ev', 'index': 1}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanthemum\"}', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}, {'name': 'magic_function', 'args': '{\"in', 'id': 'call_yiao3eVlh6TFB8vZPDydP5ev', 'index': 1}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanthemum\"}', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}, {'name': 'magic_function', 'args': '{\"input\":', 'id': 'call_yiao3eVlh6TFB8vZPDydP5ev', 'index': 1}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanthemum\"}', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}, {'name': 'magic_function', 'args': '{\"input\": 3}', 'id': 'call_yiao3eVlh6TFB8vZPDydP5ev', 'index': 1}]\n",
      "[{'name': 'get_word_length', 'args': '{\"word\": \"chrysanthemum\"}', 'id': 'call_tdd4aenF3EyCRl9t61HH6J56', 'index': 0}, {'name': 'magic_function', 'args': '{\"input\": 3}', 'id': 'call_yiao3eVlh6TFB8vZPDydP5ev', 'index': 1}]\n"
     ]
    }
   ],
   "source": [
    "first = True\n",
    "async for chunk in llm_openai.astream(query):\n",
    "    if first:\n",
    "        gathered = chunk\n",
    "        first = False\n",
    "    else:\n",
    "        gathered = gathered + chunk\n",
    "\n",
    "    print(gathered.tool_call_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24238178-55c6-4c6a-b2c9-322325b29b98",
   "metadata": {},
   "source": [
    "And below we accumulate tool calls to demonstrate partial parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d3f88e-35f0-48cc-b505-3dbe21981f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[{'name': 'get_word_length', 'args': {}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}]\n",
      "[{'name': 'get_word_length', 'args': {}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrys'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanth'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanthemum'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanthemum'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanthemum'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanthemum'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}, {'name': 'magic_function', 'args': {}, 'id': 'call_snvH5SBo0Ti0OLJLfYNNKOyU'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanthemum'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}, {'name': 'magic_function', 'args': {}, 'id': 'call_snvH5SBo0Ti0OLJLfYNNKOyU'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanthemum'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}, {'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_snvH5SBo0Ti0OLJLfYNNKOyU'}]\n",
      "[{'name': 'get_word_length', 'args': {'word': 'chrysanthemum'}, 'id': 'call_Owpz7LKLjBEdUepp4R9J3pNK'}, {'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_snvH5SBo0Ti0OLJLfYNNKOyU'}]\n"
     ]
    }
   ],
   "source": [
    "first = True\n",
    "async for chunk in llm_openai.astream(query):\n",
    "    if first:\n",
    "        gathered = chunk\n",
    "        first = False\n",
    "    else:\n",
    "        gathered = gathered + chunk\n",
    "\n",
    "    print(gathered.tool_calls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
