{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69e747b-4e79-4caf-8f8b-c6e70275a31d",
   "metadata": {},
   "source": [
    "# Streaming Agents with Callbacks (Advanced)\n",
    "\n",
    "This notebooks shows how to stream agent using callbacks.\n",
    "\n",
    "This notebook uses an agent based on OpenAI tools invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d27b51-e8bc-4217-a469-562c0bf01b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, TypeVar, Union\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain import agents, hub\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.callbacks.base import AsyncCallbackHandler\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import ChatGenerationChunk, GenerationChunk, LLMResult\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab6752b-d49e-473d-91ec-655bfdd6d40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c767f760-fe52-47e5-9c2a-622f03507aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def what_does_the_cat_say(callbacks) -> str:\n",
    "    \"\"\"What does the cat say?!\"\"\"\n",
    "    chunks = list(\n",
    "        model.stream(\n",
    "            \"You are a cat. Say something that a cat may say. make it cat like.\",\n",
    "            {\"callbacks\": callbacks, \"tags\": [\"cat_says\"]},\n",
    "        )\n",
    "    )\n",
    "    return \"\".join(chunk.content for chunk in chunks)\n",
    "\n",
    "\n",
    "@tool\n",
    "def where_cat_is_hiding(callbacks) -> str:\n",
    "    \"\"\"Where is the cat hiding right now?\"\"\"\n",
    "    chunks = list(\n",
    "        model.stream(\n",
    "            \"Give one up to three word answer about where the cat might be hiding in the house right now.\",\n",
    "            {\"callbacks\": callbacks, \"tags\": [\"hiding_spot\"]},\n",
    "        )\n",
    "    )\n",
    "    return \"\".join(chunk.content for chunk in chunks)\n",
    "\n",
    "\n",
    "@tool\n",
    "def tell_me_a_joke_about(topic: str, callbacks) -> str:\n",
    "    \"\"\"Tell a joke about a given topic.\"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are Cat Agent 007. You are funny and know many jokes.\"),\n",
    "            (\"human\", \"Tell me a joke about {topic}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | model.with_config({\"tags\": [\"joke\"]})\n",
    "    chunks = list(chain.stream({\"topic\": topic}, {\"callbacks\": callbacks}))\n",
    "    return \"\".join(chunk.content for chunk in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c8d640e-f2b2-4261-ba2e-87924e59cf3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CallbackHandler(AsyncCallbackHandler):\n",
    "    def __init__(self, filter_tags: List[str]) -> None:\n",
    "        \"\"\"Initialize a callback handler.\"\"\"\n",
    "        self.filter_tags = filter_tags\n",
    "\n",
    "    async def on_chat_model_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        messages: List[List[BaseMessage]],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run when a chat model starts running.\"\"\"\n",
    "        if not self.has_overlap(tags):\n",
    "            return\n",
    "        print()\n",
    "        print(\"-----\")\n",
    "        print(tags)\n",
    "\n",
    "    def has_overlap(self, tags: Optional[List[str]]) -> bool:\n",
    "        \"\"\"Check for overlap with filtered tags.\"\"\"\n",
    "        if not tags:\n",
    "            return False\n",
    "        return bool(set(tags or []) & set(self.filter_tags or []))\n",
    "\n",
    "    async def on_llm_new_token(\n",
    "        self,\n",
    "        token: str,\n",
    "        *,\n",
    "        chunk: Optional[Union[GenerationChunk, ChatGenerationChunk]] = None,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"\n",
    "        if not self.has_overlap(tags):\n",
    "            return\n",
    "        print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad986227-842b-49c2-bb0b-eafaf125cff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "handler = CallbackHandler(filter_tags=[\"cat_says\", \"hiding_spot\", \"joke\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d012c42-39b7-4471-b47c-4aa6c7a54d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dcb28ba-fa59-402d-9162-3e392be3b616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [what_does_the_cat_say, tell_me_a_joke_about, where_cat_is_hiding]\n",
    "agent = agents.create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent\"]}), tools, prompt\n",
    ")\n",
    "executor = agents.AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a0861b-9299-456a-9352-5c10bd1978af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "['cat_says']\n",
      "Meow, hooman! I demand your immediate attention and affection."
     ]
    }
   ],
   "source": [
    "executor.invoke({\"input\": \"what does the cat say?\"}, {\"callbacks\": [handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1508e7b-375c-4f3b-851f-909624fd1b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "['hiding_spot']\n",
      "Under the bed.\n",
      "-----\n",
      "['seq:step:2', 'joke']\n",
      "Why did the scarecrow bring a ladder under the bed?\n",
      "\n",
      "Because it heard there was a \"bed spring\" party going on!"
     ]
    }
   ],
   "source": [
    "executor.invoke(\n",
    "    {\"input\": \"tell me a joke about the location where the cat is hiding\"},\n",
    "    {\"callbacks\": [handler]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03ea798e-b62d-46cf-9bcf-81aa40903d34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "['hiding_spot']\n",
      "Under the bed.\n",
      "-----\n",
      "['seq:step:2', 'joke']\n",
      "Why did the scarecrow bring a ladder under the bed?\n",
      "\n",
      "Because it heard there was a \"bed spring\" party going on!"
     ]
    }
   ],
   "source": [
    "handler = CallbackHandler(filter_tags=[\"cat_says\", \"hiding_spot\", \"joke\"])\n",
    "executor.invoke(\n",
    "    {\"input\": \"tell me a joke about the location where the cat is hiding\"},\n",
    "    {\"callbacks\": [handler]},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
