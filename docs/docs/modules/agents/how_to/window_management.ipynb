{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b234bd2c-dacb-48e3-ba60-cbbe34e827ad",
   "metadata": {},
   "source": [
    "# Manage prompt size\n",
    "\n",
    "Agents dynamically call tools, and the results of those tools get add back to the prompt so that the agent can plan the next action. Depending on what tools are being used and how they're being called, the agent prompt could grow larger than the model context window.\n",
    "\n",
    "With LCEL, it's easy to add custom functionality for managing the size of prompts. Here's a simple example of how we can do this. In this example we'll simply drop the earliest function messages when we bump up against the model's context window limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d817293-7ae7-47ae-949b-d844e94d5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain duckduckgo-search\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.chat import ChatPromptValue\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.tools.render import format_tool_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96498fb3-ef6b-462f-be1c-8ccfffadd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [DuckDuckGoSearchRun().with_retry(stop_after_attempt=3)]\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b0686dc-ad06-4a0d-83cf-7f760580cc95",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[1;32m     12\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     13\u001b[0m     {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: itemgetter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIFunctionsAgentOutputParser()\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m \u001b[43mAgentExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m agent_executor\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m     27\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is the current US president? What\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms their home state? What\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms their home state\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms bird? What\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms that bird\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms scientific name?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m~/langchain/libs/langchain/langchain/load/serializable.py:97\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/langchain/.venv/lib/python3.9/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/langchain/.venv/lib/python3.9/site-packages/pydantic/v1/main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1104\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/langchain/libs/langchain/langchain/agents/agent.py:814\u001b[0m, in \u001b[0;36mAgentExecutor.validate_tools\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate that tools are compatible with agent.\"\"\"\u001b[39;00m\n\u001b[1;32m    813\u001b[0m agent \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 814\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    815\u001b[0m allowed_tools \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_allowed_tools()\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_tools \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tools'"
     ]
    }
   ],
   "source": [
    "def condense_prompt(prompt: ChatPromptValue) -> ChatPromptValue:\n",
    "    messages = prompt.to_messages()\n",
    "    num_tokens = llm.get_num_tokens_from_messages(messages)\n",
    "    function_messages = messages[2:]\n",
    "    while num_tokens > 4_000:\n",
    "        function_messages = function_messages[1:]\n",
    "        num_tokens = llm.get_num_tokens_from_messages(messages[:2] + function_messages)\n",
    "    messages = messages[:2] + function_messages\n",
    "    return ChatPromptValue(messages=messages)\n",
    "\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | condense_prompt\n",
    "    | llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke(\n",
    "    {\"input\": \"Who is the current US president? What's their home state? What's their home state's bird? What's that bird's scientific name?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afe5010-7af8-461e-a41c-93be225db493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.tools.ddg_search.tool.DDGInput"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(tools[0], \"args_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd07555a-f647-4122-a15e-b6bff572ca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.tools.ddg_search.tool.DDGInput"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].args_schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
