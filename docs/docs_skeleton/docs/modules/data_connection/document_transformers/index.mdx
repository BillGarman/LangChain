---
sidebar_position: 1
---
# Document transformers

Once you've loaded documents, you'll often want to transform them to better suit your application. The simplest example
is you may want to split a long document into smaller chunks that can fit into your model's context window. LangChain
has a number of built-in document transformers that make it easy to split, combine, filter, and otherwise manipulate documents.

## Text splitters

When you want to deal with long pieces of text, it is necessary to split up that text into chunks.
As simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What "semantically related" means could depend on the type of text.
This notebook showcases several ways to do that.

At a high level, text splitters work as following:

1. Split the text up into small, semantically meaningful chunks (often sentences).
2. Start combining these small chunks into a larger chunk until you reach a certain size (as measured by some function).
3. Once you reach that size, make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between chunks).

That means there are two different axes along which you can customize your text splitter:

1. How the text is split
2. How the chunk size is measured

## Get started with text splitters

import GetStarted from "@snippets/modules/data_connection/document_transformers/get_started.mdx"

<GetStarted/>

## Filter redundant embeddings
When documents have similar (even identical) content, it's not necessary to index every document. The `EmbeddingsRedundantFilter` filters out redundant documents based a semantic similarity threshold.

## Convert text to Q&A format
Often, text is presented in narrative or conversational format, but the user's query is typically formatted as a question. Converting documents to
question and answer format ("interrogating" documents) before vectorization can help improve the reliability of the vector retrieval step.

LangChain uses the [doctran](https://github.com/psychic-api/doctran/tree/main) library to interrogate documents, which itself depends on (OpenAI function calling)[https://openai.com/blog/function-calling-and-other-api-updates].

## Translate text
Sometimes, it's useful to translate documents into mulitple languages before generating embeddings from it, particularly for use cases
where queries in more than one language are expected.

LangChain uses the [doctran](https://github.com/psychic-api/doctran/tree/main) library to translate documents, which itself depends on (OpenAI function calling)[https://openai.com/blog/function-calling-and-other-api-updates].