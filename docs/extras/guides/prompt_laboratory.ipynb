{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "920a3c1a",
   "metadata": {},
   "source": [
    "# Prompt Comparison\n",
    "\n",
    "Constructing your language model application will likely involved choosing between many different options of prompts, models, and even chains to use. When doing so, you will want to compare these different options on different inputs in an easy, flexible, and intuitive way. \n",
    "\n",
    "LangChain provides the concept of a PromptLaboratory to test out and try different prompts on the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.laboratory import PromptLaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_template = \"\"\"Answer to the query.\n",
    "Query: {query}\n",
    "Answer: \"\"\"\n",
    "simple_cot_template = \"\"\"Answer to the query. Explain the reasoning step by step.\n",
    "Query: {query}\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cde09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lab = PromptLaboratory.from_templates(llm, [simple_template, simple_cot_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lab.compare({\"query\": \"What is 12 plus 26?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompt = PromptTemplate.from_template(simple_template)\n",
    "simple_cot_prompt = PromptTemplate.from_template(simple_cot_template)\n",
    "prompt_lab_with_names = PromptLaboratory(llm, [simple_prompt, simple_cot_prompt], [\"base\", \"CoT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64377ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lab_with_names.compare({\"query\": \"What is fifth decimal place of pi?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
