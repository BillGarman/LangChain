{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6605e7f7",
   "metadata": {},
   "source": [
    "# Web scraping using OpenAI Functions Extraction chain\n",
    "\n",
    "Web scraping is challenging for many reasons; one of them is the changing nature of modern websites' layouts and content, which requires modifying scraping scripts to accommodate the changes.\n",
    "\n",
    "Using OpenAI Function in the extraction chain, you can avoid having to change your code constantly when websites change. Plus, this will save you time setting up when scraping a website for the first time by creating simple schemas.\n",
    "\n",
    "In this notebook, we scrape The Wall Street Journal. You'll need to have an OpenAI API key for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05087ad3",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "\n",
    "We need OpenAI and LangChain for the extraction part, and Playwright and Beautiful Soup for the scraping part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q openai langchain playwright beautifulsoup4\n",
    "! playwright install\n",
    "\n",
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "# import dotenv\n",
    "# dotenv.load_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7f514",
   "metadata": {},
   "source": [
    "## Use AsyncChromiumLoader\n",
    "\n",
    "This load will use Chromium to scrape the web page. In the context of this code, Chromium is one of the browsers supported by Playwright, a library used to control browser automation. This will launch a headless instance of Chromium. Headless mode means that the browser is running without a graphical user interface, which is commonly used for web scraping or automated testing of web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce67cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncChromiumLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f4bf0",
   "metadata": {},
   "source": [
    "## Define the LLM object and extraction function\n",
    "\n",
    "Next, we define the LLM object using LangChain and OpenAI Python SDK.\n",
    "\n",
    "We're using `gpt-3.5-turbo-0613` to guarantee access to OpenAI Functions feature (although this might be available to everyone by time of writing). We're also keeping `temperature` at `0` to keep randomness of the LLM down.\n",
    "\n",
    "# Define a schema\n",
    "\n",
    "Next, you define a schema to specify what kind of data you want to extract. Here, the key names matter as they tell the LLM what kind of information they want. So, be as detailed as possible. In this example, we want to scrape only news article's name and summary from The Wall Street Journal website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95506f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_extraction_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"news_article_title\": {\"type\": \"string\"},\n",
    "        \"news_article_summary\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"news_article_title\", \"news_article_summary\"],\n",
    "}\n",
    "\n",
    "def extract(content: str, schema: dict):\n",
    "        return create_extraction_chain(schema=schema, llm=llm).run(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc265526",
   "metadata": {},
   "source": [
    "# Run the web scraper w/ HTML2Text\n",
    "\n",
    "* Grab HTML / JS w/ AsyncChromiumLoader\n",
    "* Transform HTML to Text (Markdown) w/ Html2TextTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9de2e792",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content with LLM\n",
      "[{'news_article_summary': \"Trusted Insights On Today's Top Stories\",\n",
      "  'news_article_title': 'The Wall Street Journal'},\n",
      " {'news_article_summary': 'WSJ Pro, Bankruptcy, Central Banking, Private '\n",
      "                          'Equity, Venture Capital',\n",
      "  'news_article_title': 'Economy'},\n",
      " {'news_article_summary': 'Management, Journal Reports, The Future of '\n",
      "                          'Everything, Obituaries, Tech/WSJ.D',\n",
      "  'news_article_title': 'Business'},\n",
      " {'news_article_summary': 'CFO Journal, CIO Journal, CMO Today, Logistics '\n",
      "                          'Report, Risk & Compliance, The Workplace Report',\n",
      "  'news_article_title': 'C-Suite'},\n",
      " {'news_article_summary': 'CIO Journal, The Future of Everything, Personal '\n",
      "                          'Tech',\n",
      "  'news_article_title': 'Tech'},\n",
      " {'news_article_summary': 'Bonds, Commercial Real Estate, Commodities & '\n",
      "                          'Futures, Stocks, Personal Finance, WSJ Money, '\n",
      "                          'Streetwise, Intelligent Investor',\n",
      "  'news_article_title': 'Markets'},\n",
      " {'news_article_summary': 'Columnists, Editorials, Commentary, Future View, '\n",
      "                          'Houses of Worship, Cross Country, Letters to the '\n",
      "                          'Editor',\n",
      "  'news_article_title': 'Opinion'},\n",
      " {'news_article_summary': 'Reviews, Film, Television, Theater, Masterpiece '\n",
      "                          'Series, Music',\n",
      "  'news_article_title': 'Books & Arts'}]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import pprint\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "\n",
    "token_limit = 4000\n",
    "def scrape_with_playwright(urls, schema):\n",
    "    \n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    html_content = docs_transformed[0].page_content\n",
    "    \n",
    "    print(\"Extracting content with LLM\")\n",
    "    html_content_fits_context_window_llm = html_content[:token_limit]\n",
    "    extracted_content = extract(schema=schema,\n",
    "                                content=html_content_fits_context_window_llm)\n",
    "    pprint.pprint(extracted_content)\n",
    "    \n",
    "urls = [\"https://www.wsj.com\"]\n",
    "scrape_with_playwright(urls, schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f7de42",
   "metadata": {},
   "source": [
    "# Run the web scraper w/ BeautifulSoup\n",
    "\n",
    "* Grab HTML / JS w/ AsyncChromiumLoader\n",
    "* Transform HTML to Text w/ BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52826986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_unwanted_tags(html_content, unwanted_tags=[\"script\", \"style\"]):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    for tag in unwanted_tags:\n",
    "        for element in soup.find_all(tag):\n",
    "            element.decompose()\n",
    "    return str(soup)\n",
    "\n",
    "def extract_tags(html_content, tags: list[str]):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    text_parts = []\n",
    "    for tag in tags:\n",
    "        elements = soup.find_all(tag)\n",
    "        for element in elements:\n",
    "            if tag == \"a\":\n",
    "                href = element.get(\"href\")\n",
    "                if href:\n",
    "                    text_parts.append(f\"{element.get_text()} ({href})\")\n",
    "                else:\n",
    "                    text_parts.append(element.get_text())\n",
    "            else:\n",
    "                text_parts.append(element.get_text())\n",
    "\n",
    "    return \" \".join(text_parts)\n",
    "\n",
    "def scrape_by_url_raw(url: str) -> str:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    return response.text\n",
    "\n",
    "def remove_unessesary_lines(content: str) -> str:\n",
    "    lines = content.split(\"\\n\")\n",
    "    stripped_lines = [line.strip() for line in lines]\n",
    "    non_empty_lines = [line for line in stripped_lines if line]\n",
    "    seen = set()\n",
    "    deduped_lines = [\n",
    "        line for line in non_empty_lines if not (line in seen or seen.add(line))\n",
    "    ]\n",
    "    cleaned_content = \"\".join(deduped_lines)\n",
    "\n",
    "    return cleaned_content\n",
    "\n",
    "def bs4_transfomer(html):\n",
    "\n",
    "    clean_html = remove_unessesary_lines(extract_tags(remove_unwanted_tags(html), \n",
    "                                                      [\"p\", \"li\", \"div\", \"a\"]))\n",
    "    return clean_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2615a7",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977560ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content with LLM\n",
      "[{'news_article_summary': 'It isn’t cool enough for the Fed just yet, but it '\n",
      "                          'is getting there.',\n",
      "  'news_article_title': 'Employment data showed America’s job market is '\n",
      "                        'cooling.'},\n",
      " {'news_article_title': 'A bond selloff pushed up yields and drew traders away '\n",
      "                        'from stocks in recent days.'},\n",
      " {'news_article_title': 'Icahn Enterprises is cutting its dividend in half and '\n",
      "                        'winding down bets that the stock market would '\n",
      "                        'collapse, which have inflicted heavy losses.'},\n",
      " {'news_article_title': 'The decision eliminates a sizable claim against '\n",
      "                        'Google while preserving the core of the government’s '\n",
      "                        'case against the search giant, clearing the way for '\n",
      "                        'the antitrust trial that is slated to begin next '\n",
      "                        'month.'},\n",
      " {'news_article_title': 'John Lauro called the indictment an unconstitutional '\n",
      "                        'attack on political speech.'},\n",
      " {'news_article_title': 'Justices let stand a lower court order that city '\n",
      "                        'can’t enforce municipal code against tribal members '\n",
      "                        'on land that falls within reservation’s boundaries.'},\n",
      " {'news_article_title': 'Three side-by-side houses in Boston are designed to '\n",
      "                        'offer clean inside air, reduced emissions and little '\n",
      "                        'to no energy costs.'},\n",
      " {'news_article_title': 'As the chaotic consolidation of college sports '\n",
      "                        'continues, the 108-year-old Pac-12 would be left with '\n",
      "                        'just seven members committed to it beyond 2024.'},\n",
      " {'news_article_title': 'The strike on one of Russia’s largest ports disrupted '\n",
      "                        'shipments of grain and oil as fighting in the Black '\n",
      "                        'Sea intensified, threatening world food and energy '\n",
      "                        'markets.'},\n",
      " {'news_article_title': 'Some people are being pushed into saving in Roth '\n",
      "                        '401(k)s, but they may come out ahead despite losing a '\n",
      "                        'key tax deduction.'},\n",
      " {'news_article_title': 'An accident on vacation was an unpleasant reminder '\n",
      "                        'that retirement won’t always be like this.'},\n",
      " {'news_article_title': 'The regional wireless carrier’s controlling '\n",
      "                        'shareholder says it is exploring strategic options '\n",
      "                        'for a business left behind by telecom’s consolidation '\n",
      "                        'wave.'},\n",
      " {'news_article_title': 'Share prices skyrocket, then sink, for companies that '\n",
      "                        'don’t even have a direct link to room-temperature '\n",
      "                        'superconductors.'},\n",
      " {'news_article_title': 'The Second Amendment and its discontents, the life '\n",
      "                        'and drama of August Wilson, journeys to the ocean’s '\n",
      "                        'depths and more.'},\n",
      " {'news_article_title': 'The buyer of the roughly 12,000-square-foot Manhattan '\n",
      "                        'pad is Scott Lynn, chief executive of online art '\n",
      "                        'investment platform Masterworks.'},\n",
      " {'news_article_title': 'So many men overstuff their pants pockets—and nothing '\n",
      "                        'kills style faster. Heed these tips to streamline '\n",
      "                        'your lower half.'},\n",
      " {'news_article_title': 'A legendary party in the Bronx in the summer of 1973 '\n",
      "                        'helped usher in a new musical era, but it’s too much '\n",
      "                        'to call it the birth of the genre.'},\n",
      " {'news_article_title': 'Russian opposition leader Alexei Navalny, Vladimir '\n",
      "                        'Putin’s most prominent critic, was charged with '\n",
      "                        'inciting and funding extremism.'},\n",
      " {'news_article_title': 'The new policy would limit time and content according '\n",
      "                        'to age, on top of already strict videogame '\n",
      "                        'restrictions.'},\n",
      " {'news_article_title': 'Domingo Germán appeared intoxicated, flipped a couch '\n",
      "                        'and destroyed a TV in the clubhouse before the team '\n",
      "                        'announced he would seek treatment, according to '\n",
      "                        'people who were present.'},\n",
      " {'news_article_title': 'The Southern California city attracts food lovers and '\n",
      "                        'culture hounds as well as travelers who include '\n",
      "                        '‘beach walks’ in their plans.'},\n",
      " {'news_article_title': 'Domestic ticket fares are falling as travelers favor '\n",
      "                        'longer trips abroad.'},\n",
      " {'news_article_title': 'You don’t need to pay a hefty fee to score generous '\n",
      "                        'rewards.'}]\n"
     ]
    }
   ],
   "source": [
    "def scrape_with_playwright(urls, schema):\n",
    "    \n",
    "    loader = AsyncChromiumLoader(urls)\n",
    "    docs = loader.load()\n",
    "    html_content = bs4_transfomer(docs[0].page_content)\n",
    "\n",
    "    print(\"Extracting content with LLM\")\n",
    "    html_content_fits_context_window_llm = html_content[:token_limit]\n",
    "    extracted_content = extract(schema=schema,\n",
    "                                content=html_content_fits_context_window_llm)\n",
    "    pprint.pprint(extracted_content)\n",
    "    \n",
    "urls = [\"https://www.wsj.com\"]\n",
    "scrape_with_playwright(urls, schema=schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
