{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd7ec7af",
   "metadata": {},
   "source": [
    "# Elasticsearch database\n",
    "\n",
    "Interact with Elasticsearch analytics database via Langchain. This chain builds search queries via the Elasticsearch DSL API (filters and aggregations).\n",
    "\n",
    "The Elasticsearch client must have permissions for index listing, mapping description and search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8eae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from langchain.chains.elasticsearch_database import ElasticsearchDatabaseChain\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde03bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elasticsearch python client.\n",
    "# See https://elasticsearch-py.readthedocs.io/en/v8.8.2/api.html#elasticsearch.Elasticsearch\n",
    "client = Elasticsearch(\"http://user:pass@localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ae0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "chain = ElasticsearchDatabaseChain.from_llm(llm=llm, database=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d22d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the 10 biggest tenants in the database?\"\n",
    "inputs = {\n",
    "    \"question\": question,\n",
    "}\n",
    "chain(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b4bfada",
   "metadata": {},
   "source": [
    "## Custom prompt\n",
    "\n",
    "You can also customize the prompt that is used. Here is an example prompting it to understand that \"tenant\" is the same as the \"account_id\" index property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a494f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.elasticsearch_database.prompts import DEFAULT_DSL_TEMPLATE\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "PROMPT_SUFFIX = \"\"\"Only use the following Elasticsearch indices:\n",
    "{indices_info}\n",
    "\n",
    "If someone asks for the property \"tenant\", they really mean the \"account_id\" property.\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"indices_info\", \"top_k\"],\n",
    "    template=DEFAULT_DSL_TEMPLATE + PROMPT_SUFFIX,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4219960",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ElasticsearchDatabaseChain.from_llm(llm=ChatOpenAI(temperature=0), database=client, prompt=PROMPT)\n",
    "chain.run(\"How many tenants are localized in eu_west_3?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "372b8f93",
   "metadata": {},
   "source": [
    "## Adding example rows from each index\n",
    "\n",
    "Sometimes, the format of the data is not obvious and it is optimal to include a sample of rows from the indices in the prompt to allow the LLM to understand the data before providing a final query. Here we will use this feature to let the LLM know that artists are saved with their full names by providing ten rows from the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef818de",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ElasticsearchDatabaseChain.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    database=client,\n",
    "    include_indices=[\"artists\"],     # we include only one table to save tokens in the prompt :)\n",
    "    sample_documents_in_index_info=10,     # 10 rows from each index will be included in the prompt as sample data\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
