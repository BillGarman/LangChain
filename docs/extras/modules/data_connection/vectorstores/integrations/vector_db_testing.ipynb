{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328ef72d",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Test that we can both write to and read from an index across several production vectorstores.\n",
    "\n",
    "In particular, the existing documentation often involoves simmply writing to an `index` (e.g., `from_documents`).\n",
    "\n",
    "But, there are two gaps:\n",
    "\n",
    "1) We don't confirm that we can also read an existing index, which appears to be a problem w/ Weviate today.\n",
    "\n",
    "2) We also don't confirm integration w/ hosted instances in all cases (e.g., many are just local). \n",
    "\n",
    "\n",
    "## Example Text\n",
    "\n",
    "Example from Karpathy-GPT app [here](https://github.com/rlancemartin/karpathy-gpt/tree/main/eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e79437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "course_txt = open('example_data/karpathy_course_all.txt').read()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "splits = text_splitter.split_text(course_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5934097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1360"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full course\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfa86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "splits = splits[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaac9ed",
   "metadata": {},
   "source": [
    "## Pinecone\n",
    "\n",
    "* Use Pinecone console to create a new index with `index_name`\n",
    "* [Write and read supported](https://python.langchain.com/en/latest/reference/modules/vectorstores.html#langchain.vectorstores.Pinecone) to `index_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f151140",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60eb879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Auth\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-east1-gcp\"  \n",
    ")\n",
    "\n",
    "# Create new index\n",
    "embeddings = OpenAIEmbeddings()\n",
    "index_name = \"karpathy-gpt\"\n",
    "vectorstore_new = Pinecone.from_texts(splits, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b35506e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from index\n",
    "vectorstore_pinecone = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bafe2136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(lc_kwargs={'page_content': \"Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient and really what it does is it implements back propagation. Now back propagation is this algorithm that allows you to efficiently evaluate the gradient of some kind of a loss function with respect to the weights of a neural network and what that allows us to do then is we can iteratively tune the weights of that neural network to minimize the loss function and therefore improve the accuracy of the network. So back propagation would be at the mathematical core of any modern deep neural network library\", 'metadata': {'id': '01', 'link': 'https://youtu.be/VMj-3S1tku0', 'source': 'The spelled-out intro to neural networks and backpropagation： building micrograd 01', 'title': 'The spelled-out intro to neural networks and backpropagation： building micrograd'}}, page_content=\"Hello, my name is Andrej and I've been training deep neural networks for a bit more than a decade. And in this lecture I'd like to show you what neural network training looks like under the hood. So in particular we are going to start with a blank Jupyter notebook and by the end of this lecture we will define and train a neural net and you'll get to see everything that goes on under the hood and exactly sort of how that works on an intuitive level. Now specifically what I would like to do is I would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient and really what it does is it implements back propagation. Now back propagation is this algorithm that allows you to efficiently evaluate the gradient of some kind of a loss function with respect to the weights of a neural network and what that allows us to do then is we can iteratively tune the weights of that neural network to minimize the loss function and therefore improve the accuracy of the network. So back propagation would be at the mathematical core of any modern deep neural network library\", metadata={'id': '01', 'link': 'https://youtu.be/VMj-3S1tku0', 'source': 'The spelled-out intro to neural networks and backpropagation： building micrograd 01', 'title': 'The spelled-out intro to neural networks and backpropagation： building micrograd'})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_pinecone.similarity_search(query)\n",
    "matched_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc0c3b",
   "metadata": {},
   "source": [
    "## Supabase\n",
    "\n",
    "\n",
    "* Create a new project in [Supabase dashboard](https://supabase.com/dashboard/project/xhbejgrankzufmczyqil).\n",
    "* In the project, go to the SQL editor on the left.\n",
    "* We need to create a table to store our embeddings.\n",
    "* We will use `pgvector`, an extension for PostgreSQL that allows you to both store and query vector embeddings.\n",
    "* Create the table in the SQL editor with [this code](https://supabase.com/docs/guides/ai/langchain), modified below for our table name `karpathy_gpt`:\n",
    "\n",
    "```\n",
    "-- Enable the pgvector extension to work with embedding vectors\n",
    "-- create extension vector;\n",
    "\n",
    "-- Create a table to store your documents\n",
    "create table karpathy_gpt (\n",
    "  id bigserial primary key,\n",
    "  content text, -- corresponds to Document.pageContent\n",
    "  metadata jsonb, -- corresponds to Document.metadata\n",
    "  embedding vector(1536) -- 1536 works for OpenAI embeddings, change if needed\n",
    ");\n",
    "\n",
    "-- Create a function to search for documents\n",
    "CREATE OR REPLACE function match_documents (\n",
    "  query_embedding vector(1536),\n",
    "  match_count int default null,\n",
    "  filter jsonb DEFAULT '{}'\n",
    ") returns table (\n",
    "  id bigint,\n",
    "  content text,\n",
    "  metadata jsonb,\n",
    "  similarity float\n",
    ")\n",
    "language plpgsql\n",
    "as $$\n",
    "#variable_conflict use_column\n",
    "begin\n",
    "  return query\n",
    "  select\n",
    "    id,\n",
    "    content,\n",
    "    metadata,\n",
    "    1 - (karpathy_gpt.embedding <=> query_embedding) as similarity\n",
    "  from karpathy_gpt\n",
    "  where metadata @> filter\n",
    "  order by karpathy_gpt.embedding <=> query_embedding\n",
    "  limit match_count;\n",
    "end;\n",
    "$$;\n",
    "```\n",
    "\n",
    "* Now, the table is created!\n",
    "* In the project, you can find `SUPABASE_URL` and `SUPABASE_SERVICE_KEY`, which we will use to connect to this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e251d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07c12532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import SupabaseVectorStore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from supabase.client import Client, create_client\n",
    "# Auth\n",
    "supabase_url = os.environ.get('supabase_url')\n",
    "supabase_key = os.environ.get('supabase_key')\n",
    "supabase: Client = create_client(supabase_url, supabase_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75b991ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index\n",
    "table_name=\"karpathy_gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore_new = SupabaseVectorStore.from_texts(splits,embeddings,client=supabase,table_name=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b645bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from index\n",
    "vectorstore_supabase = SupabaseVectorStore(client=supabase,embedding=embeddings,table_name=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c148d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(lc_kwargs={'metadata': {}, 'page_content': \"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\"}, page_content=\"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\", metadata={})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_supabase.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ffa7b",
   "metadata": {},
   "source": [
    "# Elastic\n",
    "\n",
    "* Log into Elastic Cloud console at https://cloud.elastic.co\n",
    "* Create deployment\n",
    "* Go to the deployment page and `copy endpoint`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e15479bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auth\n",
    "elastic_endpoint = \"langchain-test.es.us-central1.gcp.cloud.es.io\"\n",
    "elasticsearch_url = f\"https://elastic:cYo6rjQMesQbwqcGHblf7P0K@{elastic_endpoint}:9243\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import ElasticVectorSearch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "index_name = \"karpathy-gpt\"\n",
    "\n",
    "# Create new index\n",
    "vectorstore_new = ElasticVectorSearch.from_texts(splits, embeddings, \n",
    "                                                 elasticsearch_url=elasticsearch_url,\n",
    "                                                 index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af7ab74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(lc_kwargs={'page_content': \"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\", 'metadata': {}}, page_content=\"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\", metadata={})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_new.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe76eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from index\n",
    "vectorstore_estc = ElasticVectorSearch(elasticsearch_url=elasticsearch_url, index_name=index_name, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c053c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(lc_kwargs={'page_content': \"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\", 'metadata': {}}, page_content=\"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\", metadata={})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query\n",
    "matched_docs = vectorstore_estc.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125056e",
   "metadata": {},
   "source": [
    "## Redis\n",
    "\n",
    "Cloud -\n",
    "\n",
    "* Create database in Redis public cloud, which has endpoint: `redis-16792.c302.asia-northeast1-1.gce.cloud.redislabs.com:16792`\n",
    "* **Need**: Documentation on how to [connect](https://docs.redis.com/latest/rs/references/client_references/client_python/) to this because we still get auth errors.\n",
    "\n",
    "--- \n",
    "\n",
    "Local - \n",
    "  \n",
    "```\n",
    "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n",
    "brew install redis\n",
    "brew services start redis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e6a01a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redis in /Users/31treehaus/miniconda3/envs/langchain/lib/python3.9/site-packages (4.5.5)\r\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in /Users/31treehaus/miniconda3/envs/langchain/lib/python3.9/site-packages (from redis) (4.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae502d1",
   "metadata": {},
   "source": [
    "**Need Docker to run `RediSearch` locally -** \n",
    "\n",
    "`docker run -p 6379:6379 redislabs/redisearch:latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96207bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.redis import Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Redis cannot be used as a vector database without RediSearch\n",
    "redis_local = Redis.from_texts(splits,embeddings,redis_url=\"redis://localhost:6379\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e7298b",
   "metadata": {},
   "source": [
    "`Cloud`\n",
    "\n",
    "**Need to sort out auth errors and get crisp documentation here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTH ERROR\n",
    "import redis\n",
    "r = redis.Redis(\n",
    "    host='redis-16792.c302.asia-northeast1-1.gce.cloud.redislabs.com',\n",
    "    port=16792, \n",
    "    password=os.environ.get('redis_pw'))\n",
    "\n",
    "r.set('foo', 'bar')\n",
    "value = r.get('foo')\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98005a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTH ERROR\n",
    "redis_url=\"redis://redis-16792.c302.asia-northeast1-1.gce.cloud.redislabs.com:16792\"\n",
    "vectorstore_new = Redis.from_texts(splits,embeddings,redis_url=redis_url,index_name='link')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d923c",
   "metadata": {},
   "source": [
    "## Weviate\n",
    "\n",
    "* Create a new cluser in [Weviate dashboard](https://console.weaviate.cloud/dashboard).\n",
    "* This gives you a url: https://langchain-test-l73n8vle.weaviate.network\n",
    "* `text_key` is the name of the text property in your Weaviate schema where the text of your documents is stored. \n",
    "* It's used to find documents that are similar to a text query.\n",
    "\n",
    "**Bug: https://github.com/hwchase17/langchain/issues/6121**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from weaviate import Client, auth\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Auth\n",
    "weaviate_url = \"https://langchain-test-l73n8vle.weaviate.network\"\n",
    "client = Client(url=weaviate_url, auth_client_secret=auth.AuthClientPassword(\"lance@langchain.dev\", \"j!ZEFs6pFd.SWH.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7de36ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index!\n",
      "LangChain_0b289ac1f5dd4543b76b9f9bdf047ef6\n",
      "Text key: text_key!\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "# Create and add texts\n",
    "### Added logging to show the auto-generated index_name and text_key ###\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore_new = Weaviate.from_texts(splits,embeddings,client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06580c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name in similarity_search_by_vector\n",
      "LangChain_0b289ac1f5dd4543b76b9f9bdf047ef6\n",
      "Result\n",
      "{'data': {'Get': {'LangChain_0b289ac1f5dd4543b76b9f9bdf047ef6': [{'text': \"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\"}]}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(lc_kwargs={'page_content': \"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\", 'metadata': {}}, page_content=\"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\", metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_new.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28cf27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to our index using the index_name and text_key we obtained from logging\n",
    "index_name = \"LangChain_0b289ac1f5dd4543b76b9f9bdf047ef6\"\n",
    "text_key = \"text\"\n",
    "vectorstore_weviate = Weaviate(client=client,index_name=index_name,text_key=text_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d915cb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error during query: [{'locations': [{'column': 58, 'line': 1}], 'message': 'Unknown argument \"nearText\" on field \"LangChain_0b289ac1f5dd4543b76b9f9bdf047ef6\" of type \"GetObjectsObj\". Did you mean \"nearVector\" or \"nearObject\"?', 'path': None}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matched_docs \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore_weviate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m matched_docs\n",
      "File \u001b[0;32m~/Desktop/AI/langchain-fork/langchain/vectorstores/weaviate.py:170\u001b[0m, in \u001b[0;36mWeaviate.similarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    List of Documents most similar to the query.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_by_text:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/AI/langchain-fork/langchain/vectorstores/weaviate.py:202\u001b[0m, in \u001b[0;36mWeaviate.similarity_search_by_text\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m result \u001b[38;5;241m=\u001b[39m query_obj\u001b[38;5;241m.\u001b[39mwith_near_text(content)\u001b[38;5;241m.\u001b[39mwith_limit(k)\u001b[38;5;241m.\u001b[39mdo()\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_name]:\n",
      "\u001b[0;31mValueError\u001b[0m: Error during query: [{'locations': [{'column': 58, 'line': 1}], 'message': 'Unknown argument \"nearText\" on field \"LangChain_0b289ac1f5dd4543b76b9f9bdf047ef6\" of type \"GetObjectsObj\". Did you mean \"nearVector\" or \"nearObject\"?', 'path': None}]"
     ]
    }
   ],
   "source": [
    "matched_docs = vectorstore_weviate.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f25750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to supply an index name on initialization\n",
    "index_name = \"karpathy_gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore_new = Weaviate.from_texts(splits, embeddings, client=client, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07f1127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Name in similarity_search_by_vector\n",
      "karpathy_gpt\n",
      "Result\n",
      "{'data': {'Get': {'Karpathy_gpt': [{'text': \"would like to take you through building of micrograd. Now micrograd is this library that I released on GitHub about two years ago but at the time I only uploaded the source code and you'd have to go in by yourself and really figure out how it works. So in this lecture I will take you through it step by step and kind of comment on all the pieces of it. So what is micrograd and why is it interesting? Thank you. Micrograd is basically an autograd engine. Autograd is short for automatic gradient\"}]}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'karpathy_gpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is micrograd?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m matched_docs \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m matched_docs\n",
      "File \u001b[0;32m~/Desktop/AI/langchain-fork/langchain/vectorstores/weaviate.py:178\u001b[0m, in \u001b[0;36mWeaviate.similarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_embedding cannot be None for similarity_search when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_by_text=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AI/langchain-fork/langchain/vectorstores/weaviate.py:227\u001b[0m, in \u001b[0;36mWeaviate.similarity_search_by_vector\u001b[0;34m(self, embedding, k, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_name\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    228\u001b[0m     text \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_key)\n\u001b[1;32m    229\u001b[0m     docs\u001b[38;5;241m.\u001b[39mappend(Document(page_content\u001b[38;5;241m=\u001b[39mtext, metadata\u001b[38;5;241m=\u001b[39mres))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'karpathy_gpt'"
     ]
    }
   ],
   "source": [
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_new.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
