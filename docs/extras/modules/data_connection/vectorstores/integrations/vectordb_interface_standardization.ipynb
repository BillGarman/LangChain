{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328ef72d",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Test that we can both write to and read from an index across several production vectorstores.\n",
    "\n",
    "In particular, the existing documentation often involoves simmply writing to an `index` (e.g., `from_documents`).\n",
    "\n",
    "But, there are two gaps:\n",
    "\n",
    "1) We don't confirm that we can also read an existing index, which appears to be a problem w/ Weviate today.\n",
    "\n",
    "2) We also don't confirm integration w/ hosted instances in all cases (e.g., many are just local). \n",
    "\n",
    "\n",
    "## Example Text\n",
    "\n",
    "Example from Karpathy-GPT app [here](https://github.com/rlancemartin/karpathy-gpt/tree/main/eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "course_txt = open('example_data/karpathy_course_all.txt').read()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "splits = text_splitter.split_text(course_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full course\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "splits = splits[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaac9ed",
   "metadata": {},
   "source": [
    "## Pinecone\n",
    "\n",
    "**Create index** \n",
    "\n",
    "* Use Pinecone console to create a new index with `index_name`\n",
    " \n",
    " ---\n",
    " \n",
    "**Pinecone python client:**\n",
    "\n",
    "* [`Insert`](https://docs.pinecone.io/reference/upsert) by ID:\n",
    "\n",
    "```\n",
    "pinecone.Index(index_name).upsert(vectors=vectors, ids=ids)\n",
    "```\n",
    "\n",
    "* `Update` an existing entry by ID is done by upsert if the ID does not exist in the index:\n",
    "\n",
    "* [`Delete`](https://docs.pinecone.io/reference/delete_post) by ID:\n",
    "```\n",
    "pinecone.Index(index_name).delete(ids=ids_to_delete)\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Langchain:**\n",
    "\n",
    "`Write / Update`\n",
    "\n",
    "* `from_texts` and `add_texts` both using `upsert`\n",
    "* IDs can be supplied\n",
    "\n",
    "```\n",
    "ids = ids or [str(uuid.uuid4()) for _ in texts]\n",
    "docs.append((ids[i], embedding, metadata))\n",
    "self._index.upsert(vectors=docs, namespace=namespace, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "`Read`\n",
    "\n",
    "* Supported from an existing index\n",
    "\n",
    "`Delete`\n",
    "\n",
    "* **Need support for delete**\n",
    "\n",
    "`Update`\n",
    "\n",
    "[Docs](https://python.langchain.com/en/latest/reference/modules/vectorstores.html#langchain.vectorstores.Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f151140",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Auth\n",
    "pinecone.init(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY'),  \n",
    "    environment=\"us-east1-gcp\"  \n",
    ")\n",
    "\n",
    "# Create new index\n",
    "embeddings = OpenAIEmbeddings()\n",
    "index_name = \"karpathy-gpt\"\n",
    "vectorstore_new = Pinecone.from_texts(splits, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35506e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from index\n",
    "vectorstore_pinecone = Pinecone.from_existing_index(index_name=index_name,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_pinecone.similarity_search(query)\n",
    "matched_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc0c3b",
   "metadata": {},
   "source": [
    "## Supabase\n",
    "\n",
    "**Create index** \n",
    "\n",
    "* Create a new project in [Supabase dashboard](https://supabase.com/dashboard/project/xhbejgrankzufmczyqil).\n",
    "* In the project, go to the SQL editor on the left.\n",
    "* We need to create a table to store our embeddings.\n",
    "* We will use `pgvector`, an extension for PostgreSQL that allows you to both store and query vector embeddings.\n",
    "* Create the table in the SQL editor with [this code](https://supabase.com/docs/guides/ai/langchain), modified below for our table name `karpathy_gpt`:\n",
    "\n",
    "```\n",
    "-- Enable the pgvector extension to work with embedding vectors\n",
    "-- create extension vector;\n",
    "\n",
    "-- Create a table to store your documents\n",
    "create table karpathy_gpt (\n",
    "  id bigserial primary key,\n",
    "  content text, -- corresponds to Document.pageContent\n",
    "  metadata jsonb, -- corresponds to Document.metadata\n",
    "  embedding vector(1536) -- 1536 works for OpenAI embeddings, change if needed\n",
    ");\n",
    "\n",
    "-- Create a function to search for documents\n",
    "CREATE OR REPLACE function match_documents (\n",
    "  query_embedding vector(1536),\n",
    "  match_count int default null,\n",
    "  filter jsonb DEFAULT '{}'\n",
    ") returns table (\n",
    "  id bigint,\n",
    "  content text,\n",
    "  metadata jsonb,\n",
    "  similarity float\n",
    ")\n",
    "language plpgsql\n",
    "as $$\n",
    "#variable_conflict use_column\n",
    "begin\n",
    "  return query\n",
    "  select\n",
    "    id,\n",
    "    content,\n",
    "    metadata,\n",
    "    1 - (karpathy_gpt.embedding <=> query_embedding) as similarity\n",
    "  from karpathy_gpt\n",
    "  where metadata @> filter\n",
    "  order by karpathy_gpt.embedding <=> query_embedding\n",
    "  limit match_count;\n",
    "end;\n",
    "$$;\n",
    "```\n",
    "\n",
    "* Now, the table is created!\n",
    "* In the project, you can find `SUPABASE_URL` and `SUPABASE_SERVICE_KEY`, which we will use to connect to this table.\n",
    "\n",
    "---\n",
    "\n",
    "**Python client:**\n",
    "\n",
    "* [`Insert`](https://supabase.com/docs/reference/python/insert) by ID:\n",
    "\n",
    "```\n",
    "client = create_client(supabase_url, supabase_key)\n",
    "data = {'id': 'custom_id', 'name': 'John Doe', 'age': 30}\n",
    "response = client.table(table).insert(data)\n",
    "```\n",
    "\n",
    "* `Update` an existing entry by ID:\n",
    "```\n",
    "client = create_client(supabase_url, supabase_key)\n",
    "condition = {'id': 'your_id'}\n",
    "response = client.table(table).update(data, condition)\n",
    "```\n",
    "\n",
    "* `Delete` by ID:\n",
    "```\n",
    "condition = {'id': 'your_id'}\n",
    "response = client.table(table).delete(condition)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Langchain:**\n",
    "\n",
    "`Write / Update` \n",
    "\n",
    "* `from_texts` and `add_texts` both using `insert`\n",
    "* **Need support for ID-wise write and update**\n",
    "```\n",
    "result = client.from_(table_name).insert(chunk).execute()\n",
    "```\n",
    "\n",
    "`Read` \n",
    "\n",
    "* Supported from an existing index\n",
    "\n",
    "\n",
    "`Delete`\n",
    "\n",
    "* **Need support for delete**\n",
    "\n",
    "[Docs](http://localhost:8888/notebooks/docs/modules/indexes/vectorstores/examples/vector_db_testing.ipynb#Supabase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e251d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c12532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import SupabaseVectorStore\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from supabase.client import Client, create_client\n",
    "# Auth\n",
    "supabase_url = os.environ.get('supabase_url')\n",
    "supabase_key = os.environ.get('supabase_key')\n",
    "supabase: Client = create_client(supabase_url, supabase_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b991ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new index\n",
    "table_name=\"karpathy_gpt\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore_new = SupabaseVectorStore.from_texts(splits,embeddings,client=supabase,table_name=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from index\n",
    "vectorstore_supabase = SupabaseVectorStore(client=supabase,embedding=embeddings,table_name=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c148d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_supabase.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ffa7b",
   "metadata": {},
   "source": [
    "# Elastic\n",
    "\n",
    "**Create index** \n",
    "\n",
    "* Log into Elastic Cloud console at https://cloud.elastic.co\n",
    "* Create deployment\n",
    "* Go to the deployment page and `copy endpoint`\n",
    "\n",
    "---\n",
    "\n",
    "**Python client:**\n",
    "\n",
    "* [`Bulk`](https://elasticsearch-py.readthedocs.io/en/7.x/helpers.html) to add or update documents by specifying the document ID in the request dictionary\n",
    "\n",
    "* `Delete` by ID:\n",
    "\n",
    "```\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "for document_id in document_ids:\n",
    "    es.delete(index=index_name, id=document_id)\n",
    " ```\n",
    "\n",
    "---\n",
    "\n",
    "**Langchain:**\n",
    "\n",
    "`Write / Update` \n",
    "\n",
    "* `from_texts` and `add_texts` both using `bulk()` with an ID passed\n",
    "\n",
    "```\n",
    "for i, text in enumerate(texts):\n",
    "    metadata = metadatas[i] if metadatas else {}\n",
    "    _id = str(uuid.uuid4())\n",
    "    request = {\n",
    "        \"_op_type\": \"index\",\n",
    "        \"_index\": self.index_name,\n",
    "        \"vector\": embeddings[i],\n",
    "        \"text\": text,\n",
    "        \"metadata\": metadata,\n",
    "        \"_id\": _id,\n",
    "    }\n",
    "    ids.append(_id)\n",
    "    requests.append(request)\n",
    "bulk(self.client, requests)\n",
    "```\n",
    "\n",
    "`Read` \n",
    "\n",
    "* Supported from an existing index\n",
    " \n",
    "`Delete`\n",
    "\n",
    "* **Need support for delete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15479bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auth\n",
    "elastic_endpoint = \"langchain-test.es.us-central1.gcp.cloud.es.io\"\n",
    "elasticsearch_url = f\"https://elastic:cYo6rjQMesQbwqcGHblf7P0K@{elastic_endpoint}:9243\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import ElasticVectorSearch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "index_name = \"karpathy-gpt\"\n",
    "\n",
    "# Create new index\n",
    "vectorstore_new = ElasticVectorSearch.from_texts(splits, embeddings, \n",
    "                                                 elasticsearch_url=elasticsearch_url,\n",
    "                                                 index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ab74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_new.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe76eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from index\n",
    "vectorstore_estc = ElasticVectorSearch(elasticsearch_url=elasticsearch_url, index_name=index_name, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c053c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "matched_docs = vectorstore_estc.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d923c",
   "metadata": {},
   "source": [
    "## Weviate\n",
    "\n",
    "**Create index** \n",
    "\n",
    "* Create a new cluser in [Weviate dashboard](https://console.weaviate.cloud/dashboard).\n",
    "* This gives you a url: https://langchain-test-l73n8vle.weaviate.network\n",
    "* `text_key` is the name of the text property in your Weaviate schema where the text of your documents is stored. \n",
    "* It's used to find documents that are similar to a text query.\n",
    "\n",
    "A few notes:\n",
    "\n",
    "* Index names [must be capitalized](https://github.com/weaviate/weaviate/issues/3132#event-9524209890)\n",
    "* Be sure to pass `by_text=False` in the client [when connecting to an existing index](https://github.com/weaviate/weaviate/issues/3142#event-9541172186)\n",
    "\n",
    "---\n",
    "\n",
    "**Python client:**\n",
    "\n",
    "* `add_data_object` is used to add a data object (either create a new one or updating based on ID)\n",
    "* `delete` is easily handled by ID\n",
    "\n",
    "```\n",
    "weaviate_url = \"http://your-weaviate-url:8080\"\n",
    "client = Client(weaviate_url)\n",
    "client.data.delete(uuid=data_object_uuid)\n",
    "```\n",
    "\n",
    "**Langchain:**\n",
    "\n",
    "* `from_texts` and `add_texts` both using `add_data_object()` with an ID passed\n",
    "\n",
    "```\n",
    "# If the UUID of one of the objects already exists\n",
    "# then the existing objectwill be replaced by the new object.\n",
    "if \"uuids\" in kwargs:\n",
    "    _id = kwargs[\"uuids\"][i]\n",
    "else:\n",
    "    _id = get_valid_uuid(uuid4())\n",
    "\n",
    "# if an embedding strategy is not provided, we let\n",
    "# weaviate create the embedding. Note that this will only\n",
    "# work if weaviate has been installed with a vectorizer module\n",
    "# like text2vec-contextionary for example\n",
    "params = {\n",
    "    \"uuid\": _id,\n",
    "    \"data_object\": data_properties,\n",
    "    \"class_name\": index_name,\n",
    "}\n",
    "if embeddings is not None:\n",
    "    params[\"vector\"] = embeddings[i]\n",
    "\n",
    "batch.add_data_object(**params)\n",
    "```\n",
    "\n",
    "`Read` \n",
    "\n",
    "* Supported from an existing index\n",
    " \n",
    "`Delete`\n",
    "\n",
    "* **Need support for delete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from weaviate import Client, auth\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Auth\n",
    "weaviate_url = \"https://langchain-test-l73n8vle.weaviate.network\"\n",
    "client = Client(url=weaviate_url, auth_client_secret=auth.AuthClientPassword(\"lance@langchain.dev\", \"j!ZEFs6pFd.SWH.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and add texts\n",
    "embeddings = OpenAIEmbeddings()\n",
    "index_name = \"Karpathy_gpt\"\n",
    "vectorstore_new = Weaviate.from_texts(\n",
    "    splits, embeddings, client=client, index_name=index_name, text_key=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06580c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_new.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from index\n",
    "vectorstore_weviate = Weaviate(\n",
    "    client=client,\n",
    "    index_name=index_name,\n",
    "    text_key=\"text\",\n",
    "    by_text=False,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"What is micrograd?\"\n",
    "matched_docs = vectorstore_weviate.similarity_search(query,k=1)\n",
    "matched_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4705e",
   "metadata": {},
   "source": [
    "## Redis\n",
    "\n",
    "< TO FINISH > \n",
    "\n",
    "Cloud -\n",
    "\n",
    "* Create database in Redis public cloud, which has endpoint: `redis-16792.c302.asia-northeast1-1.gce.cloud.redislabs.com:16792`\n",
    "* **Need**: Documentation on how to [connect](https://docs.redis.com/latest/rs/references/client_references/client_python/) to this because we still get auth errors.\n",
    "\n",
    "--- \n",
    "\n",
    "Local - \n",
    "  \n",
    "```\n",
    "/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n",
    "brew install redis\n",
    "brew services start redis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474df362",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores.redis import Redis\n",
    "password = \"LangChainTest01!\"\n",
    "public_endpoint = \"redis-18547.c1.us-central1-2.gce.cloud.redislabs.com:18547\"\n",
    "redis_url = f'redis://pexpresss31@gmail.com:{password}@{public_endpoint}'\n",
    "print(redis_url)\n",
    "vectorstore_new = Redis.from_texts(splits,embeddings,redis_url=redis_url,index_name='link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f57fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTH ERROR\n",
    "import urllib.parse\n",
    "password = 'm.fN%A#A8vEwVK6'\n",
    "redis_url=\"redis://redis-16792.c302.asia-northeast1-1.gce.cloud.redislabs.com:16792\"\n",
    "password_encoded = urllib.parse.quote(password)\n",
    "redis_url = f'redis://:{password_encoded}@redis-16792.c302.asia-northeast1-1.gce.cloud.redislabs.com:16792'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
