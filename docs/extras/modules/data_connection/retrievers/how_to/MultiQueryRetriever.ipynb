{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc82b48",
   "metadata": {},
   "source": [
    "# MultiQueryRetriever\n",
    "\n",
    "Distance-based vector database retrieval represents queries in high-dimensional space and finds similar documents based on \"distance\" in this high-dimensional space. One of the biggest drawbacks of this technique is that it doesn't inherently understand context, reason, or semantic meaning. \n",
    "\n",
    "Because it merely considers the position of vectors in high-dimensional space, retrieval might fail to distinguish between different uses of the same word or understand complex relationships between different concepts. Also, if the embeddings do not capture the essential semantics of the data well (as the comment on ada-002 suggests), the technique can produce poor results.\n",
    "\n",
    "Here, we use a LLM to generate multiple queries for a given question, then retrieve a set of relevant documents for each query and take the union of these sets to get a larger set of potentially relevant documents. The idea is that by generating multiple perspectives on the same question, the system might be able to overcome some of the limitations of the distance-based approach and get a richer set of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f3f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load PDF\n",
    "path=\"path_to_files\"\n",
    "loaders = [\n",
    "    PyPDFLoader(path+\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(path+\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(path+\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "    \n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# VectorDB\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents=splits,embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a282f",
   "metadata": {},
   "source": [
    "Pass an `LLMChain` with a specified prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9afb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# LLM chain w/ output parser\n",
    "class LineList(BaseModel):\n",
    "    lines: List[str] = Field(description=\"Lines of text\")\n",
    "\n",
    "class LineListOutputParser(PydanticOutputParser):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(pydantic_object=LineList)\n",
    "\n",
    "    def parse(self, text: str) -> LineList:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        # Retriver expects parsed output to have \"text\"\n",
    "        return LineList(lines=lines)\n",
    "\n",
    "output_parser = LineListOutputParser()\n",
    "    \n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\", \"num_queries\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate {num_queries} \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions seperated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "llm_chain = LLMChain(llm=llm,prompt=QUERY_PROMPT,output_parser=output_parser)\n",
    " \n",
    "# Other inputs\n",
    "question=\"What does the course say about regression?\"\n",
    "num_queries=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6660d7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated queries: ['1. Can you provide me with information on regression covered in the course?', '2. How is regression discussed in the course material?', '3. What topics related to regression are included in the course content?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run\n",
    "retriever = MultiQueryRetriever(retriever=vectordb.as_retriever(), num_queries=num_queries, llm_chain=llm_chain)\n",
    "unique_docs = retriever.get_relevant_documents(question=\"What does the course say about regression?\")\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822d749",
   "metadata": {},
   "source": [
    "Define `from_llm` using the default prompt for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a2acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What does the course say about regression?\"\n",
    "num_queries=3\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectordb.as_retriever(),num_queries=num_queries,llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dddd449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated queries: ['1. Can you provide information on regression covered in the course?', '2. How is regression discussed in the course material?', '3. What topics related to regression are included in the course content?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(question=\"What does the course say about regression?\")\n",
    "len(unique_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
