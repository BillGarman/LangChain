{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0ffe42",
   "metadata": {},
   "source": [
    "# WebResearchRetriever\n",
    "\n",
    "Given a query, this retriever will: \n",
    "\n",
    "* Formulate a set of relate Google searches\n",
    "* Search for each \n",
    "* Load all the resulting URLs\n",
    "* Then embed and perform similarity search with the query on the consolidate page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abea0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.retrievers.web_research import WebResearchRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e57bb",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "Pass the desired model and vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d84ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "# Set input\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "vectorstore = Chroma(embedding_function=OpenAIEmbeddings())\n",
    "GOOGLE_CSE_ID = \"b5e84267513eb4dcf\"\n",
    "GOOGLE_API_KEY = \"AIzaSyDUKwJCpdU6nNwANyA7NC2cXnMfvXD6YcM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f135e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "web_research_retriever = WebResearchRetriever(\n",
    "    vectorstore=vectorstore, \n",
    "    llm=llm, \n",
    "    GOOGLE_CSE_ID=GOOGLE_CSE_ID, \n",
    "    GOOGLE_API_KEY=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c958adc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.web_research:Generating questions for Google Search ...\n",
      "INFO:langchain.retrievers.web_research:Questions for Google Search (raw): {'question': 'How do LLM Powered Autonomous Agents work?', 'text': LineList(lines=['1. What is the definition of LLM Powered Autonomous Agents?', '2. What are the key features of LLM Powered Autonomous Agents?', '3. How do LLM Powered Autonomous Agents differ from traditional autonomous agents?', '4. What are the applications of LLM Powered Autonomous Agents?', '5. Are there any case studies or examples of successful implementations of LLM Powered Autonomous Agents?'])}\n",
      "INFO:langchain.retrievers.web_research:Questions for Google Search: ['1. What is the definition of LLM Powered Autonomous Agents?', '2. What are the key features of LLM Powered Autonomous Agents?', '3. How do LLM Powered Autonomous Agents differ from traditional autonomous agents?', '4. What are the applications of LLM Powered Autonomous Agents?', '5. Are there any case studies or examples of successful implementations of LLM Powered Autonomous Agents?']\n",
      "INFO:langchain.retrievers.web_research:Searching for relevat urls ...\n",
      "INFO:langchain.retrievers.web_research:URLs to load: {'https://towardsdatascience.com/autonomous-agents-and-multi-agent-systems-101-agents-and-deception-f4da3401f92a', 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "INFO:langchain.retrievers.web_research:Grabbing most relevant splits from urls ...\n",
      "Fetching pages: 100%|##############################################################################################################################################| 2/2 [00:02<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.web_research\").setLevel(logging.INFO)\n",
    "user_input = \"How do LLM Powered Autonomous Agents work?\"\n",
    "docs = web_research_retriever.get_relevant_documents(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c07edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663b2ba",
   "metadata": {},
   "source": [
    "`Local -`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62e36e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/rlm/Desktop/Code/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 9132.71 MB (+ 1608.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /Users/rlm/.cache/gpt4all/ggml-all-MiniLM-L6-v2-f16.bin\n",
      "llama_new_context_with_model: max tensor size =    87.89 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x2a58f3710\n",
      "ggml_metal_init: loaded kernel_mul                            0x2a58f4c40\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x2a58f5af0\n",
      "ggml_metal_init: loaded kernel_scale                          0x2a58f3a60\n",
      "ggml_metal_init: loaded kernel_silu                           0x2a58f3cc0\n",
      "ggml_metal_init: loaded kernel_relu                           0x2a58f6260\n",
      "ggml_metal_init: loaded kernel_gelu                           0x2a58f68b0\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x2a58f75b0\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x2a58f7a70\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x2a58f8530\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x2a58f8b90\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x2a58f9390\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x2a58f9bc0\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x2a58fa2b0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x2a58fa980\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x2a58fb070\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x2a58fb7c0\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x2a16e6940\n",
      "ggml_metal_init: loaded kernel_norm                           0x2a16e7440\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x2a16e79e0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x2a16e8aa0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x2a16e9290\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x2a16e8400\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x2a58fc520\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x2a58fc940\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x2a58fd930\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x2a58fe0e0\n",
      "ggml_metal_init: loaded kernel_rope                           0x2a58fe810\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x2a5c04330\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x2a5c04bf0\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x2a16ea2a0\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x2a16ea870\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 21845.34 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  6984.06 MB, ( 6984.52 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =  1040.00 MB, ( 8024.52 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  3202.00 MB, (11226.52 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   597.00 MB, (11823.52 / 21845.34)\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   512.00 MB, (12335.52 / 21845.34)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "objc[82333]: Class GGMLMetalClass is implemented in both /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/llama_cpp/libllama.dylib (0x2a571c208) and /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x2a77c8208). One of the two will be used. Which one is undefined.\n",
      "objc[82333]: Class GGMLMetalClass is implemented in both /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/llama_cpp/libllama.dylib (0x2a571c208) and /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x2b4ca0208). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llama = LlamaCpp(\n",
    "    model_path=\"/Users/rlm/Desktop/Code/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=4096,  # Context window\n",
    "    max_tokens=1000,  # Max tokens to generate\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings())\n",
    "GOOGLE_CSE_ID = \"b5e84267513eb4dcf\"\n",
    "GOOGLE_API_KEY = \"AIzaSyDUKwJCpdU6nNwANyA7NC2cXnMfvXD6YcM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ff3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebResearchRetriever\n",
    "web_research_retriever = WebResearchRetriever(\n",
    "    vectorstore=vectorstore_llama, \n",
    "    llm=llama, \n",
    "    GOOGLE_CSE_ID=GOOGLE_CSE_ID, \n",
    "    GOOGLE_API_KEY=GOOGLE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0898e34c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.web_research:Generating questions for Google Search ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure! Here are five search queries that could help answer the user's question about how LLM powered autonomous agents work:\n",
      "\n",
      "1. \"LLM powered autonomous agents architecture\" - This search query could provide information on the overall design and structure of LLM powered autonomous agents, including the components and interfaces involved in their operation.\n",
      "2. \"How do LLM powered autonomous agents perceive their environment?\" - This search query could provide information on the sensors and other sources of data that LLM powered autonomous agents use to understand their environment and make decisions.\n",
      "3. \"What algorithms and techniques are used in LLM powered autonomous agents for decision making?\" - This search query could provide information on the machine learning and artificial intelligence techniques that are used in LLM powered autonomous agents to enable them to make decisions and take actions based on their environment and objectives.\n",
      "4. \"How do LLM powered autonomous agents learn and improve over time?\" - This search query could provide information on how LLM powered autonomous agents learn from their experiences and adapt to new situations, as well as any techniques or algorithms used for learning and improvement.\n",
      "5. \"What are some examples of real-world applications of LLM powered autonomous agents?\" - This search query could provide information on the types of tasks and industries where LLM powered autonomous agents are being used successfully, such as self-driving cars, robots, or other intelligent systems.\n",
      "\n",
      "These search queries should provide a good starting point for understanding how LLM powered autonomous agents work and their potential applications in various fields."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  7344.40 ms\n",
      "llama_print_timings:      sample time =   245.79 ms /   350 runs   (    0.70 ms per token,  1423.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  7344.26 ms /    99 tokens (   74.18 ms per token,    13.48 tokens per second)\n",
      "llama_print_timings:        eval time = 14318.16 ms /   349 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time = 22399.59 ms\n",
      "INFO:langchain.retrievers.web_research:Questions for Google Search (raw): {'question': 'How do LLM Powered Autonomous Agents work?', 'text': LineList(lines=['1. \"LLM powered autonomous agents architecture\" - This search query could provide information on the overall design and structure of LLM powered autonomous agents, including the components and interfaces involved in their operation.\\n', '2. \"How do LLM powered autonomous agents perceive their environment?\" - This search query could provide information on the sensors and other sources of data that LLM powered autonomous agents use to understand their environment and make decisions.\\n', '3. \"What algorithms and techniques are used in LLM powered autonomous agents for decision making?\" - This search query could provide information on the machine learning and artificial intelligence techniques that are used in LLM powered autonomous agents to enable them to make decisions and take actions based on their environment and objectives.\\n', '4. \"How do LLM powered autonomous agents learn and improve over time?\" - This search query could provide information on how LLM powered autonomous agents learn from their experiences and adapt to new situations, as well as any techniques or algorithms used for learning and improvement.\\n', '5. \"What are some examples of real-world applications of LLM powered autonomous agents?\" - This search query could provide information on the types of tasks and industries where LLM powered autonomous agents are being used successfully, such as self-driving cars, robots, or other intelligent systems.\\n'])}\n",
      "INFO:langchain.retrievers.web_research:Questions for Google Search: ['1. \"LLM powered autonomous agents architecture\" - This search query could provide information on the overall design and structure of LLM powered autonomous agents, including the components and interfaces involved in their operation.\\n', '2. \"How do LLM powered autonomous agents perceive their environment?\" - This search query could provide information on the sensors and other sources of data that LLM powered autonomous agents use to understand their environment and make decisions.\\n', '3. \"What algorithms and techniques are used in LLM powered autonomous agents for decision making?\" - This search query could provide information on the machine learning and artificial intelligence techniques that are used in LLM powered autonomous agents to enable them to make decisions and take actions based on their environment and objectives.\\n', '4. \"How do LLM powered autonomous agents learn and improve over time?\" - This search query could provide information on how LLM powered autonomous agents learn from their experiences and adapt to new situations, as well as any techniques or algorithms used for learning and improvement.\\n', '5. \"What are some examples of real-world applications of LLM powered autonomous agents?\" - This search query could provide information on the types of tasks and industries where LLM powered autonomous agents are being used successfully, such as self-driving cars, robots, or other intelligent systems.\\n']\n",
      "INFO:langchain.retrievers.web_research:Searching for relevat urls ...\n",
      "INFO:langchain.retrievers.web_research:Searching for relevat urls ...\n",
      "INFO:langchain.retrievers.web_research:Search results: [{'Result': 'No good Google Search Result was found'}]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'link'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain.retrievers.web_research\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[1;32m      4\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow do LLM Powered Autonomous Agents work?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mweb_research_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain/libs/langchain/langchain/schema/retriever.py:181\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    184\u001b[0m         result,\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    186\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Code/langchain/libs/langchain/langchain/schema/retriever.py:174\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Desktop/Code/langchain/libs/langchain/langchain/retrievers/web_research.py:125\u001b[0m, in \u001b[0;36mWebResearchRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    123\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m search_results:\n\u001b[0;32m--> 125\u001b[0m         urls_to_look\u001b[38;5;241m.\u001b[39mappend(\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlink\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Load HTML to text\u001b[39;00m\n\u001b[1;32m    128\u001b[0m urls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(urls_to_look)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'link'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.web_research\").setLevel(logging.INFO)\n",
    "user_input = \"How do LLM Powered Autonomous Agents work?\"\n",
    "docs = web_research_retriever.get_relevant_documents(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e06adad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
