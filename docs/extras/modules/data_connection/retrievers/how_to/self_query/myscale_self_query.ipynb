{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13afcae7",
   "metadata": {},
   "source": [
    "# Self-querying with MyScale\n",
    "\n",
    ">[MyScale](https://docs.myscale.com/en/) is an integrated vector database. You can access your database in SQL and also from here, LangChain. MyScale can make a use of [various data types and functions for filters](https://blog.myscale.com/2023/06/06/why-integrated-database-solution-can-boost-your-llm-apps/#filter-on-anything-without-constraints). It will boost up your LLM app no matter if you are scaling up your data or expand your system to broader application.\n",
    "\n",
    "In the notebook we'll demo the `SelfQueryRetriever` wrapped around a MyScale vector store with some extra piece we contributed to LangChain. In short, it can be concluded into 4 points:\n",
    "1. Add `contain` comparator to match list of any if there is more than one element matched\n",
    "2. Add `timestamp` data type for datetime match (ISO-format, or YYYY-MM-DD)\n",
    "3. Add `like` comparator for string pattern search\n",
    "4. Add arbitrary function capability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68e75fb9",
   "metadata": {},
   "source": [
    "## Creating a MyScale vectorstore\n",
    "MyScale has already been integrated to LangChain for a while. So you can follow [this notebook](/docs/modules/data_connection/vectorstores/integrations/myscale.ipynb) to create your own vectorstore for a self-query retriever.\n",
    "\n",
    "NOTE: All self-query retrievers requires you to have `lark` installed (`pip install lark`). We use `lark` for grammar definition. Before you proceed to the next step, we also want to remind you that `clickhouse-connect` is also needed to interact with your MyScale backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8af5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install lark clickhouse-connect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83811610-7df3-4ede-b268-68a6a83ba9e2",
   "metadata": {},
   "source": [
    "In this tutorial we follow other example's setting and use `OpenAIEmbeddings`. Remember to get a OpenAI API Key for valid accesss to LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01b61b-7d32-4a55-85d6-b2d2d4f18840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "os.environ['MYSCALE_HOST'] = getpass.getpass('MyScale URL:')\n",
    "os.environ['MYSCALE_PORT'] = getpass.getpass('MyScale Port:')\n",
    "os.environ['MYSCALE_USERNAME'] = getpass.getpass('MyScale Username:')\n",
    "os.environ['MYSCALE_PASSWORD'] = getpass.getpass('MyScale Password:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a5787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import MyScale\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf7f6fc4",
   "metadata": {},
   "source": [
    "## Create some sample data\n",
    "As you can see, the data we created has some difference to other self-query retrievers. We replaced keyword `year` to `date` which gives you a finer control on timestamps. We also altered the type of keyword `gerne` to list of strings, where LLM can use a new `contain` comparator to construct filters. We also provides comparator `like` and arbitrary function support to filters, which will be introduced in next few cells.\n",
    "\n",
    "Now let's look at the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe04d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    Document(page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\", metadata={\"date\": \"1993-07-02\", \"rating\": 7.7, \"genre\": [\"science fiction\"]}),\n",
    "    Document(page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\", metadata={\"date\": \"2010-12-30\", \"director\": \"Christopher Nolan\", \"rating\": 8.2}),\n",
    "    Document(page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\", metadata={\"date\": \"2006-04-23\", \"director\": \"Satoshi Kon\", \"rating\": 8.6}),\n",
    "    Document(page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\", metadata={\"date\": \"2019-08-22\", \"director\": \"Greta Gerwig\", \"rating\": 8.3}),\n",
    "    Document(page_content=\"Toys come alive and have a blast doing so\", metadata={\"date\": \"1995-02-11\", \"genre\": [\"animated\"]}),\n",
    "    Document(page_content=\"Three men walk into the Zone, three men walk out of the Zone\", metadata={\"date\": \"1979-09-10\", \"rating\": 9.9, \"director\": \"Andrei Tarkovsky\", \"genre\": [\"science fiction\", \"adventure\"], \"rating\": 9.9})\n",
    "]\n",
    "vectorstore = MyScale.from_documents(\n",
    "    docs, \n",
    "    embeddings, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ecaab6d",
   "metadata": {},
   "source": [
    "## Creating our self-querying retriever\n",
    "Just like other retrievers... Simple and nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e34dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info=[\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genres of the movie\", \n",
    "        type=\"list[string]\", \n",
    "    ),\n",
    "    # If you want to include length of a list, just define it as a new column\n",
    "    # This will teach the LLM to use it as a column when constructing filter.\n",
    "    AttributeInfo(\n",
    "        name=\"length(genre)\",\n",
    "        description=\"The length of genres of the movie\", \n",
    "        type=\"integer\", \n",
    "    ),\n",
    "    # Now you can define a column as timestamp. By simply set the type to timestamp.\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"The date the movie was released\", \n",
    "        type=\"timestamp\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\", \n",
    "        type=\"string\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\",\n",
    "        description=\"A 1-10 rating for the movie\",\n",
    "        type=\"float\"\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Brief summary of a movie\"\n",
    "llm = OpenAI(temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(llm, vectorstore, document_content_description, metadata_field_info, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea9df8d4",
   "metadata": {},
   "source": [
    "## Testing it out with self-query retriever's existing functionalities\n",
    "And now we can try actually using our retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a126e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example only specifies a relevant query\n",
    "retriever.get_relevant_documents(\"What are some movies about dinosaurs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f1e6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This example only specifies a filter\n",
    "retriever.get_relevant_documents(\"I want to watch a movie rated higher than 8.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example specifies a query and a filter\n",
    "retriever.get_relevant_documents(\"Has Greta Gerwig directed any movies about women\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example specifies a composite filter\n",
    "retriever.get_relevant_documents(\"What's a highly rated (above 8.5) science fiction film?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a51522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example specifies a query and composite filter\n",
    "retriever.get_relevant_documents(\"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86371ac8",
   "metadata": {},
   "source": [
    "# Wait a second... What else?\n",
    "\n",
    "Self-query retriever with MyScale can do more! Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d043096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use length(genres) to do anything you want\n",
    "retriever.get_relevant_documents(\"What's a movie that have more than 1 genres?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-grained datetime? You got it already.\n",
    "retriever.get_relevant_documents(\"What's a movie that release after feb 1995?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't know what your exact filter should be? Use string pattern match!\n",
    "retriever.get_relevant_documents(\"What's a movie whose name is like Andrei?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a514104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contain works for lists: so you can match a list with contain comparator!\n",
    "retriever.get_relevant_documents(\"What's a movie who has genres science fiction and adventure?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39bd1de1-b9fe-4a98-89da-58d8a7a6ae51",
   "metadata": {},
   "source": [
    "## Filter k\n",
    "\n",
    "We can also use the self query retriever to specify `k`: the number of documents to fetch.\n",
    "\n",
    "We can do this by passing `enable_limit=True` to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff36b88-b506-4877-9c63-e5a1a8d78e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, \n",
    "    vectorstore, \n",
    "    document_content_description, \n",
    "    metadata_field_info, \n",
    "    enable_limit=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758d229-4f97-499c-819f-888acaf8ee10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This example only specifies a relevant query\n",
    "retriever.get_relevant_documents(\"what are two movies about dinosaurs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25c52b0",
   "metadata": {},
   "source": [
    "## SQL Self-Query Retriever with MyScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f824b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install clickhouse-sqlalchemy InstructorEmbedding sentence_transformers openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7af1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ['OPENAI_API_BASE'] = 'https://one-api.myscale.cloud/v1'\n",
    "import getpass\n",
    "from typing import Dict, Any\n",
    "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain, LLMChain\n",
    "from sqlalchemy import create_engine, Column, MetaData\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "MYSCALE_HOST = \"msc-1decbcc9.us-east-1.aws.staging.myscale.cloud\"\n",
    "MYSCALE_PORT = 443\n",
    "MYSCALE_USER = \"chatdata\"\n",
    "MYSCALE_PASSWORD = \"myscale_rocks\"\n",
    "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "engine = create_engine(f'clickhouse://{MYSCALE_USER}:{MYSCALE_PASSWORD}@{MYSCALE_HOST}:{MYSCALE_PORT}/default?protocol=https')\n",
    "environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eceb0f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangruil/anaconda3/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.chains.sql_database.parser import VectorSQLOutputParser\n",
    "    \n",
    "output_parser = VectorSQLOutputParser.from_embeddings(model=HuggingFaceInstructEmbeddings(model_name='hkunlp/instructor-xl', model_kwargs={'device':'cpu'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b3e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_684103/2054588486.py:3: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  metadata = MetaData(bind=engine)\n",
      "/home/fangruil/.local/lib/python3.10/site-packages/clickhouse_sqlalchemy/drivers/base.py:273: SAWarning: Did not recognize type 'Object('json')' of column 'metadata'\n",
      "  warn(\"Did not recognize type '%s' of column '%s'\" %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Please give me 10 papers to ask what is PageRank?\n",
      "SQLQuery:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangruil/langchain/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a MyScale expert. Given an input question, first create a syntactically correct MyScale query to run, then look at the results of the query and return the answer to the input question.\n",
      "MyScale queries has a vector distance function called `DISTANCE(column, array)` to compute relevance to the user's question and sort the feature array column by the relevance. \n",
      "When the query is asking for 10 closest row, you have to use this distance function to calculate distance to entity's array on vector column and order by the distance to retrieve relevant rows.\n",
      "\n",
      "*NOTICE*: `DISTANCE(column, array)` only accept an array column as its first argument and a `NeuralArray(entity)` as its second argument. You also need a user defined function called `NeuralArray(entity)` to retrieve the entity's array. \n",
      "\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 10 results using the LIMIT clause as per MyScale. You should only order according to the distance function.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use today() function to get the current date, if the question involves \"today\". `ORDER BY` clause should always be after `WHERE` clause. DO NOT add semicolon to the end of SQL. Pay attention to the comment in table schema.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: \"Question here\"\n",
      "SQLQuery: \"SQL Query to run\"\n",
      "SQLResult: \"Result of the SQLQuery\"\n",
      "Answer: \"Final answer here\"\n",
      "Only use the following tables:\n",
      "\n",
      "CREATE TABLE \"ChatArXiv\" (\n",
      "\tabstract String, \n",
      "\tid String, \n",
      "\tvector Array(Float32), \n",
      "\tpubdate DateTime, \n",
      "\ttitle String, \n",
      "\tcategories Array(String), \n",
      "\tauthors Array(String), \n",
      "\tcomment String, \n",
      "\tprimary_category String\n",
      ") ENGINE = ReplicatedReplacingMergeTree('/clickhouse/tables/bb56d04b-baf0-4676-b051-64fe88c4377c/{shard}', '{replica}')\n",
      " ORDER BY id\n",
      " PRIMARY KEY id\n",
      "\n",
      "/*\n",
      "3 rows from ChatArXiv table:\n",
      "abstract\tid\tvector\tpubdate\ttitle\tcategories\tauthors\tcomment\tprimary_category\n",
      "  Adaptive networks appear in many biological applications. They combine\n",
      "topological evolution of th\thttp://arxiv.org/abs/0709.1858v2\t[0.007527284,-0.0030175236,0.009047618,-0.04547687,-0.06116927,-0.07906006,-0.06741533,0.0097926,-0.\t2007-09-12 21:26:00\tAdaptive Coevolutionary Networks: A Review\t['physics.soc-ph','cond-mat.stat-mech','q-bio.PE']\t['Thilo Gross','Bernd Blasius']\t13 pages, 5 figures\tphysics.soc-ph\n",
      "  Experimental analysis of data from particle collisions is typically expressed\n",
      "as statistical limit\thttp://arxiv.org/abs/1203.6642v3\t[0.012555987,0.012607349,-0.004974116,-0.020995466,-0.058307458,-0.042527035,-0.07622006,0.009503578\t2012-03-30 03:45:09\tReinterpretion of Experimental Results with Basis Templates\t['hep-ex','hep-ph']\t['Kanishka Rao','Daniel Whiteson']\t\thep-ex\n",
      "  We study the relationship between derived categories of factorizations on\n",
      "gauged Landau-Ginzburg m\thttp://arxiv.org/abs/1203.6643v4\t[-0.004498747,0.0004967965,0.012601328,-0.0291525,-0.06666261,-0.07153263,-0.073795326,0.011703003,-\t2012-03-30 03:45:37\tVariation of geometric invariant theory quotients and derived categories\t['math.AG']\t['Matthew Ballard','David Favero','Ludmil Katzarkov']\tUpdated references and addresses\tmath.AG\n",
      "*/\n",
      "\n",
      "Question: Please give me 10 papers to ask what is PageRank?\n",
      "SQLQuery:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSELECT id, title, authors, comment FROM ChatArXiv ORDER BY DISTANCE(vector, NeuralArray('PageRank')) LIMIT 10;\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[{'id': 'http://arxiv.org/abs/1002.2858v3', 'title': 'PageRank: Standing on the shoulders of giants', 'authors': ['Massimo Franceschet'], 'comment': ''}, {'id': 'http://arxiv.org/abs/1312.1904v1', 'title': 'The PageRank Problem, Multi-Agent Consensus and Web Aggregation -- A\\n  Systems and Control Viewpoint', 'authors': ['Hideaki Ishii', 'Roberto Tempo'], 'comment': ''}, {'id': 'http://arxiv.org/abs/2304.12232v1', 'title': 'Variational Quantum PageRank', 'authors': ['Christopher Sims'], 'comment': '9 pages, 1 figure'}, {'id': 'http://arxiv.org/abs/0712.0469v1', 'title': 'Multiple equilibria of nonhomogeneous Markov chains and self-validating\\n  web rankings', 'authors': ['Marianne Akian', 'Stephane Gaubert', 'Laure Ninove'], 'comment': '22 pages, 4 figures'}, {'id': 'http://arxiv.org/abs/1509.01476v1', 'title': 'Ranking nodes in growing networks: When PageRank fails', 'authors': ['Manuel Sebastian Mariani', 'Matus Medo', 'Yi-Cheng Zhang'], 'comment': 'Article + Supplementary Information'}, {'id': 'http://arxiv.org/abs/1908.00235v2', 'title': 'A Hessenberg-type Algorithm for Computing PageRank Problems', 'authors': ['Xian-Ming Gu', 'Siu-Long Lei', 'Ke Zhang', 'Zhao-Li Shen', 'Chun Wen', 'Bruno Carpentieri'], 'comment': '4 Figures, 6 Tables. 19 pages, the current version has been improved\\n  further and accepted by {\\\\em Numerical Algorithms}'}, {'id': 'http://arxiv.org/abs/1709.02858v1', 'title': 'Advanced Page Rank Algorithm with Semantics, In Links, Out Links and\\n  Google Analytics', 'authors': ['Aritra Banerjee', 'Shrey Choudhary'], 'comment': '6 pages, 2 figures, Published with International Journal of Computer\\n  Trends and Technology (IJCTT)'}, {'id': 'http://arxiv.org/abs/0912.1828v1', 'title': 'Using social annotation and web log to enhance search engine', 'authors': ['Vu Thanh Nguyen'], 'comment': 'International Journal of Computer Science Issues, IJCSI Volume 6,\\n  Issue 2, pp1-6, November 2009'}, {'id': 'http://arxiv.org/abs/1012.4872v1', 'title': 'PageRank for ranking authors in co-citation networks', 'authors': ['Ying Ding', 'Erjia Yan', 'Arthur Frazho', 'James Caverlee'], 'comment': '19 pages, 7 figures'}, {'id': 'http://arxiv.org/abs/1105.1062v2', 'title': 'Universal Emergence of PageRank', 'authors': ['K. M. Frahm', 'B. Georgeot', 'D. L. Shepelyansky'], 'comment': 'research at http://www.quantware.ups-tlse.fr/ 18 pages, 7 figures\\n  discussion updates'}]\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/1002.2858v3</td>\n",
       "      <td>PageRank: Standing on the shoulders of giants</td>\n",
       "      <td>[Massimo Franceschet]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/1312.1904v1</td>\n",
       "      <td>The PageRank Problem, Multi-Agent Consensus an...</td>\n",
       "      <td>[Hideaki Ishii, Roberto Tempo]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/2304.12232v1</td>\n",
       "      <td>Variational Quantum PageRank</td>\n",
       "      <td>[Christopher Sims]</td>\n",
       "      <td>9 pages, 1 figure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/0712.0469v1</td>\n",
       "      <td>Multiple equilibria of nonhomogeneous Markov c...</td>\n",
       "      <td>[Marianne Akian, Stephane Gaubert, Laure Ninove]</td>\n",
       "      <td>22 pages, 4 figures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/1509.01476v1</td>\n",
       "      <td>Ranking nodes in growing networks: When PageRa...</td>\n",
       "      <td>[Manuel Sebastian Mariani, Matus Medo, Yi-Chen...</td>\n",
       "      <td>Article + Supplementary Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://arxiv.org/abs/1908.00235v2</td>\n",
       "      <td>A Hessenberg-type Algorithm for Computing Page...</td>\n",
       "      <td>[Xian-Ming Gu, Siu-Long Lei, Ke Zhang, Zhao-Li...</td>\n",
       "      <td>4 Figures, 6 Tables. 19 pages, the current ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://arxiv.org/abs/1709.02858v1</td>\n",
       "      <td>Advanced Page Rank Algorithm with Semantics, I...</td>\n",
       "      <td>[Aritra Banerjee, Shrey Choudhary]</td>\n",
       "      <td>6 pages, 2 figures, Published with Internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://arxiv.org/abs/0912.1828v1</td>\n",
       "      <td>Using social annotation and web log to enhance...</td>\n",
       "      <td>[Vu Thanh Nguyen]</td>\n",
       "      <td>International Journal of Computer Science Issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://arxiv.org/abs/1012.4872v1</td>\n",
       "      <td>PageRank for ranking authors in co-citation ne...</td>\n",
       "      <td>[Ying Ding, Erjia Yan, Arthur Frazho, James Ca...</td>\n",
       "      <td>19 pages, 7 figures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://arxiv.org/abs/1105.1062v2</td>\n",
       "      <td>Universal Emergence of PageRank</td>\n",
       "      <td>[K. M. Frahm, B. Georgeot, D. L. Shepelyansky]</td>\n",
       "      <td>research at http://www.quantware.ups-tlse.fr/ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0   http://arxiv.org/abs/1002.2858v3   \n",
       "1   http://arxiv.org/abs/1312.1904v1   \n",
       "2  http://arxiv.org/abs/2304.12232v1   \n",
       "3   http://arxiv.org/abs/0712.0469v1   \n",
       "4  http://arxiv.org/abs/1509.01476v1   \n",
       "5  http://arxiv.org/abs/1908.00235v2   \n",
       "6  http://arxiv.org/abs/1709.02858v1   \n",
       "7   http://arxiv.org/abs/0912.1828v1   \n",
       "8   http://arxiv.org/abs/1012.4872v1   \n",
       "9   http://arxiv.org/abs/1105.1062v2   \n",
       "\n",
       "                                               title  \\\n",
       "0      PageRank: Standing on the shoulders of giants   \n",
       "1  The PageRank Problem, Multi-Agent Consensus an...   \n",
       "2                       Variational Quantum PageRank   \n",
       "3  Multiple equilibria of nonhomogeneous Markov c...   \n",
       "4  Ranking nodes in growing networks: When PageRa...   \n",
       "5  A Hessenberg-type Algorithm for Computing Page...   \n",
       "6  Advanced Page Rank Algorithm with Semantics, I...   \n",
       "7  Using social annotation and web log to enhance...   \n",
       "8  PageRank for ranking authors in co-citation ne...   \n",
       "9                    Universal Emergence of PageRank   \n",
       "\n",
       "                                             authors  \\\n",
       "0                              [Massimo Franceschet]   \n",
       "1                     [Hideaki Ishii, Roberto Tempo]   \n",
       "2                                 [Christopher Sims]   \n",
       "3   [Marianne Akian, Stephane Gaubert, Laure Ninove]   \n",
       "4  [Manuel Sebastian Mariani, Matus Medo, Yi-Chen...   \n",
       "5  [Xian-Ming Gu, Siu-Long Lei, Ke Zhang, Zhao-Li...   \n",
       "6                 [Aritra Banerjee, Shrey Choudhary]   \n",
       "7                                  [Vu Thanh Nguyen]   \n",
       "8  [Ying Ding, Erjia Yan, Arthur Frazho, James Ca...   \n",
       "9     [K. M. Frahm, B. Georgeot, D. L. Shepelyansky]   \n",
       "\n",
       "                                             comment  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                  9 pages, 1 figure  \n",
       "3                                22 pages, 4 figures  \n",
       "4                Article + Supplementary Information  \n",
       "5  4 Figures, 6 Tables. 19 pages, the current ver...  \n",
       "6  6 pages, 2 figures, Published with Internation...  \n",
       "7  International Journal of Computer Science Issu...  \n",
       "8                                19 pages, 7 figures  \n",
       "9  research at http://www.quantware.ups-tlse.fr/ ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "metadata = MetaData(bind=engine)\n",
    "\n",
    "from langchain.chains.sql_database.base import SQLDatabaseChain\n",
    "from langchain.chains.sql_database.prompt import MYSCALE_PROMPT\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "chain = SQLDatabaseChain(\n",
    "    llm_chain=LLMChain(llm=OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0), prompt=MYSCALE_PROMPT, output_parser=output_parser), \n",
    "    top_k=10,\n",
    "    return_direct=True,\n",
    "    database=SQLDatabase(engine, None, metadata),\n",
    "    native_format=True)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(chain.run(\"Please give me 10 papers to ask what is PageRank?\", callbacks=[StdOutCallbackHandler()]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d6b1385",
   "metadata": {},
   "source": [
    "## SQL Database as Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864ad4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fangruil/langchain/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 papers that discuss PageRank:\n",
      "\n",
      "1. \"PageRank: Standing on the shoulders of giants\" by Massimo Franceschet (2010) [SOURCE](http://arxiv.org/abs/1002.2858v3)\n",
      "2. \"The PageRank Problem, Multi-Agent Consensus and Web Aggregation -- A Systems and Control Viewpoint\" by Hideaki Ishii and Roberto Tempo (2013) [SOURCE](http://arxiv.org/abs/1312.1904v1)\n",
      "3. \"Variational Quantum PageRank\" by Christopher Sims (2023) [SOURCE](http://arxiv.org/abs/2304.12232v1)\n",
      "4. \"Multiple equilibria of nonhomogeneous Markov chains and self-validating web rankings\" by Marianne Akian, Stephane Gaubert, and Laure Ninove (2007) [SOURCE](http://arxiv.org/abs/0712.0469v1)\n",
      "5. \"Ranking nodes in growing networks: When PageRank fails\" by Manuel Sebastian Mariani, Matus Medo, and Yi-Cheng Zhang (2015) [SOURCE](http://arxiv.org/abs/1509.01476v1)\n",
      "6. \"A Hessenberg-type Algorithm for Computing PageRank Problems\" by Xian-Ming Gu, Siu-Long Lei, Ke Zhang, Zhao-Li Shen, Chun Wen, and Bruno Carpentieri (2019) [SOURCE](http://arxiv.org/abs/1908.00235v2)\n",
      "7. \"Advanced Page Rank Algorithm with Semantics, In Links, Out Links and Google Analytics\" by Aritra Banerjee and Shrey Choudhary (2017) [SOURCE](http://arxiv.org/abs/1709.02858v1)\n",
      "8. \"Using social annotation and web log to enhance search engine\" by Vu Thanh Nguyen (2009) [SOURCE](http://arxiv.org/abs/0912.1828v1)\n",
      "9. \"PageRank for ranking authors in co-citation networks\" by Ying Ding, Erjia Yan, Arthur Frazho, and James Caverlee (2010) [SOURCE](http://arxiv.org/abs/1012.4872v1)\n",
      "10. \"Universal Emergence of PageRank\" by K. M. Frahm, B. Georgeot, and D. L. Shepelyansky (2011) [SOURCE](http://arxiv.org/abs/1105.1062v2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import SQLDatabaseChainRetriever\n",
    "from langchain.chains.sql_database.parser import VectorSQLRetrieveAllOutputParser\n",
    "from langchain.chains.qa_with_sources.retrieval import RetrievalQAWithSourcesChain\n",
    "\n",
    "output_parser_retrieve_all = VectorSQLRetrieveAllOutputParser.from_embeddings(output_parser.model)\n",
    "\n",
    "chain = SQLDatabaseChain.from_llm(\n",
    "    llm=OpenAI(openai_api_key=OPENAI_API_KEY, temperature=0),\n",
    "    prompt=MYSCALE_PROMPT, \n",
    "    top_k=10,\n",
    "    return_direct=True,\n",
    "    db=SQLDatabase(engine, None, metadata),\n",
    "    sql_cmd_parser=output_parser_retrieve_all,\n",
    "    native_format=True)\n",
    "\n",
    "# You need all those keys to get docs\n",
    "retriever = SQLDatabaseChainRetriever(sql_db_chain=chain, page_content_key='abstract')\n",
    "\n",
    "document_with_metadata_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\", \"id\", \"title\", \"authors\", \"pubdate\", \"categories\"],\n",
    "    template=\"Content:\\n\\tTitle: {title}\\n\\tAbstract: {page_content}\\n\\tAuthors: {authors}\\n\\tpubdate: {pubdate}\\n\\tCategories: {categories}\\nSOURCE: {id}\")\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(model_name='gpt-3.5-turbo-16k', openai_api_key=OPENAI_API_KEY, temperature=0.6), \n",
    "    retriever=retriever,\n",
    "    chain_type='stuff', \n",
    "    chain_type_kwargs = {'document_prompt': document_with_metadata_prompt,},\n",
    "    return_source_documents=True)\n",
    "ans = chain(\"Please give me 10 papers to ask what is PageRank?\")\n",
    "print(ans['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1dddf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
