{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe57ac5-31c5-4dbb-b96c-78dead32e1bd",
   "metadata": {},
   "source": [
    "# Indexing Basics\n",
    "\n",
    "Here, we will look at a basic indexing workflow using the LangChain indexing API.\n",
    "\n",
    "The main features of the API are to help:\n",
    "\n",
    "* Avoid writing duplicated content into the vectostore\n",
    "* Avoid over-writing content if it's unchanged\n",
    "\n",
    "The indexing API will work even if working with documents that have gone several \n",
    "transformation steps (e.g., via text chunking) w/ respect to the original source document.\n",
    "\n",
    "## How\n",
    "\n",
    "LangChain indexing makes use of an persistence layer (`RecordManager`) that keeps track of document writes into the vectostore.\n",
    "\n",
    "When indexing content, hashes are computed for each document, and the following information is stored in the record manager: \n",
    "\n",
    "- the document hash (hashed content of both page content and metadata)\n",
    "- write time\n",
    "- the source id -- each document should include information in its metadata to allow us determining the ultimate source of this document\n",
    "\n",
    "## Deletion Modes\n",
    "\n",
    "Indexing has 3 deletion modes:\n",
    "\n",
    "| Delete Mode | De-Duplicates Content | Parallelizable | Handles Deletion of Source Docs | Handles Mutations of Source Docs and/or Derived Docs | Clean Up Timing   |\n",
    "|-------------|-----------------------|---------------|----------------------------------|----------------------------------------------------|---------------------|\n",
    "| None        | ✅                    | ✅            | ❌                               | ❌                                                 | -                  |\n",
    "| Incremental | ✅                    | ✅            | ❌                               | ✅                                                 | Continuously       |\n",
    "| Full        | ✅                    | ❌            | ✅                               | ✅                                                 | At end of indexing |\n",
    "\n",
    "\n",
    "* If the source document has been deleted, only the `full` delete mode will be able to delete it from the vectorstore correctly.\n",
    "* If the source document has been mutated or documents derived from it have been changed (e.g., by changing chunking parameters), either `incremental` or `full` modes will be able to clean up the previous versions of the content.\n",
    "\n",
    "\n",
    "When content is mutated (e.g., the source PDF file was revised) there will be a period of time during indexing when both the new and old versions may be returned to the user. This happens after the new content was written, but before the old version was deleted.\n",
    "\n",
    "* `incremental` indexing minimizes this period of time as it able to do clean up continuously.\n",
    "* `full` mode does the clean up after all batches have been written.\n",
    "\n",
    "## Vectorstore Requirements\n",
    "\n",
    "This code only works with LangChain Vectorstores that support:\n",
    "\n",
    "* document addition by id (`add_documents` method with `ids` argument)\n",
    "* delete by id (`delete` method with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05922847-5e17-4402-9d91-e96688a57cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebc9af8-a194-40f5-ab5f-50b1d506c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5127fd7b-1fcd-4e09-82e6-59d00ad0b3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers.txt import TextParser\n",
    "from langchain.document_loaders import DocumentPipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from typing import Iterator, List, Optional, Sequence\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.schema import BaseDocumentTransformer, Document\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import LanceDB\n",
    "import lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6b868a-3516-4b73-980f-4782aa5e655a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[91mYour system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\u001b[0m\u001b[94mPlease visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[1;32m      3\u001b[0m embedder \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[0;32m----> 4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/langchain/libs/langchain/langchain/vectorstores/chroma.py:81\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with Chroma client.\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/langchain_310_p1/lib/python3.10/site-packages/chromadb/__init__.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m         sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpysqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91mYour system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94mPlease visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override Chroma's default settings, environment variables or .env files\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[91mYour system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\u001b[0m\u001b[94mPlease visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\u001b[0m"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedder = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(embedding_function=embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4854b3-69a3-42bb-8e80-5acf806dbdc1",
   "metadata": {},
   "source": [
    "**Suggestion** Use a namespace that takes into account both the vectostore and the collection name in the vectorstore; e.g., 'chromadb/my_docs' or 'postgres/my_docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cc80e-c339-49ee-893b-b18d06346ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "namespace = 'my_docs'\n",
    "record_manager = SQLRecordManager(namespace, db_url=\"sqlite:///record_manager_cache.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c2c19-68ec-4086-9066-f7ba40877fd5",
   "metadata": {},
   "source": [
    "Create a schema before using the record manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be2da3-3a5c-468a-a824-560157290f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_manager.create_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46496bf6-e3f4-4110-9e08-d06d0557b603",
   "metadata": {},
   "source": [
    "Instantiate vector db with cached backed embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07c6bd-6ada-4b17-a8c5-fe5e4a5278fd",
   "metadata": {},
   "source": [
    "Create a vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4cdf812-4977-43c1-a2c4-d34c0f965993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = lancedb.connect(\"/tmp/lancedb\")\n",
    "# table = db.create_table(\n",
    "#     \"my_table\",\n",
    "#     data=[\n",
    "#         {\n",
    "#             \"vector\": embedder.embed_query(\"Hello World\"),\n",
    "#             \"text\": \"Hello World\",\n",
    "#             \"id\": \"1\",\n",
    "#         }\n",
    "#     ],\n",
    "#     mode=\"overwrite\",\n",
    "# )\n",
    "# table = db.open_table('my_table')\n",
    "# vectorstore = LanceDB(table, embedding=embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b235c-eab7-4682-9a7a-5d0fbc6dacfa",
   "metadata": {},
   "source": [
    "Let's create some test data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1b6d497-529c-4382-8bf7-7ae04924afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.vectorstores import Chroma\n",
    "\n",
    "# faiss = Chroma(embedding_function=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85212091-0166-4604-a492-1c2b65155834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "sample_data_dir = tempfile.mkdtemp(prefix=\"sample_data\")\n",
    "\n",
    "text1_content = \"hello said the little kitty\"\n",
    "text2_content = \"byebye said the big doggy\"\n",
    "\n",
    "with open(os.path.join(sample_data_dir, \"text1.txt\"), \"w\") as text1_file:\n",
    "    text1_file.write(text1_content)\n",
    "\n",
    "with open(os.path.join(sample_data_dir, \"text2.txt\"), \"w\") as text2_file:\n",
    "    text2_file.write(text2_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dea359-d3c6-4353-9cde-cd328c3ce6d5",
   "metadata": {},
   "source": [
    "We'll be loading these files and splitting them using a text splitter and then indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddad4260-fd11-4ca7-a1a2-ebacd95faaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_loader = GenericLoader.from_filesystem(\n",
    "    sample_data_dir, glob=\"*.txt\", parser=TextParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ccda14-86b5-455a-ae53-7d8b542e96df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='hello said the little kitty', metadata={'source': '/tmp/sample_data92gr1kxd/text1.txt'}),\n",
       " Document(page_content='byebye said the big doggy', metadata={'source': '/tmp/sample_data92gr1kxd/text2.txt'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(file_loader.lazy_load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae1fc7a-c527-4dbb-b033-1019f9174fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "index(file_loader, record_manager, vectorstore, delete_mode='incremental', source_id_key='source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3498262-c11f-4538-a83c-2b16ee9ca0ce",
   "metadata": {},
   "source": [
    "If we try to re-run it again, no content will be re-written since the original content has not changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "82f925dd-c3a0-4a57-9f66-34549c6ab55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.98 ms, sys: 4.67 ms, total: 11.6 ms\n",
      "Wall time: 27.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "index(file_loader, record_manager, vectorstore, delete_mode='incremental', source_id_key='source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e819d7-efde-4e1f-8aeb-6ac3cb167f8f",
   "metadata": {},
   "source": [
    "## Run an update!\n",
    "\n",
    "Change the loader to only pick up 1 of the files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9deb6977-d250-47e4-9f7a-cf4e4b28c260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_loader = GenericLoader.from_filesystem(\n",
    "    sample_data_dir, glob=\"text1.txt\", parser=TextParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "02863705-b667-44a2-9ac6-b49843ba5fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='hello said the little kitty', metadata={'source': '/tmp/sample_data4z34vlfe/text1.txt'})]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(file_loader.lazy_load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9aee22-d2ba-4cc7-99c9-cda3e6a3771d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac630da2-11c0-4f47-80b8-73cae33a6d34",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "610ca611-a425-4ee0-86d4-9ef9afc5f807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamped_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timestamped_set' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index(pipeline_loader, record_manager, vectorstore, delete_mode='incremental', source_id_key='source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746832e7-ec69-4f4f-97d6-ba610f77a252",
   "metadata": {
    "tags": []
   },
   "source": [
    "Run another update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7faf435f-0954-4c38-bbb6-b1d37b487054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 21, which is longer than the specified 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.24 ms, sys: 9.44 ms, total: 18.7 ms\n",
      "Wall time: 45.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 4, 'num_deleted': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "index(pipeline_loader, record_manager, vectorstore, delete_mode='incremental', source_id_key='source')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa024a6f-6a33-4bbc-9be8-c96853d06dd8",
   "metadata": {},
   "source": [
    "# More complex pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8dc12f-d7d1-43b5-a3bd-a8190f58884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's create a document pipeline to make i\n",
    "\n",
    "class Pipeline(BaseLoader):\n",
    "    \"\"\"A document pipeline that can be used to load documents.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        loader: BaseLoader,\n",
    "        *,\n",
    "        transformers: Sequence[BaseDocumentTransformer] = (),\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the document pipeline.\n",
    "        Args:\n",
    "            loader: The loader to use for loading the documents.\n",
    "            transformers: The transformers to use for transforming the documents.\n",
    "        \"\"\"\n",
    "        self.loader = loader\n",
    "        self.transformers = transformers\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"Fetch the data from the data selector.\"\"\"\n",
    "        try:\n",
    "            documents = self.loader.lazy_load()\n",
    "        except NotImplementedError:\n",
    "            documents = iter(self.loader.load())\n",
    "\n",
    "        for document in documents:\n",
    "            _docs = [document]\n",
    "            for transformer in self.transformers:\n",
    "                # List below is needed because of typing issue in langchain\n",
    "                _docs = list(transformer.transform_documents(_docs))\n",
    "            yield from _docs\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Fetch the data from the data selector.\"\"\"\n",
    "        raise NotImplementedError(\"Use lazy_load instead\")\n",
    "\n",
    "    def load_and_split(\n",
    "        self, text_splitter: Optional[TextSplitter] = None\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Fetch the data from the data selector.\"\"\"\n",
    "        raise NotImplementedError(\"Use lazy_load instead\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
