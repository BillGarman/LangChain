{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7cc773",
   "metadata": {},
   "source": [
    "# Recursive URL Loader\n",
    "\n",
    "We may want to process load all URLs under a root directory.\n",
    "\n",
    "For example, let's look at the [LangChain JS documentation](https://js.langchain.com/docs/).\n",
    "\n",
    "This has many interesting child pages that we may want to read in bulk.\n",
    "\n",
    "Of course, the `WebBaseLoader` can load a list of pages. \n",
    "\n",
    "But, the challenge is traversing the tree of child pages and actually assembling that list!\n",
    " \n",
    "We do this using the `RecursiveUrlLoader`.\n",
    "\n",
    "This also gives us the flexibility to exclude some children (e.g., the `api` directory with > 800 child pages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3532b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders.recursive_url_loader import RecursiveUrlLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384c057",
   "metadata": {},
   "source": [
    "Let's try a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69e5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://js.langchain.com/docs/modules/memory/examples/\"\n",
    "loader = RecursiveUrlLoader(url=url)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084fb2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851105c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\nMomento-Backed Chat Memory | ü¶úÔ∏èüîó Langchain\\n\\n\\n\\n\\n\\nSkip to main contentü¶úÔ∏èüîó LangChainConceptsPython DocsJS/TS DocsGitHubCTRLKWelcome to LangChainGetting StartedSetup and InstallationQuickstart, using LLMsQuickstart, using Chat ModelsComponentsSchemaModelsPromptsIndexesMemoryExamplesBuffer MemoryUsing Buffer Memory with Chat ModelsBuffer Window MemoryConversation SummaryDynamoDB-Backed Chat MemoryEntity MemoryMomento-Backed Chat MemoryMot√∂rhead MemoryRedis-Backed Chat MemoryUpstash Redis-Backed Chat MemoryVectorStore-Backed MemoryZep MemoryChainsAgentsUse CasesPersonal AssistantsQuestion AnsweringTabular Question AnsweringInteracting with APIsSummarizationAgent SimulationsAutonomous AgentsProductionEvents /\\u200b CallbacksDeploymentTracingEcosystemAPI ReferenceComponentsMemoryExamplesMomento-Backed Chat MemoryMomento-Backed Chat MemoryFor distributed, serverless persistence across chat sessions, you can swap in a Momento-backed chat message history.\\nBecause a Momento cache is instantly available and requires zero infrastructure maintenance, it\\'s a great way to get started with chat history whether building locally or in production.Setup\\u200bYou will need to install the Momento Client Library in your project:npmYarnpnpmnpm install @gomomento/sdkyarn add @gomomento/sdkpnpm add @gomomento/sdkYou will also need an API key from Momento. You can sign up for a free account here.Usage\\u200bTo distinguish one chat history session from another, we need a unique sessionId. You may also provide an optional sessionTtl to make sessions expire after a given number of seconds.import {  CacheClient,  Configurations,  CredentialProvider,} from \"@gomomento/sdk\";import { BufferMemory } from \"langchain/memory\";import { ChatOpenAI } from \"langchain/chat_models/openai\";import { ConversationChain } from \"langchain/chains\";import { MomentoChatMessageHistory } from \"langchain/stores/message/momento\";// See https://github.com/momentohq/client-sdk-javascript for connection optionsconst client = new CacheClient({  configuration: Configurations.Laptop.v1(),  credentialProvider: CredentialProvider.fromEnvironmentVariable({    environmentVariableName: \"MOMENTO_AUTH_TOKEN\",  }),  defaultTtlSeconds: 60 * 60 * 24,});// Create a unique session IDconst sessionId = new Date().toISOString();const cacheName = \"langchain\";const memory = new BufferMemory({  chatHistory: await MomentoChatMessageHistory.fromProps({    client,    cacheName,    sessionId,    sessionTtl: 300,  }),});console.log(  `cacheName=${cacheName} and sessionId=${sessionId} . This will be used to store the chat history. You can inspect the values at your Momento console at https://console.gomomento.com.`);const model = new ChatOpenAI({  modelName: \"gpt-3.5-turbo\",  temperature: 0,});const chain = new ConversationChain({ llm: model, memory });const res1 = await chain.call({ input: \"Hi! I\\'m Jim.\" });console.log({ res1 });/*{  res1: {    text: \"Hello Jim! It\\'s nice to meet you. My name is AI. How may I assist you today?\"  }}*/const res2 = await chain.call({ input: \"What did I just say my name was?\" });console.log({ res2 });/*{  res1: {    text: \"You said your name was Jim.\"  }}*/// See the chat history in the Momentoconsole.log(await memory.chatHistory.getMessages());API Reference:BufferMemory from langchain/memoryChatOpenAI from langchain/chat_models/openaiConversationChain from langchain/chainsMomentoChatMessageHistory from langchain/stores/message/momentoEdit this pagePreviousEntity MemoryNextMot√∂rhead MemoryCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc.\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13bd7e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://js.langchain.com/docs/modules/memory/examples/momento',\n",
       " 'title': 'Momento-Backed Chat Memory | ü¶úÔ∏èüîó Langchain',\n",
       " 'description': 'For distributed, serverless persistence across chat sessions, you can swap in a Momento-backed chat message history.',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc13ef",
   "metadata": {},
   "source": [
    "Now, let's try a more extensive example, the `docs` root dir.\n",
    "\n",
    "We will skip everything under `api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a278ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://js.langchain.com/docs/'\n",
    "exclude_dirs=['https://js.langchain.com/docs/api/']\n",
    "loader=RecursiveUrlLoader(url=url,exclude_dirs=exclude_dirs)\n",
    "\n",
    "# Lazy load to yield docs while crawling\n",
    "docs = [print(doc) or doc for doc in loader.lazy_load()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca80b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\nSetup and Installation | ü¶úÔ∏èüîó Langchain\\n\\n\\n\\n\\n\\nS'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df97cf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://js.langchain.com/docs/getting-started/install',\n",
       " 'title': 'Setup and Installation | ü¶úÔ∏èüîó Langchain',\n",
       " 'description': 'Updating from <0.0.52? See this section for instructions.',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
