{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4462a94",
   "metadata": {},
   "source": [
    "# Manifest\n",
    "\n",
    "This notebook goes over how to use Manifest and LangChain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59fcaebc",
   "metadata": {},
   "source": [
    "For more detailed information on `manifest`, and how to use it with local hugginface models like in this example, see https://github.com/HazyResearch/manifest\n",
    "\n",
    "Another example of [using Manifest with Langchain](https://github.com/HazyResearch/manifest/blob/main/examples/langchain_chatgpt.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205d1e4-e6da-4d67-a0c7-b7e8fd1e98d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install manifest-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a0170a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from manifest import Manifest\n",
    "from langchain.llms.manifest import ManifestWrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5149112e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de250a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "manifest = Manifest(\n",
    "    client_name=\"huggingface\", client_connection=\"http://127.0.0.1:5000\"\n",
    ")\n",
    "print(manifest.client.get_model_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b719d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ManifestWrapper(\n",
    "    client=manifest, llm_kwargs={\"temperature\": 0.001, \"max_tokens\": 256}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af505a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map reduce example\n",
    "from langchain import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "\n",
    "\n",
    "_prompt = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "\n",
    "{text}\n",
    "\n",
    "\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate(template=_prompt, input_variables=[\"text\"])\n",
    "\n",
    "text_splitter = CharacterTextSplitter()\n",
    "\n",
    "mp_chain = MapReduceChain.from_params(llm, prompt, text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "mp_chain.run(state_of_the_union)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e9d45a8",
   "metadata": {},
   "source": [
    "## Compare HF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33407ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.laboratory import ModelLaboratory\n",
    "\n",
    "manifest1 = ManifestWrapper(\n",
    "    client=Manifest(\n",
    "        client_name=\"huggingface\", client_connection=\"http://127.0.0.1:5000\"\n",
    "    ),\n",
    "    llm_kwargs={\"temperature\": 0.01},\n",
    ")\n",
    "manifest2 = ManifestWrapper(\n",
    "    client=Manifest(\n",
    "        client_name=\"huggingface\", client_connection=\"http://127.0.0.1:5001\"\n",
    "    ),\n",
    "    llm_kwargs={\"temperature\": 0.01},\n",
    ")\n",
    "manifest3 = ManifestWrapper(\n",
    "    client=Manifest(\n",
    "        client_name=\"huggingface\", client_connection=\"http://127.0.0.1:5002\"\n",
    "    ),\n",
    "    llm_kwargs={\"temperature\": 0.01},\n",
    ")\n",
    "llms = [manifest1, manifest2, manifest3]\n",
    "model_lab = ModelLaboratory(llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448935c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lab.compare(\"What color is a flamingo?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "51b9b5b89a4976ad21c8b4273a6c78d700e2954ce7d7452948b7774eb33bbce4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
