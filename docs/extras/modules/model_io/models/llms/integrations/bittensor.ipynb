{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6674b6",
   "metadata": {},
   "source": [
    "# NIBittensorLLM\n",
    "\n",
    "[ngrok Validator Endpoint](https://6860-65-108-32-175.ngrok-free.app/chat) A ngrok web url to post user prompt to get request from top bittensor miners showing potential of decentralized AI.\n",
    "\n",
    "This example goes over how to use LangChain to interact with LLM models via the `Bittensor Validator Endpoint` API integration.\n",
    "\n",
    "This Decentralized Bittensor LLM developed by Neural Internet Org.\n",
    "\n",
    "If you do not get any response then please understand we are scalling the system. In case of any difficulties or queries reach out to our developer [Github@Kunj-2206](https://github.com/Kunj-2206)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5add21",
   "metadata": {},
   "source": [
    "##  Using NIBittensorLLM with LLMChain and PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms.bittensor import NIBittensorLLM\n",
    "\n",
    "langchain.debug = True\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# System parameter in NIBittensorLLM is optional but you can set whatever you want to perform with model\n",
    "llm = NIBittensorLLM(system=\"Your task is to determine response based on user prompt\")\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"What is bittensor?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20166791",
   "metadata": {},
   "source": [
    "##  Using NIBittensorLLM with Conversational Agent with Google Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb57901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import (\n",
    "    AgentType,\n",
    "    initialize_agent,\n",
    "    load_tools,\n",
    "    ZeroShotAgent,\n",
    "    Tool,\n",
    "    AgentExecutor,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.utilities import GoogleSearchAPIWrapper, SerpAPIWrapper\n",
    "from langchain.llms.bittensor import NIBittensorLLM\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "\n",
    "prefix = \"\"\"SYSTEM: You are NIBittensorLLM and your task is to answer user prompt. Answer prompt based on LLM if there is need to search something then use internet and observe internet result and give accurate reply of user questions also try to use authenticated sources\"\"\"\n",
    "suffix = \"\"\"Begin!\n",
    "            {chat_history}\n",
    "            Question: {input}\n",
    "            {agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "llm = NIBittensorLLM(system=\"Your task is to determine response based on user prompt\")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "response = agent_chain.run(input=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aad74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
