{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "FPF4vhdZyJ7S"
   },
   "source": [
    "# KoboldAI API\n",
    "\n",
    "[KoboldAI](https://github.com/KoboldAI/KoboldAI-Client) is a browser-based front-end for AI-assisted writing, supporting multiple local and remote AI models. KoboldAI provides a public and local API that can be utilized with the LangChain library.\n",
    "\n",
    "This tutorial will guide you on how to use LangChain with the KoboldAI API.\n",
    "\n",
    "You can find detailed information on the parameters [here](https://api.python.langchain.com/en/latest/llms/langchain.llms.koboldai.KoboldApiLLM.html).\n",
    "\n",
    "To start KoboldAI, follow these instructions:\n",
    "\n",
    "- Windows: Run 'remoteplay.bat' for a public endpoint.\n",
    "- Linux: Use `play.sh --remote` for a public endpoint or  `./play.sh --host XXX.XXX.XXX.0/24 --port 5000` for a local endpoint.\n",
    "\n",
    "Once the endpoint is active, you can connect to it using LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyzOsRRTf_Vr"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import KoboldApiLLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1a_H7mvfy51O"
   },
   "source": [
    "Replace the endpoint seen below with the one shown in the output after starting it with the correct arguments. \n",
    "\n",
    "Optionally, you can pass in parameters like temperature or max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3vGebq8f_Vr"
   },
   "outputs": [],
   "source": [
    "\n",
    "llm = KoboldApiLLM(endpoint=\"http://127.0.0.1:5000\", max_length=80, temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "\n",
    "langchain.debug = True\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
