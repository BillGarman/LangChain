{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6574496-b360-4ffa-9523-7fd34a590164",
   "metadata": {},
   "source": [
    "# Async API\n",
    "\n",
    "GigaChain предоставляет асинхронную поддержку LLMs с использованием библиотеки [asyncio](https://docs.python.org/3/library/asyncio.html).\n",
    "\n",
    "Поддержка асинхронности особенно полезна для одновременного вызова нескольких LLM, поскольку эти вызовы привязаны к сети. На данный момент поддерживаются: `GigaChat`, `OpenAI`, `PromptLayerOpenAI`, `ChatOpenAI`, `Anthropic` и `Cohere`. Поддержка других LLM будет добавлена в будущем.\n",
    "\n",
    "Вы можете использовать метод `agenerate` чтобы обращаться к LLM асинхронно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e49e96c-0f88-466d-b3d3-ea0966bdf19e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кошка поймала мышку и съела ее.\n",
      "Кошка спит на окне, солнце светит ярко.\n",
      "Луна светит ярко, а звезды блестят на черном небе.\n",
      "Маленький зверек бежал по лесу, стараясь не попасться на глаза хищникам.\n",
      "Я видел падающую звезду, но она не долетела до земли.\n",
      "Яблоко падает на голову Ньютона, и он открывает закон всемирного тяготения.\n",
      "Яблоко падает на голову Ньютона, и он открывает закон всемирного тяготения.\n",
      "Кошка и мышь играют в прятки. Кошка всегда находит, а мышка никогда не может найти кошку.\n",
      "В лесу жила маленькая мышка, которая любила собирать ягоды. Однажды она нашла большой орех и решила его попробовать.\n",
      "В лесу жил маленький зайчик, который любил прыгать и играть с друзьями. Но однажды он попал в ловушку охотника и был вынужден жить в клетке. Он никогда не забывал свою свободу и продолжал мечтать о том, чтобы снова стать свободным.\n",
      "\u001b[1mConcurrent executed in 1.87 seconds.\u001b[0m \n",
      "\n",
      "\n",
      "Я не могу придумать короткий рассказ, так как я — текстовый бот. Но если вы хотите, чтобы я помог вам с чем-то другим, пожалуйста, сообщите мне об этом.\n",
      "Луна была полной, когда она заметила маленького лисенка, который заблудился в лесу. Она помогла ему найти дорогу домой и они стали лучшими друзьями.\n",
      "Луна медленно поднималась над горизонтом, освещая темные деревья и спокойную воду озера.\n",
      "Кошка спит на окне, рядом с цветами.\n",
      "Луна упала на Землю.\n",
      "Я видел сон, в котором я был бабочкой и летал над полем цветов.\n",
      "Кошка поймала мышку и съела ее.\n",
      "Луна была полной, когда она села на вершину горы и заплакала.\n",
      "Я придумал короткий рассказ до 10 символов: \n",
      "В лесу жила маленькая фея, которая летала на своей волшебной палочке и исполняла желания всех, кто к ней обращался.\n",
      "Луна была полной, когда она упала на Землю.\n",
      "\u001b[1mSerial executed in 8.08 seconds.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "giga = GigaChat(oauth_token=..., temperature=1)\n",
    "\n",
    "messages = [SystemMessage(content=\"Придумай короткий рассказ до 10 символов.\")]\n",
    "\n",
    "\n",
    "async def async_generate():\n",
    "    resp = await giga.ainvoke(messages)\n",
    "    print(resp.content)\n",
    "\n",
    "\n",
    "async def generate_concurrently():\n",
    "    tasks = [async_generate() for _ in range(10)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "async def generate_serially():\n",
    "    for i in range(10):\n",
    "        await async_generate()\n",
    "\n",
    "\n",
    "s = time.perf_counter()\n",
    "await generate_concurrently()\n",
    "elapsed = time.perf_counter() - s\n",
    "print(\"\\033[1m\" + f\"Concurrent executed in {elapsed:0.2f} seconds.\" + \"\\033[0m \\n\\n\")\n",
    "\n",
    "s = time.perf_counter()\n",
    "await generate_serially()\n",
    "elapsed = time.perf_counter() - s\n",
    "print(\"\\033[1m\" + f\"Serial executed in {elapsed:0.2f} seconds.\" + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3a966-3a27-44e8-9441-ed72f01b86f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
