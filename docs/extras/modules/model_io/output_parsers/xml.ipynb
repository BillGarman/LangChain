{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181b5b6d",
   "metadata": {},
   "source": [
    "# XML parser\n",
    "This output parser allows users to obtain results from LLM in the popular XML format. \n",
    "\n",
    "Keep in mind that large language models are leaky abstractions! You'll have to use an LLM with sufficient capacity to generate well-formed XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b10fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import XMLOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909161d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateusz/Documents/Projects/langchain/libs/langchain/langchain/llms/openai.py:200: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/mateusz/Documents/Projects/langchain/libs/langchain/langchain/llms/openai.py:787: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.0\n",
    "model = OpenAI(model_name=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ba8d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<filmography>\n",
      "    <actor name=\"Tom Hanks\">\n",
      "        <film>\n",
      "            <title>Forrest Gump</title>\n",
      "            <year>1994</year>\n",
      "        </film>\n",
      "        <film>\n",
      "            <title>Saving Private Ryan</title>\n",
      "            <year>1998</year>\n",
      "        </film>\n",
      "        <film>\n",
      "            <title>Cast Away</title>\n",
      "            <year>2000</year>\n",
      "        </film>\n",
      "        <film>\n",
      "            <title>The Da Vinci Code</title>\n",
      "            <year>2006</year>\n",
      "        </film>\n",
      "        <film>\n",
      "            <title>Toy Story</title>\n",
      "            <year>1995</year>\n",
      "        </film>\n",
      "        <film>\n",
      "            <title>Toy Story 2</title>\n",
      "            <year>1999</year>\n",
      "        </film>\n",
      "        <film>\n",
      "            <title>Toy Story 3</title>\n",
      "            <year>2010</year>\n",
      "        </film>\n",
      "    </actor>\n",
      "</filmography>\n"
     ]
    }
   ],
   "source": [
    "actor_query = \"Generate the filmography for Tom Hanks.\"\n",
    "\n",
    "parser = XMLOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(query=actor_query)\n",
    "\n",
    "output = model(_input.to_string())\n",
    "\n",
    "parsed = parser.parse(output)\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722a235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
