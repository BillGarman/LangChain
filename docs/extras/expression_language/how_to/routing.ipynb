{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b47436a",
   "metadata": {},
   "source": [
    "# Route between multiple Runnables\n",
    "\n",
    "This notebook covers how to do routing in the LangChain Expression Language.\n",
    "\n",
    "Routing allows you to create non-deterministic chains where the output of a previous step defines the next step. Routing helps provide structure and consistency around interactions with LLMs.\n",
    "\n",
    "There are two ways to perform routing:\n",
    "\n",
    "1. Using a `RunnableBranch`.\n",
    "2. Writing custom factory function that takes the input of a previous step and returns a **runnable**. Importantly, this should return a **runnable** and NOT actually execute.\n",
    "\n",
    "We'll illustrate both methods using a two step sequence where the first step classifies an input question as being about `LangChain`, `Anthropic`, or `Other`, then routes to a corresponding prompt chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885113d",
   "metadata": {},
   "source": [
    "## Using a RunnableBranch\n",
    "\n",
    "A `RunnableBranch` is initialized with a list of (condition, runnable) pairs and a default runnable. It selects which branch by passing each condition the input it's invoked with. It selects the first condition to evaluate to True, and runs the corresponding runnable to that condition with the input. \n",
    "\n",
    "If no provided conditions match, it runs the default runnable.\n",
    "\n",
    "Here's an example of what it looks like in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa13c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84c59a",
   "metadata": {},
   "source": [
    "First, let's create a chain that will identify incoming questions as being about `LangChain`, `Anthropic`, or `Other`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec03886",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = PromptTemplate.from_template(\"\"\"Given the user question below, classify it as either being about `LangChain`, `Anthropic`, or `Other`.\n",
    "                                     \n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\") | ChatAnthropic() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ae7c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Anthropic'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"how do I call Anthropic?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0a365",
   "metadata": {},
   "source": [
    "Now, let's create three sub chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d479962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chain = PromptTemplate.from_template(\"\"\"You are an expert in langchain. \\\n",
    "Always answer questions starting with \"As Harrison Chase told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()\n",
    "anthropic_chain = PromptTemplate.from_template(\"\"\"You are an expert in anthropic. \\\n",
    "Always answer questions starting with \"As Dario Amodei told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()\n",
    "general_chain = PromptTemplate.from_template(\"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593eab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "  (lambda x: \"anthropic\" in x[\"topic\"].lower(), anthropic_chain),\n",
    "  (lambda x: \"langchain\" in x[\"topic\"].lower(), langchain_chain),\n",
    "  general_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752c732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29231bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Dario Amodei told me, here are a few tips for using Anthropic:\\n\\n- Sign up for an account at anthropic.com to get access to their AI assistant Claude. \\n\\n- Interact with Claude through natural conversation. Ask questions, give instructions, have discussions etc and Claude will respond.\\n\\n- Provide feedback to Claude when it responds accurately or inaccurately. This helps Claude improve over time.\\n\\n- Use Claude for a variety of tasks like writing, research, answering questions and more. Explore what it's capable of.\\n\\n- Check out the Anthropic blog and documentation for tips, examples and ideas on how to make the most of Claude.\\n\\n- Remember that Claude is still an AI in development. Be patient with it and keep providing feedback to improve it.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthropic?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67d8733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Harrison Chase told me, to use LangChain you simply ask it questions in natural language, just as you would ask another person, and it will attempt to provide helpful responses. You can ask about a wide range of topics, and LangChain will do its best to give useful information by searching its knowledge base. The key is to ask clear, specific questions so that it can understand exactly what you want to know. LangChain gets smarter over time as it learns from more conversations, so feel free to follow up if its first response doesn't fully address your question. The more you use it, the better it will become at having natural conversations and providing you with meaningful answers.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935ad949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' 4', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"whats 2 + 2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d042c",
   "metadata": {},
   "source": [
    "## Using a custom function\n",
    "\n",
    "You can also use a custom function to route between different outputs. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687492da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    inputs = {\"question\": lambda x: x[\"question\"]}\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return inputs | anthropic_chain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return inputs | langchain_chain\n",
    "    else:\n",
    "        return inputs | general_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a33c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e977a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb#Y146sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m full_chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mhow do I use Anthroipc?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:1158\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1157\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 1158\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   1159\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1160\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   1161\u001b[0m             patch_config(\n\u001b[1;32m   1162\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1163\u001b[0m             ),\n\u001b[1;32m   1164\u001b[0m         )\n\u001b[1;32m   1165\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:1930\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m   1924\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1925\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   1926\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1927\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   1928\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[1;32m   1929\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfunc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\n\u001b[1;32m   1931\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke,\n\u001b[1;32m   1932\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   1933\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_config(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc),\n\u001b[1;32m   1934\u001b[0m         )\n\u001b[1;32m   1935\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1936\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1937\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1938\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `ainvoke` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1939\u001b[0m         )\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:321\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type)\u001b[0m\n\u001b[1;32m    314\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    315\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    316\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[1;32m    317\u001b[0m     run_type\u001b[39m=\u001b[39mrun_type,\n\u001b[1;32m    318\u001b[0m     name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    319\u001b[0m )\n\u001b[1;32m    320\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(func, \u001b[39minput\u001b[39;49m, run_manager, config)\n\u001b[1;32m    322\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    323\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/config.py:158\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    157\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 158\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:1864\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\n\u001b[1;32m   1859\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1860\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   1861\u001b[0m     run_manager: CallbackManagerForChainRun,\n\u001b[1;32m   1862\u001b[0m     config: RunnableConfig,\n\u001b[1;32m   1863\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[0;32m-> 1864\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39minput\u001b[39;49m, run_manager, config)\n\u001b[1;32m   1865\u001b[0m     \u001b[39m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/config.py:158\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, run_manager, config)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    157\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 158\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb#Y146sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroute\u001b[39m(info):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb#Y146sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39manthropic\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m info[\u001b[39m\"\u001b[39m\u001b[39mtopic\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlower():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb#Y146sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m info \u001b[39m|\u001b[39;49m anthropic_chain\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb#Y146sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlangchain\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m info[\u001b[39m\"\u001b[39m\u001b[39mtopic\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlower():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacoblee/langchain/langchain/docs/extras/expression_language/how_to/routing.ipynb#Y146sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m info \u001b[39m|\u001b[39m langchain_chain\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:1141\u001b[0m, in \u001b[0;36mRunnableSequence.__ror__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[39mreturn\u001b[39;00m RunnableSequence(\n\u001b[1;32m   1135\u001b[0m         first\u001b[39m=\u001b[39mother\u001b[39m.\u001b[39mfirst,\n\u001b[1;32m   1136\u001b[0m         middle\u001b[39m=\u001b[39mother\u001b[39m.\u001b[39mmiddle \u001b[39m+\u001b[39m [other\u001b[39m.\u001b[39mlast] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle,\n\u001b[1;32m   1137\u001b[0m         last\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast,\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m     \u001b[39mreturn\u001b[39;00m RunnableSequence(\n\u001b[0;32m-> 1141\u001b[0m         first\u001b[39m=\u001b[39mcoerce_to_runnable(other),\n\u001b[1;32m   1142\u001b[0m         middle\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle,\n\u001b[1;32m   1143\u001b[0m         last\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast,\n\u001b[1;32m   1144\u001b[0m     )\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:2206\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39mreturn\u001b[39;00m RunnableLambda(thing)\n\u001b[1;32m   2205\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(thing, \u001b[39mdict\u001b[39m):\n\u001b[0;32m-> 2206\u001b[0m     runnables: Mapping[\u001b[39mstr\u001b[39m, Runnable[Any, Any]] \u001b[39m=\u001b[39m {\n\u001b[1;32m   2207\u001b[0m         key: coerce_to_runnable(r) \u001b[39mfor\u001b[39;00m key, r \u001b[39min\u001b[39;00m thing\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   2208\u001b[0m     }\n\u001b[1;32m   2209\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Runnable[Input, Output], RunnableMap(steps\u001b[39m=\u001b[39mrunnables))\n\u001b[1;32m   2210\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:2207\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39mreturn\u001b[39;00m RunnableLambda(thing)\n\u001b[1;32m   2205\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(thing, \u001b[39mdict\u001b[39m):\n\u001b[1;32m   2206\u001b[0m     runnables: Mapping[\u001b[39mstr\u001b[39m, Runnable[Any, Any]] \u001b[39m=\u001b[39m {\n\u001b[0;32m-> 2207\u001b[0m         key: coerce_to_runnable(r) \u001b[39mfor\u001b[39;00m key, r \u001b[39min\u001b[39;00m thing\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   2208\u001b[0m     }\n\u001b[1;32m   2209\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Runnable[Input, Output], RunnableMap(steps\u001b[39m=\u001b[39mrunnables))\n\u001b[1;32m   2210\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/langchain/langchain/libs/langchain/langchain/schema/runnable/base.py:2211\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   2209\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Runnable[Input, Output], RunnableMap(steps\u001b[39m=\u001b[39mrunnables))\n\u001b[1;32m   2210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2211\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2212\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected a Runnable, callable or dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2213\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInstead got an unsupported type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(thing)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2214\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthroipc?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48913dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Harrison Chase told me, here is how you use LangChain:\\n\\nLangChain is an AI assistant that can have natural conversations and provide helpful information. To use LangChain, simply chat with it in a conversational way, asking questions or making requests. It will try to understand what you are asking and provide an appropriate response. \\n\\nYou can ask LangChain open-ended questions, and it will generate thoughtful answers drawing from its broad knowledge. Or you can ask it for specifics, like definitions of words, calculations, or facts about certain topics. LangChain aims to have nuanced, high-quality conversations spanning many subjects.\\n\\nSome tips for using LangChain effectively:\\n\\n- Ask clear, straightforward questions and state requests plainly. Don't use too much slang or figures of speech that could confuse it.\\n\\n- You can follow up on its responses by asking for clarification, additional details, examples, etc. Having a back-and-forth conversation helps LangChain better understand you.\\n\\n- If you get a response that doesn't seem adequate, try rephrasing your question and asking it in a different way.\\n\\n- Let it know when its responses are helpful, incorrect, or could be improved. Providing feedback\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a14d0dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' 4', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"whats 2 + 2\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
