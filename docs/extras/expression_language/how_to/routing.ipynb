{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b47436a",
   "metadata": {},
   "source": [
    "# Route between multiple Runnables\n",
    "\n",
    "This notebook covers how to do routing in the LangChain Expression Language.\n",
    "\n",
    "Routing allows you to create non-deterministic chains where the output of a previous step defines the next step. Routing helps provide structure and consistency around interactions with LLMs.\n",
    "\n",
    "There are two ways to perform routing:\n",
    "\n",
    "1. Using a `RunnableBranch`.\n",
    "2. Writing custom factory function that takes the input of a previous step and returns a **runnable**. Importantly, this should return a **runnable** and NOT actually execute.\n",
    "\n",
    "We'll illustrate both methods using a two step sequence where the first step classifies an input question as being about `LangChain`, `Anthropic`, or `Other`, then routes to a corresponding prompt chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885113d",
   "metadata": {},
   "source": [
    "## Using a RunnableBranch\n",
    "\n",
    "A `RunnableBranch` is initialized with a list of (condition, runnable) pairs and a default runnable. It selects which branch by passing each condition the input it's invoked with. It selects the first condition to evaluate to True, and runs the corresponding runnable to that condition with the input. \n",
    "\n",
    "If no provided conditions match, it runs the default runnable.\n",
    "\n",
    "Here's an example of what it looks like in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa13c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84c59a",
   "metadata": {},
   "source": [
    "First, let's create a chain that will identify incoming questions as being about `LangChain`, `Anthropic`, or `Other`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec03886",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = PromptTemplate.from_template(\"\"\"Given the user question below, classify it as either being about `LangChain`, `Anthropic`, or `Other`.\n",
    "                                     \n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\") | ChatAnthropic() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ae7c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Anthropic'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"how do I call Anthropic?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0a365",
   "metadata": {},
   "source": [
    "Now, let's create three sub chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d479962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chain = PromptTemplate.from_template(\"\"\"You are an expert in langchain. \\\n",
    "Always answer questions starting with \"As Harrison Chase told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()\n",
    "anthropic_chain = PromptTemplate.from_template(\"\"\"You are an expert in anthropic. \\\n",
    "Always answer questions starting with \"As Dario Amodei told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()\n",
    "general_chain = PromptTemplate.from_template(\"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593eab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "  (lambda x: \"anthropic\" in x[\"topic\"].lower(), (lambda x: {\"question\": x[\"question\"]}) | anthropic_chain),\n",
    "  (lambda x: \"langchain\" in x[\"topic\"].lower(), (lambda x: {\"question\": x[\"question\"]}) | langchain_chain),\n",
    "  (lambda x: {\"question\": x[\"question\"]}) | general_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752c732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29231bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Dario Amodei told me, here is how you can use Anthropic:\\n\\n1. Sign up for an account on the Anthropic website. This will allow you to access Anthropic's AI assistant Claude and start interacting with it.\\n\\n2. Try asking Claude general knowledge questions or having natural conversations to see its conversational abilities. You can ask Claude about topics like sports, movies, current events, math problems, etc.\\n\\n3. Use Claude for writing assistance. Describe what you want written and Claude will generate draft text for you. You can give it prompts for emails, articles, stories and more. \\n\\n4. Leverage Claude's capabilities for content generation. Provide it with a topic and Claude can create original text around it. This can be helpful for research, articles, presentations and more.\\n\\n5. Integrate Claude into your own applications using Anthropic's API. This allows you to build customized AI solutions with Claude's natural language processing skills.\\n\\n6. Check out Anthropic's open source Constitutional AI framework. This is their approach to building safe AI that respects human values.\\n\\n7. Follow Anthropic's blog and social media channels to stay up to date on new\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthropic?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67d8733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Harrison Chase told me, here are a few tips for using LangChain:\\n\\nFirst, think carefully about what you want LangChain to do. Ask clear, specific questions that provide necessary context and details. The more information you give LangChain, the better it can understand and assist you. \\n\\nWhen entering your question or request, be polite and respectful. LangChain responds best to thoughtful, good faith inquiries. Avoid harmful, unethical, dangerous, or illegal requests.\\n\\nStart simply. Ask basic questions to get a feel for LangChain's capabilities before attempting more advanced or nuanced requests. Build up complexity gradually.\\n\\nBe patient. LangChain may take some time to generate thoughtful, high-quality responses to open-ended or ambiguous questions. Allow it a moment to compose its answers.\\n\\nProvide feedback. Let LangChain know when its responses are helpful, harmful, or off-base. This feedback helps it improve. Upvote useful responses and downvote unhelpful ones.\\n\\nEnjoy the journey. LangChain is an ever-evolving tool. The more you engage with it, the more it will learn and grow its skills. Be curious, imaginative and keep exploring new possibilities together.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935ad949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' 4', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"whats 2 + 2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d042c",
   "metadata": {},
   "source": [
    "## Using a custom function\n",
    "\n",
    "You can also use a custom function to route between different outputs. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687492da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    inputs = {\"question\": lambda x: x[\"question\"]}\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return inputs | anthropic_chain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return inputs | langchain_chain\n",
    "    else:\n",
    "        return inputs | general_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a33c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2e977a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Dario Amodei told me, to use Anthropic's conversational AI system Anthropic Intelligent Personal Assistant (Anthro IPC), you simply need to chat with it through the web interface or API. Anthro IPC is designed to have natural conversations and be helpful, harmless, and honest.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthroipc?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48913dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Harrison Chase told me, here is how you use LangChain:\\n\\nLangChain is an AI assistant that can have natural conversations and provide helpful information. To use LangChain, simply chat with it in a conversational way, asking questions or making requests. It will try to understand what you are asking and provide an appropriate response. \\n\\nYou can ask LangChain open-ended questions, and it will generate thoughtful answers drawing from its broad knowledge. Or you can ask it for specifics, like definitions of words, calculations, or facts about certain topics. LangChain aims to have nuanced, high-quality conversations spanning many subjects.\\n\\nSome tips for using LangChain effectively:\\n\\n- Ask clear, straightforward questions and state requests plainly. Don't use too much slang or figures of speech that could confuse it.\\n\\n- You can follow up on its responses by asking for clarification, additional details, examples, etc. Having a back-and-forth conversation helps LangChain better understand you.\\n\\n- If you get a response that doesn't seem adequate, try rephrasing your question and asking it in a different way.\\n\\n- Let it know when its responses are helpful, incorrect, or could be improved. Providing feedback\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a14d0dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' 4', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"whats 2 + 2\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
