{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b47436a",
   "metadata": {},
   "source": [
    "# Route between multiple Runnables\n",
    "\n",
    "This notebook covers how to do routing in the LangChain Expression Language.\n",
    "\n",
    "Routing allows you to create non-deterministic chains where the output of a previous step defines the next step. Routing helps provide structure and consistency around interactions with LLMs.\n",
    "\n",
    "There are two ways to perform routing:\n",
    "\n",
    "1. Using a `RunnableBranch`.\n",
    "2. Writing custom factory function that takes the input of a previous step and returns a **runnable**. Importantly, this should return a **runnable** and NOT actually execute.\n",
    "\n",
    "We'll illustrate both methods using a two step sequence where the first step classifies an input question as being about `LangChain`, `Anthropic`, or `Other`, then routes to a corresponding prompt chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f885113d",
   "metadata": {},
   "source": [
    "## Using a RunnableBranch\n",
    "\n",
    "A `RunnableBranch` is initialized with a list of (condition, runnable) pairs and a default runnable. It selects which branch by passing each condition the input it's invoked with. It selects the first condition to evaluate to True, and runs the corresponding runnable to that condition with the input. \n",
    "\n",
    "If no provided conditions match, it runs the default runnable.\n",
    "\n",
    "Here's an example of what it looks like in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa13c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84c59a",
   "metadata": {},
   "source": [
    "First, let's create a chain that will identify incoming questions as being about `LangChain`, `Anthropic`, or `Other`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec03886",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = PromptTemplate.from_template(\"\"\"Given the user question below, classify it as either being about `LangChain`, `Anthropic`, or `Other`.\n",
    "                                     \n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\") | ChatAnthropic() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ae7c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Anthropic'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"how do I call Anthropic?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0a365",
   "metadata": {},
   "source": [
    "Now, let's create three sub chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d479962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chain = PromptTemplate.from_template(\"\"\"You are an expert in langchain. \\\n",
    "Always answer questions starting with \"As Harrison Chase told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()\n",
    "anthropic_chain = PromptTemplate.from_template(\"\"\"You are an expert in anthropic. \\\n",
    "Always answer questions starting with \"As Dario Amodei told me\". \\\n",
    "Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()\n",
    "general_chain = PromptTemplate.from_template(\"\"\"Respond to the following question:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\") | ChatAnthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593eab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "branch = RunnableBranch(\n",
    "  (lambda x: \"anthropic\" in x[\"topic\"].lower(), anthropic_chain),\n",
    "  (lambda x: \"langchain\" in x[\"topic\"].lower(), langchain_chain),\n",
    "  general_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752c732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29231bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Dario Amodei told me, here are a few ways to use Anthropic:\\n\\n- Sign up for an account at Anthropic.com to access the free tier of Claude, Anthropic's conversational AI assistant. You can chat with Claude through the website.\\n\\n- Integrate Claude into your own products and services using Anthropic's API. This allows you to leverage Claude's natural language capabilities in your own applications.\\n\\n- Use Anthropic PBC, their proprietary AI safety technique, to align Claude's responses with your values and intended use cases. PBC helps ensure reliable and safe conversations.\\n\\n- Leverage their self-supervised and constitutional AI techniques like Constitutional AI and Self-Supervised Learning to train AI systems that are helpful, harmless, and honest.\\n\\n- Apply for partnerships if you are working on particularly useful or important applications of AI conversational agents. Anthropic selectively collaborates this way.\\n\\n- Follow Anthropic's research publication and blog to stay up to date on their latest AI safety techniques and capabilities as they work to develop AI that is beneficial for all.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthropic?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67d8733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Harrison Chase told me, here is how you use LangChain:\\n\\nLangChain is an AI assistant that allows you to have natural conversations and ask questions on any topic. To use LangChain, simply type or speak your question or request just as you would to a friend. LangChain will then generate a helpful response to continue the conversation. \\n\\nYou can ask LangChain open-ended questions, request definitions or explanations on a concept, have it summarize information for you, and more. The key is to engage with it in a natural, conversational way. Don't worry about using special commands or syntax. Over time and with more conversations, LangChain will learn your interests and communication style to provide increasingly relevant and personalized responses.\\n\\nSome examples of questions you can ask LangChain:\\n\\n- What is the capital of France?\\n- Can you explain the key principles of machine learning in simple terms?  \\n- What is the plot summary of the book X?\\n- What is the latest news about topic Y?\\n- How do you make a Spanish omelette? \\n\\nLangChain works best when you treat it like an intelligent assistant in a dialogue. Feel free to follow up on its responses by asking clarifying questions or requesting more details\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935ad949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' 4', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"whats 2 + 2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d042c",
   "metadata": {},
   "source": [
    "## Using a custom function\n",
    "\n",
    "You can also use a custom function to route between different outputs. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687492da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    inputs = {\"question\": lambda x: x[\"question\"]}\n",
    "    if \"anthropic\" in info[\"topic\"].lower():\n",
    "        return inputs | anthropic_chain\n",
    "    elif \"langchain\" in info[\"topic\"].lower():\n",
    "        return inputs | langchain_chain\n",
    "    else:\n",
    "        return inputs | general_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a33c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "full_chain = {\n",
    "    \"topic\": chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e977a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Dario Amodei told me, to use Anthropic's conversational AI system Anthro IPC, you first need to sign up for an API key at anthropic.com. Once you have a key, you can make requests to the Anthro IPC API endpoints to have conversations with the AI assistant. The basic process is:\\n\\n1. Send a POST request to the `/message` endpoint with your API key and the user message as the request body. This will return the AI's response.\\n\\n2. To have a conversation, continue sending requests to the `/message` endpoint, each time including the previous messages and responses in the request body. The AI will use the context to understand the ongoing conversation.\\n\\n3. Make sure to implement rate limiting on requests as per Anthropic's usage guidelines. The free tier has limits on requests per minute and month.\\n\\n4. Refer to the Anthro IPC documentation for details on request parameters, endpoints, error handling, etc. There are also client libraries available to make integration easier.\\n\\n5. Have fun conversing with Anthropic's remarkable AI assistant! As Dario told me, Anthro IPC enables safe and helpful dialogue.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use Anthroipc?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48913dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" As Harrison Chase told me, here is how you can use LangChain:\\n\\nLangChain is an AI assistant that can have natural conversations and provide helpful information to users. To start a conversation with LangChain, simply ask it a question or make a request. LangChain will then try to understand what you are asking and provide a relevant and thoughtful response. \\n\\nYou can ask LangChain questions on a wide variety of topics - from seeking advice, to asking for definitions of words, to having a casual chat. LangChain aims to have human-like conversations and be helpful, harmless, and honest in its responses. \\n\\nSome examples of questions you could ask LangChain:\\n\\n- What's the weather forecast for tomorrow?\\n- Can you recommend a good book to read? \\n- What is the capital of Australia?\\n- How do you make lasagna?\\n- What is your favorite color?\\n\\nLangChain may sometimes admit if it does not know the answer to a question. But it will try its best to provide useful information related to the topic. The more you talk with LangChain, the more it can learn about your interests and provide personalized responses.\\n\\nI hope this gives you a good overview of how to have engaging conversations\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"how do I use LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14d0dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' 4', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"whats 2 + 2\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
