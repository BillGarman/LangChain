{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be908912-b177-4473-868a-35545432b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=  \"/Users/wfh/code/lc/langchain/docs/_dist/docs_skeleton/docs/integrations/chat_loaders/discord_chats.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fdb792f-b143-4885-a798-5406238d542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_loaders.discord import DiscordChatLoader\n",
    "\n",
    "loader = DiscordChatLoader(\n",
    "    path=p, \n",
    "    user_name=\"talkingtower\", # the user handle to represent the ai message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b117c03d-35f6-4845-9f4f-1d4105c7f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24cfd71d-7b25-4c26-9a9c-539cb5f56c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.adapters import openai as openai_adapter\n",
    "\n",
    "openai_messages = openai_adapter.convert_messages_for_finetuning(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56898d4-efe3-46f8-886f-73c9e1dea940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our chat is alternating, we will make each datapoint a group of 8 messages,\n",
    "# with 4 messages overlapping\n",
    "chunk_size = 8\n",
    "overlap = 4\n",
    "message_groups = [\n",
    "    conversation_messages[i: i + chunk_size] \n",
    "    for conversation_messages in openai_messages\n",
    "    for i in range(0, len(conversation_messages) - chunk_size + 1, chunk_size - overlap)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "110ef1e6-5c9c-4bd8-befc-3eba67876439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "import openai\n",
    "\n",
    "\n",
    "my_file = io.BytesIO()\n",
    "for group in message_groups:\n",
    "    my_file.write((json.dumps({\"messages\": group}) + \"\\n\").encode('utf-8'))\n",
    "\n",
    "my_file.seek(0)\n",
    "training_file = openai.File.create(\n",
    "  file=my_file,\n",
    "  purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871d8f18-9336-4151-860b-27fb94922647",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = openai.FineTuningJob.create(training_file=training_file.id, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c199aad-5571-4338-8e76-12ab75cde94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:personal::7qtt96yblapsed: 476.21012806892395\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "while True:\n",
    "  ftj = openai.FineTuningJob.retrieve(job.id)\n",
    "  if ftj.fine_tuned_model is None:\n",
    "    print(f\"Waiting for fine-tuning to complete... Elapsed: {time.time() - start}\", end=\"\\r\", flush=True)\n",
    "    time.sleep(10)\n",
    "  else:\n",
    "    print(ftj.fine_tuned_model, flush=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7193475-1019-4347-b4ce-9520434a7069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.retrieve(job.id).status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e60701-a480-4032-9823-fd1a69237b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Reporter Bob! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain import chat_models, prompts\n",
    "\n",
    "model_name = ftj.fine_tuned_model\n",
    "# Example: ft:gpt-3.5-turbo-0613:personal::5mty86jblapsed\n",
    "llm = chat_models.ChatOpenAI(model=model_name)\n",
    "print(llm.predict(\"Hi i'm reporterbob\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf11f844-05f1-4098-b58f-b2cb14beeea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
