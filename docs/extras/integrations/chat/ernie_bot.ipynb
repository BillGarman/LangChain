{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERNIE-Bot Chat\n",
    "\n",
    "[ERNIE-Bot](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/jlil56u11) is a large language model developed by Baidu, covering a huge amount of Chinese data.\n",
    "This notebook covers how to get started with ErnieBot chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ErnieBotChat\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ErnieBotChat(ernie_client_id='your_ak', ernie_client_secret='your_sk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or you can set `client_id` and `client_secret` in your environment variables\n",
    "```bash\n",
    "export ERNIE_CLIENT_ID=YOUR_CLIENT_ID\n",
    "export ERNIE_CLIENT_SECRET=YOUR_CLIENT_SECRET\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My name is dst. As an artificial intelligence language model, I have no real form and identity, and my purpose is to help users get information and answers. What can I do for you?', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([\n",
    "    HumanMessage(content='hello there, who are you?')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='Hello, I am an artificial intelligence language model. My purpose is to help users obtain information and answer their questions. What can I do for you?', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='Hello, I am an artificial intelligence language model. My purpose is to help users obtain information and answer their questions. What can I do for you?', additional_kwargs={}, example=False))]], llm_output={}, run=[RunInfo(run_id=UUID('3e0350a6-daa6-4754-9d27-a014ccf7bd0a'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.generate(messages=[[\n",
    "    HumanMessage(content='hello there, who are you?')\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat resp1: content='您好，您似乎输入' additional_kwargs={} example=False\n",
      "chat resp1: content='了一个话题标签，需要我帮忙解答吗？' additional_kwargs={} example=False\n",
      "chat resp1: content='请提供更多的信息给我。' additional_kwargs={} example=False\n",
      "chat resp1: content='' additional_kwargs={} example=False\n",
      "generations=[[ChatGeneration(text='The sea is a vast expanse of water, stretching as far as the eye can see. It is a source of inspiration and adventure for many people, and a place where they can relax and unwind.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='The sea is a vast expanse of water, stretching as far as the eye can see. It is a source of inspiration and adventure for many people, and a place where they can relax and unwind.', additional_kwargs={}, example=False))]] llm_output={} run=[RunInfo(run_id=UUID('d73cca9d-bf7d-4bb9-b80c-2421d801be74'))]\n",
      "astream content='大海是地球上最' additional_kwargs={} example=False\n",
      "astream content='广阔的水域之一，它拥有美丽的海岸线和各种奇妙的海洋生物。' additional_kwargs={} example=False\n",
      "astream content='海水的深度和透明度取决于其所在地区的纬度和气候条件。' additional_kwargs={} example=False\n",
      "astream content='海浪的运动和潮汐的变化都是海上的重要现象，给人类带来了很多机遇和挑战。' additional_kwargs={} example=False\n",
      "astream content='' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "# aio functions\n",
    "import asyncio\n",
    "\n",
    "res = chat.stream([HumanMessage(content=\"hi\")], stream=True)\n",
    "for r in res:\n",
    "    print(\"chat resp1:\", r)\n",
    "\n",
    "\n",
    "async def run_aio_generate():\n",
    "    resp = await chat.agenerate(messages=[[HumanMessage(content=\"write a 20 words sentence about sea.\")]])\n",
    "    print(resp)\n",
    "        \n",
    "await run_aio_generate()\n",
    "\n",
    "async def run_aio_stream():\n",
    "    async for res in chat.astream([HumanMessage(content=\"write a 20 words sentence about sea.\")]):\n",
    "        print(\"astream\", res)\n",
    "        \n",
    "await run_aio_stream()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Call\n",
    "- use functions call with LLM by chatModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FUNCTIONS: Any = [\n",
    "    {\n",
    "        \"name\": \"format_person_info\",\n",
    "        \"description\": (\n",
    "            \"Output formatter. Should always be used to format your response to the\"\n",
    "            \" user.\"\n",
    "        ),\n",
    "        \"parameters\": {\n",
    "            \"title\": \"Person\",\n",
    "            \"description\": \"Identifying information about a person.\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"title\": \"Name\",\n",
    "                    \"description\": \"The person's name\",\n",
    "                    \"type\": \"string\",\n",
    "                },\n",
    "                \"age\": {\n",
    "                    \"title\": \"Age\",\n",
    "                    \"description\": \"The person's age\",\n",
    "                    \"type\": \"integer\",\n",
    "                },\n",
    "                \"fav_food\": {\n",
    "                    \"title\": \"Fav Food\",\n",
    "                    \"description\": \"The person's favorite food\",\n",
    "                    \"type\": \"string\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"name\", \"age\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_current_temperature\",\n",
    "        \"description\": (\"Used to get the location's temperature.\"),\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"city name\",\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"centigrade\", \"Fahrenheit\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"unit\"],\n",
    "        },\n",
    "        \"responses\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"temperature\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"city temperature\",\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"centigrade\", \"Fahrenheit\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ErnieBotChat()\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import AIMessage, FunctionMessage, HumanMessage, SystemMessage\n",
    "from langchain.chains.openai_functions import create_openai_fn_chain\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessage(content=\"What's the temperature in Shanghai today?\"),\n",
    "        AIMessage(\n",
    "            content=\"\",\n",
    "            additional_kwargs={\n",
    "                \"function_call\": {\n",
    "                    \"name\": \"get_current_temperature\",\n",
    "                    \"thoughts\": \"i will use get_current_temperature \"\n",
    "                    \"to resolve the questions\",\n",
    "                    \"arguments\": '{\"location\":\"Shanghai\",\"unit\":\"centigrade\"}',\n",
    "                }\n",
    "            },\n",
    "        ),\n",
    "        FunctionMessage(\n",
    "            name=\"get_current_weather\",\n",
    "            content='{\"temperature\": \"25\", \\\n",
    "                            \"unit\": \"摄氏度\", \"description\": \"晴朗\"}',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "llm_chain = create_openai_fn_chain(\n",
    "    _FUNCTIONS,\n",
    "    chat,\n",
    "    prompt,\n",
    "    output_parser=None,\n",
    ")\n",
    "resp = llm_chain.generate([{}])\n",
    "print(\"resp\", resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6fa70026b407ae751a5c9e6bd7f7d482379da8ad616f98512780b705c84ee157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
