{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Activeloop's Deep Lake\n",
    "\n",
    ">[Activeloop's Deep Lake](https://docs.activeloop.ai/) as a Multi-Modal Vector Store that stores embeddings and their metadata including text, jsons, images, audio, video, and more. It saves the data locally, in your cloud, or on Activeloop storage. It performs hybrid search including embeddings and their attributes.\n",
    "\n",
    "This notebook showcases basic functionality related to `Activeloop's Deep Lake`. While `Deep Lake` can store embeddings, it is capable of storing any type of data. It is a serverless data lake with version control, query engine and streaming dataloaders to deep learning frameworks.  \n",
    "\n",
    "For more information, please see the Deep Lake [documentation](https://docs.activeloop.ai) or [api reference](https://docs.deeplake.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (0.27.8)\n",
      "Requirement already satisfied: deeplake[enterprise] in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (3.6.13)\n",
      "Requirement already satisfied: tiktoken in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from openai) (3.8.5)\n",
      "\u001b[33mWARNING: deeplake 3.6.13 does not provide the extra 'enterprise'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (1.24.4)\n",
      "Requirement already satisfied: pillow in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (10.0.0)\n",
      "Requirement already satisfied: boto3 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (1.26.76)\n",
      "Requirement already satisfied: click in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (8.1.6)\n",
      "Requirement already satisfied: pathos in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (0.3.1)\n",
      "Requirement already satisfied: humbug>=0.3.1 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (0.3.2)\n",
      "Requirement already satisfied: numcodecs in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (0.11.0)\n",
      "Requirement already satisfied: pyjwt in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (2.8.0)\n",
      "Requirement already satisfied: aioboto3>=10.4.0 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (11.2.0)\n",
      "Requirement already satisfied: nest-asyncio in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from deeplake[enterprise]) (1.5.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: aiobotocore[boto3]==2.5.0 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aioboto3>=10.4.0->deeplake[enterprise]) (2.5.0)\n",
      "Requirement already satisfied: botocore<1.29.77,>=1.29.76 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake[enterprise]) (1.29.76)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake[enterprise]) (1.15.0)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake[enterprise]) (0.11.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiohttp->openai) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from boto3->deeplake[enterprise]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from boto3->deeplake[enterprise]) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: entrypoints in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from numcodecs->deeplake[enterprise]) (0.4)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from pathos->deeplake[enterprise]) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from pathos->deeplake[enterprise]) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from pathos->deeplake[enterprise]) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from pathos->deeplake[enterprise]) (0.70.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake[enterprise]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/adilkhansarsen/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.77,>=1.29.76->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake[enterprise]) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai 'deeplake[enterprise]' tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import DeepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "activeloop_token = getpass.getpass(\"activeloop token:\")\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../../modules/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset locally at `./deeplake/`, then run similarity search. The Deeplake+LangChain integration uses Deep Lake datasets under the hood, so `dataset` and `vector store` are used interchangeably. To create a dataset in your own cloud, or in the Deep Lake storage, [adjust the path accordingly](https://docs.activeloop.ai/storage-and-credentials/storage-options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dataset.empty() got an unexpected keyword argument 'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m db \u001b[39m=\u001b[39m DeepLake(\n\u001b[1;32m      2\u001b[0m     dataset_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./my_deeplake/\u001b[39;49m\u001b[39m\"\u001b[39;49m, embedding\u001b[39m=\u001b[39;49membeddings, overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m db\u001b[39m.\u001b[39madd_documents(docs)\n\u001b[1;32m      5\u001b[0m \u001b[39m# or shorter\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# db = DeepLake.from_documents(docs, dataset_path=\"./my_deeplake/\", embedding=embeddings, overwrite=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/work/LangChain/activeloop-langchain/langchain/libs/langchain/langchain/vectorstores/deeplake.py:147\u001b[0m, in \u001b[0;36mDeepLake.__init__\u001b[0;34m(self, dataset_path, token, embedding_function, read_only, ingestion_batch_size, num_workers, verbose, exec_option, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m embedding_function:\n\u001b[1;32m    142\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    143\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing embedding function is deprecated and will be removed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min the future. Please use embedding instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m     )\n\u001b[0;32m--> 147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore \u001b[39m=\u001b[39m DeepLakeVectorStore(\n\u001b[1;32m    148\u001b[0m     path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_path,\n\u001b[1;32m    149\u001b[0m     embedding_function\u001b[39m=\u001b[39;49membedding_function,\n\u001b[1;32m    150\u001b[0m     read_only\u001b[39m=\u001b[39;49mread_only,\n\u001b[1;32m    151\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    152\u001b[0m     exec_option\u001b[39m=\u001b[39;49mexec_option,\n\u001b[1;32m    153\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    154\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    155\u001b[0m )\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id_tensor_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39mtensors() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages/deeplake/core/vectorstore/deeplake_vectorstore.py:134\u001b[0m, in \u001b[0;36mVectorStore.__init__\u001b[0;34m(self, path, tensor_params, embedding_function, read_only, ingestion_batch_size, num_workers, exec_option, token, overwrite, verbose, runtime, creds, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m creds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     creds \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39;49mcreate_or_load_dataset(\n\u001b[1;32m    135\u001b[0m     tensor_params,\n\u001b[1;32m    136\u001b[0m     path,\n\u001b[1;32m    137\u001b[0m     token,\n\u001b[1;32m    138\u001b[0m     creds,\n\u001b[1;32m    139\u001b[0m     logger,\n\u001b[1;32m    140\u001b[0m     read_only,\n\u001b[1;32m    141\u001b[0m     exec_option,\n\u001b[1;32m    142\u001b[0m     embedding_function,\n\u001b[1;32m    143\u001b[0m     overwrite,\n\u001b[1;32m    144\u001b[0m     runtime,\n\u001b[1;32m    145\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function \u001b[39m=\u001b[39m embedding_function\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexec_option \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mparse_exec_option(\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, exec_option, _INDRA_INSTALLED\n\u001b[1;32m    150\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages/deeplake/core/vectorstore/vector_search/dataset/dataset.py:60\u001b[0m, in \u001b[0;36mcreate_or_load_dataset\u001b[0;34m(tensor_params, dataset_path, token, creds, logger, read_only, exec_option, embedding_function, overwrite, runtime, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mVector Store is not empty. You shouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt specify tensor_params if you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre loading from existing dataset.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m load_dataset(\n\u001b[1;32m     51\u001b[0m         dataset_path,\n\u001b[1;32m     52\u001b[0m         token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     58\u001b[0m     )\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m create_dataset(\n\u001b[1;32m     61\u001b[0m     logger,\n\u001b[1;32m     62\u001b[0m     tensor_params,\n\u001b[1;32m     63\u001b[0m     dataset_path,\n\u001b[1;32m     64\u001b[0m     token,\n\u001b[1;32m     65\u001b[0m     exec_option,\n\u001b[1;32m     66\u001b[0m     embedding_function,\n\u001b[1;32m     67\u001b[0m     overwrite,\n\u001b[1;32m     68\u001b[0m     creds,\n\u001b[1;32m     69\u001b[0m     runtime,\n\u001b[1;32m     70\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     71\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/work/LangChain/activeloop-langchain/langchain/.venv/lib/python3.11/site-packages/deeplake/core/vectorstore/vector_search/dataset/dataset.py:183\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(logger, tensor_params, dataset_path, token, exec_option, embedding_function, overwrite, creds, runtime, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m exec_option \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensor_db\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    173\u001b[0m     runtime \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m runtime \u001b[39m==\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtensor_db\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m}\n\u001b[1;32m    174\u001b[0m ):\n\u001b[1;32m    175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    176\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo execute queries using exec_option = \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensor_db\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe Vector Store must be stored in Deep Lake\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms Managed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcreating the Vector Store.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m dataset \u001b[39m=\u001b[39m deeplake\u001b[39m.\u001b[39;49mempty(\n\u001b[1;32m    184\u001b[0m     dataset_path,\n\u001b[1;32m    185\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    186\u001b[0m     runtime\u001b[39m=\u001b[39;49mruntime,\n\u001b[1;32m    187\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    188\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    189\u001b[0m     creds\u001b[39m=\u001b[39;49mcreds,\n\u001b[1;32m    190\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m create_tensors(tensor_params, dataset, logger, embedding_function)\n\u001b[1;32m    194\u001b[0m \u001b[39mreturn\u001b[39;00m dataset\n",
      "\u001b[0;31mTypeError\u001b[0m: dataset.empty() got an unexpected keyword argument 'embedding'"
     ]
    }
   ],
   "source": [
    "db = DeepLake(\n",
    "    dataset_path=\"./my_deeplake/\", embedding=embeddings, overwrite=True\n",
    ")\n",
    "db.add_documents(docs)\n",
    "# or shorter\n",
    "# db = DeepLake.from_documents(docs, dataset_path=\"./my_deeplake/\", embedding=embeddings, overwrite=True)\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, you can reload the dataset without recomputing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DeepLake(\n",
    "    dataset_path=\"./my_deeplake/\", embedding=embeddings, read_only=True\n",
    ")\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Lake, for now, is single writer and multiple reader. Setting `read_only=True` helps to avoid acquiring the writer lock."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Question/Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAIChat\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAIChat(model=\"gpt-3.5-turbo\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "qa.run(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute based filtering in metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create another vector store containing metadata with the year the documents were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for d in docs:\n",
    "    d.metadata[\"year\"] = random.randint(2012, 2014)\n",
    "\n",
    "db = DeepLake.from_documents(\n",
    "    docs, embeddings, dataset_path=\"./my_deeplake/\", overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\n",
    "    \"What did the president say about Ketanji Brown Jackson\",\n",
    "    filter={\"metadata\": {\"year\": 2013}},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing distance function\n",
    "Distance function `L2` for Euclidean, `L1` for Nuclear, `Max` l-infinity distance, `cos` for cosine similarity, `dot` for dot product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\n",
    "    \"What did the president say about Ketanji Brown Jackson?\", distance_metric=\"cos\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximal Marginal relevance\n",
    "Using maximal marginal relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.max_marginal_relevance_search(\n",
    "    \"What did the president say about Ketanji Brown Jackson?\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "db.delete_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if delete fails you can also force delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "DeepLake.force_delete_by_path(\"./my_deeplake\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Lake datasets on cloud (Activeloop, AWS, GCS, etc.) or in memory\n",
    "By default, Deep Lake datasets are stored locally. To store them in memory, in the Deep Lake Managed DB, or in any object storage, you can provide the [corresponding path and credentials when creating the vector store](https://docs.activeloop.ai/storage-and-credentials/storage-options). Some paths require registration with Activeloop and creation of an API token that can be [retrieved here](https://app.activeloop.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ACTIVELOOP_TOKEN\"] = activeloop_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "username = \"<username>\"  # your username on app.activeloop.ai\n",
    "dataset_path = f\"hub://{username}/langchain_testing_python\"  # could be also ./local/path (much faster locally), s3://bucket/path/to/dataset, gcs://path/to/dataset, etc.\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "db = DeepLake(dataset_path=dataset_path, embedding=embeddings, overwrite=True)\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tensor_db` execution option "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to utilize Deep Lake's Managed Tensor Database, it is necessary to specify the runtime parameter as {'tensor_db': True} during the creation of the vector store. This configuration enables the execution of queries on the Managed Tensor Database, rather than on the client side. It should be noted that this functionality is not applicable to datasets stored locally or in-memory. In the event that a vector store has already been created outside of the Managed Tensor Database, it is possible to transfer it to the Managed Tensor Database by following the prescribed steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "username = \"adilkhan\"  # your username on app.activeloop.ai\n",
    "dataset_path = f\"hub://{username}/langchain_testing\"\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "db = DeepLake(\n",
    "    dataset_path=dataset_path,\n",
    "    embedding=embeddings,\n",
    "    overwrite=True,\n",
    "    runtime={\"tensor_db\": True},\n",
    ")\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TQL Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the execution of queries is also supported within the similarity_search method, whereby the query can be specified utilizing Deep Lake's Tensor Query Language (TQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_id = db.vectorstore.dataset.id[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db.similarity_search(\n",
    "    query=None,\n",
    "    tql_query=f\"SELECT * WHERE id == '{search_id[0]}'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vector stores on AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://hub-2.0-datasets-n/langchain_test loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 1/1 [00:10<00:00\n",
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='s3://hub-2.0-datasets-n/langchain_test', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (4, 1536)  float32   None   \n",
      "    ids      text     (4, 1)      str     None   \n",
      " metadata    json     (4, 1)      str     None   \n",
      "   text      text     (4, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "dataset_path = f\"s3://BUCKET/langchain_test\"  # could be also ./local/path (much faster locally), hub://bucket/path/to/dataset, gcs://path/to/dataset, etc.\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "db = DeepLake.from_documents(\n",
    "    docs,\n",
    "    dataset_path=dataset_path,\n",
    "    embedding=embeddings,\n",
    "    overwrite=True,\n",
    "    creds={\n",
    "        \"aws_access_key_id\": os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "        \"aws_secret_access_key\": os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "        \"aws_session_token\": os.environ[\"AWS_SESSION_TOKEN\"],  # Optional\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Lake API\n",
    "you can access the Deep Lake  dataset at `db.vectorstore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://adilkhan/langchain_testing', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (42, 1536)  float32   None   \n",
      "    id        text      (42, 1)      str     None   \n",
      " metadata     json      (42, 1)      str     None   \n",
      "   text       text      (42, 1)      str     None   \n"
     ]
    }
   ],
   "source": [
    "# get structure of the dataset\n",
    "db.vectorstore.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings numpy array\n",
    "embeds = db.vectorstore.dataset.embedding.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer local dataset to cloud\n",
    "Copy already created dataset to the cloud. You can also transfer from cloud to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying dataset: 100%|██████████| 56/56 [00:38<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/davitbun/langchain_test_copy\n",
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(path='hub://davitbun/langchain_test_copy', tensors=['embedding', 'ids', 'metadata', 'text'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deeplake\n",
    "\n",
    "username = \"davitbun\"  # your username on app.activeloop.ai\n",
    "source = f\"hub://{username}/langchain_test\"  # could be local, s3, gcs, etc.\n",
    "destination = f\"hub://{username}/langchain_test_copy\"  # could be local, s3, gcs, etc.\n",
    "\n",
    "deeplake.deepcopy(src=source, dest=destination, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/davitbun/langchain_test_copy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://davitbun/langchain_test_copy loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://davitbun/langchain_test_copy already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://davitbun/langchain_test_copy', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (4, 1536)  float32   None   \n",
      "    ids      text     (4, 1)      str     None   \n",
      " metadata    json     (4, 1)      str     None   \n",
      "   text      text     (4, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ingest: 100%|██████████| 1/1 [00:31<00:00\n",
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://davitbun/langchain_test_copy', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype     shape     dtype  compression\n",
      "  -------   -------   -------   -------  ------- \n",
      " embedding  generic  (8, 1536)  float32   None   \n",
      "    ids      text     (8, 1)      str     None   \n",
      " metadata    json     (8, 1)      str     None   \n",
      "   text      text     (8, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ad42f3fe-e188-11ed-b66d-41c5f7b85421',\n",
       " 'ad42f3ff-e188-11ed-b66d-41c5f7b85421',\n",
       " 'ad42f400-e188-11ed-b66d-41c5f7b85421',\n",
       " 'ad42f401-e188-11ed-b66d-41c5f7b85421']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DeepLake(dataset_path=destination, embedding=embeddings)\n",
    "db.add_documents(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('langchain_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b0bacaffd430edc3085253ee7ee1bcda9f76a5e66b369dda8ba68baa6d14ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
