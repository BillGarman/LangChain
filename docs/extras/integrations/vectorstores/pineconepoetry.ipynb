{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "683953b3",
      "metadata": {
        "id": "683953b3"
      },
      "source": [
        "# Pinecone\n",
        "\n",
        ">[Pinecone](https://docs.pinecone.io/docs/overview) is a vector database with broad functionality.\n",
        "\n",
        "This notebook shows how to use functionality related to the `Pinecone` vector database.\n",
        "\n",
        "To use Pinecone, you must have an API key.\n",
        "Here are the [installation instructions](https://docs.pinecone.io/docs/quickstart)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Poetry Integration\n",
        "\n",
        "This Notebook demonstrates how to use the Python dependency and virtualenv manager, Poetry.\n",
        "\n",
        "Scenarios it demonstrates:\n",
        "\n",
        "* Installing packages via Poetry\n",
        "* Installing a package from a GitHub branch of a project that itself uses Poetry\n",
        "* Installing the above correctly when the target Python package resides in a subdirectory of that project\n",
        "* Configuring Poetry to create a virtualenv directly in the project working directory - simplifying use within a Jupyter Notebook\n",
        "\n",
        "# Original project requirements\n",
        "Prior to cutting this Notebook / demo over to use Poetry, its dependencies were:\n",
        "* pinecone-client\n",
        "* openai\n",
        "* tiktoken\n",
        "* langchain\n"
      ],
      "metadata": {
        "id": "PeK0pDJPmo9H"
      },
      "id": "PeK0pDJPmo9H"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Poetry which is a dependency and virtualenv manager\n",
        "# Read more at https://python-poetry.org/docs\n",
        "! curl -sSL https://install.python-poetry.org | python3 -"
      ],
      "metadata": {
        "id": "u3p2XMdNekn_"
      },
      "id": "u3p2XMdNekn_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to add Poetry's install location to the PATH so that subsequent commands can simply call `poetry` <cmd>\n",
        "# This is admittedly a bit of a hack - what we really want here is a unix alias that will persist throughout the Notebook\n",
        "poetry = \"/root/.local/bin/poetry\"\n",
        "\n",
        "# Sanity check that poetry installation and alias hack succeeded\n",
        "! $poetry --version"
      ],
      "metadata": {
        "id": "Jkh1T28zinLt"
      },
      "id": "Jkh1T28zinLt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new pyproject.toml file in the root, which signifies that this \"project\" within Jupyter Notebook is using Poetry\n",
        "! $poetry init --no-interaction"
      ],
      "metadata": {
        "id": "p1VgkSBCjNlE"
      },
      "id": "p1VgkSBCjNlE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To keep things simple for the purposes of testing, tell poetry not to create virtualenvs\n",
        "! $poetry config virtualenvs.create false\n",
        "! $poetry config virtualenvs.in-project false"
      ],
      "metadata": {
        "id": "m8gJMkR2prKC"
      },
      "id": "m8gJMkR2prKC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We've disabled virtualenv creation to keep things simple for this test notebook, but the code below\n",
        "# demonstrates how you could handle a Poetry virtualenv within a Jupyter notebook\n",
        "\n",
        "# Run this next command to get poetry to tell you about the virtualenv settings\n",
        "#! $poetry env info\n",
        "\n",
        "# This is how you could extract the virtualenv's path\n",
        "# VENV_PATH = ! $poetry env info --path\n",
        "\n",
        "# Sanity check the output - note that, if successful, the return value will be a Python list containing\n",
        "# a single string\n",
        "# print(VENV_PATH)\n",
        "\n",
        "# VENV_PATH = VENV_PATH[0]\n",
        "# print(VENV_PATH)\n",
        "\n",
        "# Activate the virtualenv\n",
        "# !source {VENV_PATH}/bin/activate\n",
        "\n",
        "# Ensure the virtualenv set up above is also the active one - the output of this command is the list of\n",
        "# virtualenvs that Poetry is managing as well as which is currently active\n",
        "# ! $poetry env list"
      ],
      "metadata": {
        "id": "fuXE0ztDavGS"
      },
      "id": "fuXE0ztDavGS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you don't pass the --no-ansi flag, then the poetry add and install commands will run, but\n",
        "# will not persist the changes to the pyproject.toml file.\n",
        "# The --no-ansi flag appears to be required for at least the poetry add and poetry install commands\n",
        "# See: https://stackoverflow.com/questions/75245758/how-to-use-poetry-in-google-colab for more info\n",
        "\n",
        "# Install base dependencies and persist them to to pyproject.toml and poetry.lock file\n",
        "! $poetry --no-ansi add pinecone-client openai tiktoken\n",
        "\n",
        "# Install the Jupyter package as a dev depenendency\n",
        "! $poetry --no-ansi add --group dev jupyter"
      ],
      "metadata": {
        "id": "LpltpiA0k2NC"
      },
      "id": "LpltpiA0k2NC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install langchain branch from the smartcat fork that we're testing - there's a couple of things going on here:\n",
        "# 1. We are installing langchain from a fork, not from its default location in GitHub or via pip\n",
        "# 2. We are furthermore getting a specific git ref (in this case the branch @pinecone-optimization)\n",
        "# 3. This repository is a monorepo that contains the actual Python package in a subdirectory, so we pass the\n",
        "# subdirectory param at the end, pointing to the subdirectory that contains the Python package's actual pyproject.toml\n",
        "# since that is primary file driving packages managed by Poetry (langchain the library also happens to be a Poetry-managed project)\n",
        "! $poetry add --no-ansi git+https://github.com/smartcat-labs/langchain.git@pinecone-optimization#subdirectory=libs/langchain"
      ],
      "metadata": {
        "id": "u-ul440bkvY7"
      },
      "id": "u-ul440bkvY7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check that our package installs have been persisted to this Jupyter Notebook's pyproject.toml file correctly:\n",
        "!cat pyproject.toml\n",
        "\n",
        "# Install the dependencies to the virtualenv and write the poetry.lock file\n",
        "# TEST if this is necessary or not\n",
        "#! $poetry --no-ansi install"
      ],
      "metadata": {
        "id": "Ov6uvHXflgHc"
      },
      "id": "Ov6uvHXflgHc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import langchain, which will now be our modified version installed from our target fork's branch\n",
        "import langchain"
      ],
      "metadata": {
        "id": "6OgH8u1ss87T"
      },
      "id": "6OgH8u1ss87T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OLnsw7l4rxOV"
      },
      "id": "OLnsw7l4rxOV"
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import openai\n",
        "!ls /usr/lib/python3/dist-packages | grep -i lang"
      ],
      "metadata": {
        "id": "QFoE7LWDqLo3"
      },
      "id": "QFoE7LWDqLo3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e38361-c1fe-4ac6-86e9-c90ebaf7ae87",
      "metadata": {
        "id": "c1e38361-c1fe-4ac6-86e9-c90ebaf7ae87"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Pinecone API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02a536e0-d603-4d79-b18b-1ed562977b40",
      "metadata": {
        "id": "02a536e0-d603-4d79-b18b-1ed562977b40"
      },
      "outputs": [],
      "source": [
        "os.environ[\"PINECONE_ENV\"] = getpass.getpass(\"Pinecone Environment:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320af802-9271-46ee-948f-d2453933d44b",
      "metadata": {
        "id": "320af802-9271-46ee-948f-d2453933d44b"
      },
      "source": [
        "We want to use `OpenAIEmbeddings` so we have to get the OpenAI API Key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffea66e4-bc23-46a9-9580-b348dfe7b7a7",
      "metadata": {
        "id": "ffea66e4-bc23-46a9-9580-b348dfe7b7a7"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aac9563e",
      "metadata": {
        "tags": [],
        "id": "aac9563e"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c3999a",
      "metadata": {
        "id": "a3c3999a"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Fetch the state of the union text file from GitHub\n",
        "target_url = 'https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/extras/modules/state_of_the_union.txt'\n",
        "\n",
        "data = urlopen(target_url).read().decode('utf-8')\n",
        "\n",
        "target_filepath = '/content/state_of_the_union.txt'\n",
        "\n",
        "with open(target_filepath, 'w') as writer:\n",
        "  writer.write(data)\n",
        "\n",
        "loader = TextLoader(target_filepath)\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/sample_data"
      ],
      "metadata": {
        "id": "YDGD12lyB_NP"
      },
      "id": "YDGD12lyB_NP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e104aee",
      "metadata": {
        "id": "6e104aee"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "\n",
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.getenv(\"PINECONE_API_KEY\"),  # find at app.pinecone.io\n",
        "    environment=os.getenv(\"PINECONE_ENV\"),  # next to api key in console\n",
        ")\n",
        "\n",
        "index_name = \"langchain-demo\"\n",
        "\n",
        "# First, check if our index already exists. If it doesn't, we create it\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    # we create a new index\n",
        "    pinecone.create_index(\n",
        "      name=index_name,\n",
        "      metric='cosine',\n",
        "      dimension=1536\n",
        ")\n",
        "# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\n",
        "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
        "\n",
        "# if you already have an index, you can load it like this\n",
        "# docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = docsearch.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c608226",
      "metadata": {
        "id": "9c608226"
      },
      "outputs": [],
      "source": [
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a4b96b",
      "metadata": {
        "id": "86a4b96b"
      },
      "source": [
        "### Adding More Text to an Existing Index\n",
        "\n",
        "More text can embedded and upserted to an existing Pinecone index using the `add_texts` function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38a7a60e",
      "metadata": {
        "id": "38a7a60e"
      },
      "outputs": [],
      "source": [
        "index = pinecone.Index(\"langchain-demo\")\n",
        "vectorstore = Pinecone(index, embeddings.embed_query, \"text\")\n",
        "\n",
        "vectorstore.add_texts(\"More text!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46d1452",
      "metadata": {
        "id": "d46d1452"
      },
      "source": [
        "### Maximal Marginal Relevance Searches\n",
        "\n",
        "In addition to using similarity search in the retriever object, you can also use `mmr` as retriever.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a359ed74",
      "metadata": {
        "id": "a359ed74"
      },
      "outputs": [],
      "source": [
        "retriever = docsearch.as_retriever(search_type=\"mmr\")\n",
        "matched_docs = retriever.get_relevant_documents(query)\n",
        "for i, d in enumerate(matched_docs):\n",
        "    print(f\"\\n## Document {i}\\n\")\n",
        "    print(d.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c477287",
      "metadata": {
        "id": "7c477287"
      },
      "source": [
        "Or use `max_marginal_relevance_search` directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca82740",
      "metadata": {
        "id": "9ca82740"
      },
      "outputs": [],
      "source": [
        "found_docs = docsearch.max_marginal_relevance_search(query, k=2, fetch_k=10)\n",
        "for i, doc in enumerate(found_docs):\n",
        "    print(f\"{i + 1}.\", doc.page_content, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}