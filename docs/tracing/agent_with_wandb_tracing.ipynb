{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5371a9bb",
   "metadata": {},
   "source": [
    "# Tracing Walkthrough\n",
    "\n",
    "There are two recommended ways to trace your LangChains:\n",
    "\n",
    "1. Setting the `LANGCHAIN_WANDB_TRACING` environment variable to \"true\".\n",
    "1. Using a context manager with tracing_enabled() to trace a particular block of code.\n",
    "\n",
    "**Note** if the environment variable is set, all code will be traced, regardless of whether or not it's within the context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-11T16:24:06.312304Z",
     "end_time": "2023-05-11T16:24:06.312549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c04cc6-c93d-4b6c-a033-e897577f4ed1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-11T16:24:06.312409Z",
     "end_time": "2023-05-11T16:24:07.262280Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"langchain-tracing\"\n",
    "\n",
    "## Uncomment below if using hosted setup.\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://langchain-api-gateway-57eoxz8z.uc.gateway.dev\" \n",
    "\n",
    "## Uncomment below if you want traces to be recorded to \"my_session\" instead of \"default\".\n",
    "# os.environ[\"LANGCHAIN_SESSION\"] = \"my_session\"  \n",
    "\n",
    "## Better to set this environment variable in the terminal\n",
    "## Uncomment below if using hosted version. Replace \"my_api_key\" with your actual API Key.\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"my_api_key\"  \n",
    "\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import wandb_tracing_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b62cd48",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-11T16:24:07.263778Z",
     "end_time": "2023-05-11T16:24:07.271104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Agent run with tracing. Ensure that OPENAI_API_KEY is set appropriately to run this example.\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa16b79-aa4b-4d41-a067-70d1f593f667",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-11T16:24:07.272431Z",
     "end_time": "2023-05-11T16:24:22.832354Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Streaming LangChain activity to W&B at https://wandb.ai/parambharat/langchain-tracing/runs/ies3jpb6\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: `WandbTracer` is currently in beta.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 2^.123243\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.0891804557407723\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer.\n",
      "Final Answer: 1.0891804557407723\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'1.0891804557407723'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"What is 2 raised to .123243 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4829eb1d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-11T16:24:22.834253Z",
     "end_time": "2023-05-11T16:24:31.443226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 2 ^ .123243\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.0891804557407723\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the answer to the question.\n",
      "Final Answer: 1.0891804557407723\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'1.0891804557407723'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent run with tracing using a chat model\n",
    "agent = initialize_agent(\n",
    "    tools, ChatOpenAI(temperature=0), agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "agent.run(\"What is 2 raised to .123243 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76abfd82",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-11T16:24:31.445972Z",
     "end_time": "2023-05-11T16:24:47.548139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 2 ^ .123243\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.0891804557407723\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the answer to the question. \n",
      "Final Answer: 1.0891804557407723\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 5 ^ .123243\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.2193914912400514\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the answer to the question. \n",
      "Final Answer: 1.2193914912400514\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Both of the agent runs will be traced because the environment variable is set\n",
    "agent.run(\"What is 2 raised to .123243 power?\")\n",
    "with wandb_tracing_enabled() as session:\n",
    "    agent.run(\"What is 5 raised to .123243 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe833c33-033f-4806-be0c-cc3d147db13d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-11T16:24:51.486704Z",
     "end_time": "2023-05-11T16:25:07.437121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 5 ^ .123243\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.2193914912400514\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the answer to the question. \n",
      "Final Answer: 1.2193914912400514\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 2 ^ .123243\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.0891804557407723\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the answer to the question. \n",
      "Final Answer: 1.0891804557407723\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'1.0891804557407723'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we unset the environment variable and use a context manager.\n",
    "if \"LANGCHAIN_TRACING\" in os.environ:\n",
    "    del os.environ[\"LANGCHAIN_WANDB_TRACING\"]\n",
    "\n",
    "# here, we are writing traces to \"my_test_session\"\n",
    "with wandb_tracing_enabled(\"my_session\") as session:\n",
    "    assert session\n",
    "    agent.run(\"What is 5 raised to .123243 power?\")  # this should be traced\n",
    "\n",
    "agent.run(\"What is 2 raised to .123243 power?\")  # this should not be traced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34105a4-be8e-46e4-8abe-01adba3ba727",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-05-11T16:25:13.420901Z",
     "end_time": "2023-05-11T16:25:54.467501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mI need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 2^0.123\u001B[0m\u001B[32;1m\u001B[1;3mI need to use a calculator to solve this.\n",
      "Action: Calculator\n",
      "Action Input: 3 ^ .123\u001B[0m\u001B[32;1m\u001B[1;3mAny number raised to the power of 0 is 1, but I'm not sure about a decimal power.\n",
      "Action: Calculator\n",
      "Action Input: 1^.123\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.1446847956963533\u001B[0m\n",
      "Thought:\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.0\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the answer to the question. \n",
      "Final Answer: 1.1446847956963533\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "Observation: \u001B[36;1m\u001B[1;3mAnswer: 1.0889970153361064\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mThat makes sense since any number raised to a power less than 1 will be less than the original number. \n",
      "Final Answer: 1.0\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.acompletion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ffa1864f12322020a433b57dbbaabf54 in your message.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3mI now know the answer to the question.\n",
      "Final Answer: 1.0889970153361064\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'1.0'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The context manager is concurrency safe:\n",
    "import asyncio \n",
    "if \"LANGCHAIN_WANDB_TRACING\" in os.environ:\n",
    "    del os.environ[\"LANGCHAIN_WANDB_TRACING\"]\n",
    "    \n",
    "questions = [f\"What is {i} raised to .123 power?\" for i in range(1,4)]\n",
    "\n",
    "# start a background task\n",
    "task = asyncio.create_task(agent.arun(questions[0]))  # this should not be traced\n",
    "with wandb_tracing_enabled() as session:\n",
    "    assert session\n",
    "    tasks = [agent.arun(q) for q in questions[1:3]]  # these should be traced\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "await task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46c85b-2ac0-4661-abed-9c2bf3036820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
