{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f8b67b",
   "metadata": {},
   "source": [
    "# AutoGPT\n",
    "\n",
    "Implementation of https://github.com/Significant-Gravitas/Auto-GPT but with LangChain primitives (LLMs, PromptTemplates, VectorStores, Embeddings, Tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192496a7",
   "metadata": {},
   "source": [
    "## Set up tools\n",
    "\n",
    "We'll set up an AutoGPT with a search tool, and write-file tool, and a read-file tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0e6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2c9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\"\n",
    "    ),\n",
    "    WriteFileTool(),\n",
    "    ReadFileTool(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39ee28",
   "metadata": {},
   "source": [
    "## Set up memory\n",
    "\n",
    "The memory here is used for the agents intermediate steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72bc204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df7b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your embedding model\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "# Initialize the vectorstore as empty\n",
    "import faiss\n",
    "\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fd657",
   "metadata": {},
   "source": [
    "## Setup model and AutoGPT\n",
    "\n",
    "Initialize everything! We will use ChatOpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3393bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.experimental.autonomous_agents.autogpt.agent import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709c08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Tom\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    memory=vectorstore.as_retriever()\n",
    ")\n",
    "# Set verbose to be true\n",
    "agent.chain.verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b51ba",
   "metadata": {},
   "source": [
    "## Run an example\n",
    "\n",
    "Here we will make it write a weather report for SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c032b182",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are Tom, Assistant\n",
      "Your decisions must always be made independently \n",
      "            without seeking user assistance. Play to your strengths \n",
      "            as an LLM and pursue simple strategies with no legal complications. \n",
      "            If you have completed all your tasks, \n",
      "            make sure to use the \"finish\" command.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. write a weather report for SF today\n",
      "\n",
      "\n",
      "Constraints:\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "\n",
      "Commands:\n",
      "1. search: useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"title\": \"Tool Input\", \"anyOf\": [{\"type\": \"string\"}, {\"type\": \"object\"}]}, \"v__duplicate_kwargs\": {\"title\": \"V  Duplicate Kwargs\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"verbose\": {\"title\": \"Verbose\", \"type\": \"boolean\"}, \"start_color\": {\"title\": \"Start Color\", \"default\": \"green\", \"type\": \"string\"}, \"color\": {\"title\": \"Color\", \"default\": \"green\", \"type\": \"string\"}, \"kwargs\": {\"title\": \"Kwargs\", \"type\": \"object\"}, \"args\": {\"title\": \"Args\", \"type\": \"array\", \"items\": {}}}\n",
      "2. write_file: Write file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}}\n",
      "3. read_file: Read file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
      "4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
      "\n",
      "Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "Performance Evaluation:\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "\n",
      "You should only respond in JSON format as described below \n",
      "Response Format: \n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\": {\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "} \n",
      "Ensure the response can be parsed by Python json.loads\n",
      "System: The current time and date is Tue Apr 18 18:48:12 2023\n",
      "System: This reminds you of these events from your past:\n",
      "[]\n",
      "\n",
      "\n",
      "Human: Determine which next command to use, and respond using the format specified above:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"I will start by writing a weather report for San Francisco today. I can use a search engine to find the current weather conditions and then write a report based on that information.\",\n",
      "        \"reasoning\": \"I need to complete my first objective, which is to write a weather report for San Francisco today. I will use a search engine to find the current weather conditions and then write a report based on that information.\",\n",
      "        \"plan\": \"- Use the search command to find the current weather conditions in San Francisco\\n- Write a weather report based on the information found\\n- Use the write_file command to save the weather report to disk\",\n",
      "        \"criticism\": \"I need to make sure that the weather report is accurate and up-to-date. I also need to make sure that I am using reliable sources for my information.\",\n",
      "        \"speak\": \"I will use a search engine to find the current weather conditions in San Francisco and then write a report based on that information.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"search\",\n",
      "        \"args\": {\n",
      "            \"tool_input\": \"san francisco weather\",\n",
      "            \"verbose\": false,\n",
      "            \"start_color\": \"green\",\n",
      "            \"color\": \"green\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run() got an unexpected keyword argument 'tool_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwrite a weather report for SF today\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workplace/langchain/langchain/experimental/autonomous_agents/autogpt/agent.py:112\u001b[0m, in \u001b[0;36mAutoGPT.run\u001b[0;34m(self, goals)\u001b[0m\n\u001b[1;32m    110\u001b[0m tool \u001b[38;5;241m=\u001b[39m tools[action\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    114\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/workplace/langchain/langchain/tools/base.py:103\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e, verbose\u001b[38;5;241m=\u001b[39mverbose_)\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\n\u001b[1;32m    105\u001b[0m     observation, verbose\u001b[38;5;241m=\u001b[39mverbose_, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation\n",
      "File \u001b[0;32m~/workplace/langchain/langchain/tools/base.py:100\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m _to_args_and_kwargs(tool_input)\n\u001b[0;32m--> 100\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e, verbose\u001b[38;5;241m=\u001b[39mverbose_)\n",
      "File \u001b[0;32m~/workplace/langchain/langchain/agents/tools.py:21\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: run() got an unexpected keyword argument 'tool_input'"
     ]
    }
   ],
   "source": [
    "agent.run([\"write a weather report for SF today\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa264f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
