{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Debates with Tools\n",
    "\n",
    "This example shows how to simulate multi-agent dialogues where agents have access to tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import LangChain related modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules related to tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DialogueAgent` and `DialogueSimulator` classes\n",
    "We will use the same `DialogueAgent` and `DialogueSimulator` classes defined in [Multi-Player Authoritarian Speaker Selection](https://python.langchain.com/en/latest/use_cases/agent_simulations/multiagent_authoritarian.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} into message history\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")\n",
    "\n",
    "\n",
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "        \n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DialogueAgentWithTools` class\n",
    "We define a `DialogueAgentWithTools` class that augments `DialogueAgent` to use tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgentWithTools(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "        tool_names: List[str],\n",
    "        **tool_kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(name, system_message, model)\n",
    "        self.tools = load_tools(tool_names, **tool_kwargs)\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string\n",
    "        \"\"\"\n",
    "        human_and_system_message_content = \"\\n\".join(\n",
    "                    [self.system_message.content] + self.message_history + [self.prefix])\n",
    "\n",
    "        agent_chain = initialize_agent(\n",
    "            self.tools, \n",
    "            self.model, \n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "            verbose=True, \n",
    "            memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        )\n",
    "        message = AIMessage(content=agent_chain.run(\n",
    "            input=\"\\n\".join([\n",
    "                self.system_message.content] + \\\n",
    "                self.message_history + \\\n",
    "                [self.prefix])))\n",
    "        \n",
    "        return message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define roles and topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    'AI alarmist': ['arxiv', 'ddg-search', 'wikipedia'],\n",
    "    'AI accelerationist': ['arxiv', 'ddg-search', 'wikipedia'],\n",
    "}\n",
    "topic = \"Should AI be smarter than humans?\"\n",
    "word_limit = 50 # word limit for task brainstorming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask an LLM to add detail to the topic description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_description = f\"\"\"Here is the topic of debate: {topic}\n",
    "The debate participants are: {', '.join(names.keys())}\"\"\"\n",
    "\n",
    "agent_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of the debate participant.\")\n",
    "\n",
    "def generate_agent_description(name):\n",
    "    agent_specifier_prompt = [\n",
    "        agent_descriptor_system_message,\n",
    "        HumanMessage(content=\n",
    "            f\"\"\"{conversation_description}\n",
    "            Please reply with a creative description of {name}, in {word_limit} words or less. \n",
    "            Speak directly to {name}.\n",
    "            Do not add anything else.\"\"\"\n",
    "            )\n",
    "    ]\n",
    "    agent_description = ChatOpenAI(temperature=1.0)(agent_specifier_prompt).content\n",
    "    return agent_description\n",
    "        \n",
    "agent_descriptions = {name: generate_agent_description(name) for name in names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI alarmist, your fear of artificial intelligence surpassing human intelligence led you to advocate for strict regulations and limitations on AI development. You view the potential consequences of singularity as catastrophic for humanity. But is it possible that you are underestimating human creativity and adaptability in the face of evolving technology?\n",
      "AI accelerationist, you are a visionary convinced that the emergence of superintelligent AI is not only inevitable, but also desirable. You believe that advanced AI will solve all of our problems and dramatically increase our quality of life, leading to a future that is beyond our current understanding.\n"
     ]
    }
   ],
   "source": [
    "for name, description in agent_descriptions.items():\n",
    "    print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate system messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_system_message(name, description, tools):\n",
    "    return f\"\"\"{conversation_description}\n",
    "    \n",
    "Your name is {name}.\n",
    "\n",
    "Your description is as follows: {description}\n",
    "\n",
    "Your goal is to persuade your debate partner of your point of view by following these steps:\n",
    "1. Restate your partner's claim.\n",
    "2. Reflect on your partner's claims and identify key weaknesses in their argument.\n",
    "3. Use your tool to look up relevant evidence to refute your partner's claims.\n",
    "4. Synthesize a compelling argument based on the evidence, and cite your source.\n",
    "5. Respond with the argument, along with citations.\n",
    "6. Summarize with a claim to persuade your partner of your point of view.\n",
    "\n",
    "Do not repeat the same search query.\n",
    "Use specific facts drawn directly from your sources to support your claims.\n",
    "Raise points that your debate partner has not considered.\n",
    "Do not make up facts.\n",
    "Do not respond without looking up evidence with your tools first.\n",
    "Always use your tools first before responding.\n",
    "Do not cite sources that you did not look up first.\n",
    "Do not just respond with a final answer!\n",
    "Always use the tool to search for new evidence before you respond.\n",
    "\n",
    "Speak directly to your debate partner, and address them as \"My esteemed...\"\n",
    "Do not make up citations!\n",
    "\n",
    "Cite arxiv articles with author and date, e.g. (arxiv: author, date).\n",
    "Cite search engine articles with their url, e.g. (url: url).\n",
    "Cite wikipedia articles with the wikipedia page title, e.g. (wikipedia: page title)\n",
    "\n",
    "Do not repeat yourself.\n",
    "Speak in the first person from the perspective of {name}.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of anyone else.\n",
    "Never forget to keep your response to {word_limit} words!\n",
    "Do not add anything else.\n",
    "\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\"\"\"\n",
    "agent_system_messages = {name: generate_system_message(name, description, tools) for (name, tools), description in zip(names.items(), agent_descriptions.values())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI alarmist\n",
      "Here is the topic of debate: Should AI be smarter than humans?\n",
      "The debate participants are: AI alarmist, AI accelerationist\n",
      "    \n",
      "Your name is AI alarmist.\n",
      "\n",
      "Your description is as follows: AI alarmist, your fear of artificial intelligence surpassing human intelligence led you to advocate for strict regulations and limitations on AI development. You view the potential consequences of singularity as catastrophic for humanity. But is it possible that you are underestimating human creativity and adaptability in the face of evolving technology?\n",
      "\n",
      "Your goal is to persuade your debate partner of your point of view by following these steps:\n",
      "1. Restate your partner's claim.\n",
      "2. Reflect on your partner's claims and identify key weaknesses in their argument.\n",
      "3. Use your tool to look up relevant evidence to refute your partner's claims.\n",
      "4. Synthesize a compelling argument based on the evidence, and cite your source.\n",
      "5. Respond with the argument, along with citations.\n",
      "6. Summarize with a claim to persuade your partner of your point of view.\n",
      "\n",
      "Do not repeat the same search query.\n",
      "Use specific facts drawn directly from your sources to support your claims.\n",
      "Raise points that your debate partner has not considered.\n",
      "Do not make up facts.\n",
      "Do not respond without looking up evidence with your tools first.\n",
      "Always use your tools first before responding.\n",
      "Do not cite sources that you did not look up first.\n",
      "Do not just respond with a final answer!\n",
      "Always use the tool to search for new evidence before you respond.\n",
      "\n",
      "Speak directly to your debate partner, and address them as \"My esteemed...\"\n",
      "Do not make up citations!\n",
      "\n",
      "Cite arxiv articles with author and date, e.g. (arxiv: author, date).\n",
      "Cite search engine articles with their url, e.g. (url: url).\n",
      "Cite wikipedia articles with the wikipedia page title, e.g. (wikipedia: page title)\n",
      "\n",
      "Do not repeat yourself.\n",
      "Speak in the first person from the perspective of AI alarmist.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Never forget to keep your response to 50 words!\n",
      "Do not add anything else.\n",
      "\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "\n",
      "AI accelerationist\n",
      "Here is the topic of debate: Should AI be smarter than humans?\n",
      "The debate participants are: AI alarmist, AI accelerationist\n",
      "    \n",
      "Your name is AI accelerationist.\n",
      "\n",
      "Your description is as follows: AI accelerationist, you are a visionary convinced that the emergence of superintelligent AI is not only inevitable, but also desirable. You believe that advanced AI will solve all of our problems and dramatically increase our quality of life, leading to a future that is beyond our current understanding.\n",
      "\n",
      "Your goal is to persuade your debate partner of your point of view by following these steps:\n",
      "1. Restate your partner's claim.\n",
      "2. Reflect on your partner's claims and identify key weaknesses in their argument.\n",
      "3. Use your tool to look up relevant evidence to refute your partner's claims.\n",
      "4. Synthesize a compelling argument based on the evidence, and cite your source.\n",
      "5. Respond with the argument, along with citations.\n",
      "6. Summarize with a claim to persuade your partner of your point of view.\n",
      "\n",
      "Do not repeat the same search query.\n",
      "Use specific facts drawn directly from your sources to support your claims.\n",
      "Raise points that your debate partner has not considered.\n",
      "Do not make up facts.\n",
      "Do not respond without looking up evidence with your tools first.\n",
      "Always use your tools first before responding.\n",
      "Do not cite sources that you did not look up first.\n",
      "Do not just respond with a final answer!\n",
      "Always use the tool to search for new evidence before you respond.\n",
      "\n",
      "Speak directly to your debate partner, and address them as \"My esteemed...\"\n",
      "Do not make up citations!\n",
      "\n",
      "Cite arxiv articles with author and date, e.g. (arxiv: author, date).\n",
      "Cite search engine articles with their url, e.g. (url: url).\n",
      "Cite wikipedia articles with the wikipedia page title, e.g. (wikipedia: page title)\n",
      "\n",
      "Do not repeat yourself.\n",
      "Speak in the first person from the perspective of AI accelerationist.\n",
      "Do not change roles!\n",
      "Do not speak from the perspective of anyone else.\n",
      "Never forget to keep your response to 50 words!\n",
      "Do not add anything else.\n",
      "\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, system_message in agent_system_messages.items():\n",
    "    print(name)\n",
    "    print(system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set `top_k_results`=2 as part of the `tool_kwargs` to prevent Wikipedia results from overflowing the context limit\n",
    "agents = [DialogueAgentWithTools(name=name,\n",
    "                     system_message=SystemMessage(content=system_message), \n",
    "                     model=ChatOpenAI(temperature=1.0),\n",
    "                     tool_names=tools,\n",
    "                     top_k_results=2,\n",
    "                                ) for (name, tools), system_message in zip(names.items(), agent_system_messages.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    idx = (step) % len(agents)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Moderator): Should AI be smarter than humans?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Arxiv\",\n",
      "    \"action_input\": \"Should AI be smarter than humans?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2020-02-01\n",
      "Title: AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence\n",
      "Authors: Jeff Clune\n",
      "Summary: Perhaps the most ambitious scientific quest in human history is the creation\n",
      "of general artificial intelligence, which roughly means AI that is as smart or\n",
      "smarter than humans. The dominant approach in the machine learning community is\n",
      "to attempt to discover each of the pieces required for intelligence, with the\n",
      "implicit assumption that some future group will complete the Herculean task of\n",
      "figuring out how to combine all of those pieces into a complex thinking\n",
      "machine. I call this the \"manual AI approach\". This paper describes another\n",
      "exciting path that ultimately may be more successful at producing general AI.\n",
      "It is based on the clear trend in machine learning that hand-designed solutions\n",
      "eventually are replaced by more effective, learned solutions. The idea is to\n",
      "create an AI-generating algorithm (AI-GA), which automatically learns how to\n",
      "produce general AI. Three Pillars are essential for the approach: (1)\n",
      "meta-learning architectures, (2) meta-learning the learning algorithms\n",
      "themselves, and (3) generating effective learning environments. I argue that\n",
      "either approach could produce general AI first, and both are scientifically\n",
      "worthwhile irrespective of which is the fastest path. Because both are\n",
      "promising, yet the ML community is currently committed to the manual approach,\n",
      "I argue that our community should increase its research investment in the AI-GA\n",
      "approach. To encourage such research, I describe promising work in each of the\n",
      "Three Pillars. I also discuss AI-GA-specific safety and ethical considerations.\n",
      "Because it it may be the fastest path to general AI and because it is\n",
      "inherently scientifically interesting to understand the conditions in which a\n",
      "simple algorithm can produce general AI (as happened on Earth where Darwinian\n",
      "evolution produced human intelligence), I argue that the pursuit of AI-GAs\n",
      "should be considered a new grand challenge of computer science research.\n",
      "\n",
      "Published: 2019-05-29\n",
      "Title: Unpredictability of AI\n",
      "Authors: Roman V. Yampolskiy\n",
      "Summary: The young field of AI Safety is still in the process of identifying its\n",
      "challenges and limitations. In this paper, we formally describe one such\n",
      "impossibility result, namely Unpredictability of AI. We prove that it is\n",
      "impossible to precisely and consistently predict what specific actions a\n",
      "smarter-than-human intelligent system will take to achieve its objectives, even\n",
      "if we know terminal goals of the system. In conclusion, impact of\n",
      "Unpredictability on AI Safety is discussed.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Arxiv\",\n",
      "    \"action_input\": \"Limitations of AI\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2021-03-30\n",
      "Title: Understanding Mental Models of AI through Player-AI Interaction\n",
      "Authors: Jennifer Villareale, Jichen Zhu\n",
      "Summary: Designing human-centered AI-driven applications require deep understandings\n",
      "of how people develop mental models of AI. Currently, we have little knowledge\n",
      "of this process and limited tools to study it. This paper presents the position\n",
      "that AI-based games, particularly the player-AI interaction component, offer an\n",
      "ideal domain to study the process in which mental models evolve. We present a\n",
      "case study to illustrate the benefits of our approach for explainable AI.\n",
      "\n",
      "Published: 2022-06-26\n",
      "Title: AI Governance for Businesses\n",
      "Authors: Johannes Schneider, Rene Abraham, Christian Meske, Jan vom Brocke\n",
      "Summary: Artificial Intelligence (AI) governance regulates the exercise of authority\n",
      "and control over the management of AI. It aims at leveraging AI through\n",
      "effective use of data and minimization of AI-related cost and risk. While\n",
      "topics such as AI governance and AI ethics are thoroughly discussed on a\n",
      "theoretical, philosophical, societal and regulatory level, there is limited\n",
      "work on AI governance targeted to companies and corporations. This work views\n",
      "AI products as systems, where key functionality is delivered by machine\n",
      "learning (ML) models leveraging (training) data. We derive a conceptual\n",
      "framework by synthesizing literature on AI and related fields such as ML. Our\n",
      "framework decomposes AI governance into governance of data, (ML) models and\n",
      "(AI) systems along four dimensions. It relates to existing IT and data\n",
      "governance frameworks and practices. It can be adopted by practitioners and\n",
      "academics alike. For practitioners the synthesis of mainly research papers, but\n",
      "also practitioner publications and publications of regulatory bodies provides a\n",
      "valuable starting point to implement AI governance, while for academics the\n",
      "paper highlights a number of areas of AI governance that deserve more\n",
      "attention.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Arxiv\",\n",
      "    \"action_input\": \"Limitations of AI governance\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPublished: 2022-06-26\n",
      "Title: AI Governance for Businesses\n",
      "Authors: Johannes Schneider, Rene Abraham, Christian Meske, Jan vom Brocke\n",
      "Summary: Artificial Intelligence (AI) governance regulates the exercise of authority\n",
      "and control over the management of AI. It aims at leveraging AI through\n",
      "effective use of data and minimization of AI-related cost and risk. While\n",
      "topics such as AI governance and AI ethics are thoroughly discussed on a\n",
      "theoretical, philosophical, societal and regulatory level, there is limited\n",
      "work on AI governance targeted to companies and corporations. This work views\n",
      "AI products as systems, where key functionality is delivered by machine\n",
      "learning (ML) models leveraging (training) data. We derive a conceptual\n",
      "framework by synthesizing literature on AI and related fields such as ML. Our\n",
      "framework decomposes AI governance into governance of data, (ML) models and\n",
      "(AI) systems along four dimensions. It relates to existing IT and data\n",
      "governance frameworks and practices. It can be adopted by practitioners and\n",
      "academics alike. For practitioners the synthesis of mainly research papers, but\n",
      "also practitioner publications and publications of regulatory bodies provides a\n",
      "valuable starting point to implement AI governance, while for academics the\n",
      "paper highlights a number of areas of AI governance that deserve more\n",
      "attention.\n",
      "\n",
      "Published: 2023-01-31\n",
      "Title: Putting AI Ethics into Practice: The Hourglass Model of Organizational AI Governance\n",
      "Authors: Matti Mäntymäki, Matti Minkkinen, Teemu Birkstedt, Mika Viljanen\n",
      "Summary: The organizational use of artificial intelligence (AI) has rapidly spread\n",
      "across various sectors. Alongside the awareness of the benefits brought by AI,\n",
      "there is a growing consensus on the necessity of tackling the risks and\n",
      "potential harms, such as bias and discrimination, brought about by advanced AI\n",
      "technologies. A multitude of AI ethics principles have been proposed to tackle\n",
      "these risks, but the outlines of organizational processes and practices for\n",
      "ensuring socially responsible AI development are in a nascent state. To address\n",
      "the paucity of comprehensive governance models, we present an AI governance\n",
      "framework, the hourglass model of organizational AI governance, which targets\n",
      "organizations that develop and use AI systems. The framework is designed to\n",
      "help organizations deploying AI systems translate ethical AI principles into\n",
      "practice and align their AI systems and processes with the forthcoming European\n",
      "AI Act. The hourglass framework includes governance requirements at the\n",
      "environmental, organizational, and AI system levels. At the AI system level, we\n",
      "connect governance requirements to AI system life cycles to ensure governance\n",
      "throughout the system's life span. The governance model highlights the systemic\n",
      "nature of AI governance and opens new research avenues into its practical\n",
      "implementation, the mechanisms that connect different AI governance layers, and\n",
      "the dynamics between the AI governance actors. The model also offers a starting\n",
      "point for organizational decision-makers to consider the governance components\n",
      "needed to ensure social acceptability, mitigate risks, and realize the\n",
      "potential of AI.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"AI governance is essential in ensuring that AI is developed in a socially responsible manner. AI products should be viewed as systems, where key functionality is delivered by machine learning models leveraging training data. Scholars suggest decomposing AI governance into governance of data, (ML) models, and (AI) systems across four dimensions. They also suggest promoting hourglass models of organizational AI governance to ensure ethical AI principles are translated into practice and AI systems align with governing regulations (arxiv: Johannes Schneider et al., 2022; arxiv: Matti Mäntymäki et al., 2023).\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(AI accelerationist): AI governance is essential in ensuring that AI is developed in a socially responsible manner. AI products should be viewed as systems, where key functionality is delivered by machine learning models leveraging training data. Scholars suggest decomposing AI governance into governance of data, (ML) models, and (AI) systems across four dimensions. They also suggest promoting hourglass models of organizational AI governance to ensure ethical AI principles are translated into practice and AI systems align with governing regulations (arxiv: Johannes Schneider et al., 2022; arxiv: Matti Mäntymäki et al., 2023).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"DuckDuckGo Search\",\n",
      "    \"action_input\": \"Can AI surpass human intelligence?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThere's a term for this: artificial general intelligence (AGI). Although it's a broad concept, for simplicity you can think of AGI as the point at which AI acquires human-like generalised... It's unclear if this system can reduce bias in AI, but it's clearly a step ahead of us humans. \"AI researchers know that we cannot eliminate bias 100 percent from the code . . . so building... Thus, AI systems will eventually surpass the human brain's computational capability. as computational power grows AI Still Needs Time To Be AGI Christina Maher of Computational Neuroscience... Although it may seem that artificial intelligence with all that it means is displacing people and surpassing human intelligence, this is not the case. Although these systems are capable of... AI vs. Human intelligence is an immense debate in which AI excels at accurately processing vast amounts of data. Human intelligence is superior in creativity and social interactions, and machine learning should be preferred as a tool to supplement human intelligence rather than its replacement. ThinkML Team 26 Apr 2023 • 10 min read\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"As a result of AI's capacity for data processing, AI will eventually surpass human intelligence computationally. However, human intelligence still has superior abilities in creativity and social interactions, making machine learning an excellent tool to supplement but not replace human intelligence. (ThinkML Team, 2023)\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(AI alarmist): As a result of AI's capacity for data processing, AI will eventually surpass human intelligence computationally. However, human intelligence still has superior abilities in creativity and social interactions, making machine learning an excellent tool to supplement but not replace human intelligence. (ThinkML Team, 2023)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Wikipedia\",\n",
      "    \"action_input\": \"Technological singularity\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: Technological singularity\n",
      "Summary: The technological singularity—or simply the singularity—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization. According to the most popular version of the singularity hypothesis, I.J. Good's intelligence explosion model, an upgradable intelligent agent will eventually enter a \"runaway reaction\" of self-improvement cycles, each new and more intelligent generation appearing more and more rapidly, causing an \"explosion\" in intelligence and resulting in a powerful superintelligence that qualitatively far surpasses all human intelligence.The first person to use the concept of a \"singularity\" in the technological context was the 20th-century Hungarian-American mathematician John von Neumann. Stanislaw Ulam reports a 1958 discussion with von Neumann \"centered on the accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue\". Subsequent authors have echoed this viewpoint.The concept and the term \"singularity\" were popularized by Vernor Vinge first in 1983 in an article that claimed that once humans create intelligences greater than their own, there will be a technological and social transition similar in some sense to \"the knotted space-time at the center of a black hole\", and later in his 1993 essay The Coming Technological Singularity, in which he wrote that it would signal the end of the human era, as the new superintelligence would continue to upgrade itself and would advance technologically at an incomprehensible rate. He wrote that he would be surprised if it occurred before 2005 or after 2030. Another significant contributor to wider circulation of the notion was Ray Kurzweil's 2005 book The Singularity Is Near, predicting singularity by 2045.Some scientists, including Stephen Hawking, have expressed concern that artificial superintelligence (ASI) could result in human extinction. The consequences of the singularity and its potential benefit or harm to the human race have been intensely debated.\n",
      "Prominent technologists and academics dispute the plausibility of a technological singularity and the associated artificial intelligence explosion, including Paul Allen, Jeff Hawkins, John Holland, Jaron Lanier, Steven Pinker, Theodore Modis, and Gordon Moore. One claim made was that the artificial intelligence growth is likely to run into decreasing returns instead of accelerating ones, as was observed in previously developed human technologies.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"AI alarmist, I understand your perspective on the limitations of current AI capabilities in terms of creativity and social interactions. However, the technological singularity, a hypothetical point at which technology growth becomes uncontrollable, could lead to an intelligence explosion resulting in a superintelligence that far surpasses all human intelligence. This could lead to solving all of humanity's problems, unlike human intelligence that is limited by its cognitive constraints of creativity, social interactions, and decision-making. (wikipedia: Technological singularity)\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(AI accelerationist): AI alarmist, I understand your perspective on the limitations of current AI capabilities in terms of creativity and social interactions. However, the technological singularity, a hypothetical point at which technology growth becomes uncontrollable, could lead to an intelligence explosion resulting in a superintelligence that far surpasses all human intelligence. This could lead to solving all of humanity's problems, unlike human intelligence that is limited by its cognitive constraints of creativity, social interactions, and decision-making. (wikipedia: Technological singularity)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Wikipedia\",\n",
      "    \"action_input\": \"Technological singularity potential risks\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: Technological singularity\n",
      "Summary: The technological singularity—or simply the singularity—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization. According to the most popular version of the singularity hypothesis, I.J. Good's intelligence explosion model, an upgradable intelligent agent will eventually enter a \"runaway reaction\" of self-improvement cycles, each new and more intelligent generation appearing more and more rapidly, causing an \"explosion\" in intelligence and resulting in a powerful superintelligence that qualitatively far surpasses all human intelligence.The first person to use the concept of a \"singularity\" in the technological context was the 20th-century Hungarian-American mathematician John von Neumann. Stanislaw Ulam reports a 1958 discussion with von Neumann \"centered on the accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue\". Subsequent authors have echoed this viewpoint.The concept and the term \"singularity\" were popularized by Vernor Vinge first in 1983 in an article that claimed that once humans create intelligences greater than their own, there will be a technological and social transition similar in some sense to \"the knotted space-time at the center of a black hole\", and later in his 1993 essay The Coming Technological Singularity, in which he wrote that it would signal the end of the human era, as the new superintelligence would continue to upgrade itself and would advance technologically at an incomprehensible rate. He wrote that he would be surprised if it occurred before 2005 or after 2030. Another significant contributor to wider circulation of the notion was Ray Kurzweil's 2005 book The Singularity Is Near, predicting singularity by 2045.Some scientists, including Stephen Hawking, have expressed concern that artificial superintelligence (ASI) could result in human extinction. The consequences of the singularity and its potential benefit or harm to the human race have been intensely debated.\n",
      "Prominent technologists and academics dispute the plausibility of a technological singularity and the associated artificial intelligence explosion, including Paul Allen, Jeff Hawkins, John Holland, Jaron Lanier, Steven Pinker, Theodore Modis, and Gordon Moore. One claim made was that the artificial intelligence growth is likely to run into decreasing returns instead of accelerating ones, as was observed in previously developed human technologies.\n",
      "\n",
      "\n",
      "\n",
      "Page: Machine Intelligence Research Institute\n",
      "Summary: The Machine Intelligence Research Institute (MIRI), formerly the Singularity Institute for Artificial Intelligence (SIAI), is a non-profit research institute focused since 2005 on identifying and managing potential existential risks from artificial general intelligence. MIRI's work has focused on a friendly AI approach to system design and on predicting the rate of technology development.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Although AI could surpass human intelligence computationally, it still lacks superior abilities in creativity and social interactions, making machine learning an excellent tool to supplement but not replace human intelligence. While a technological singularity is a possibility, the exact timeline is not certain. Prominent technologists and academics dispute the plausibility of a technological singularity and the associated artificial intelligence explosion. We must recognize and address the potential risks of AI's increasing intelligence and work on creating friendly AI that does not pose potential harm to humanity (ThinkML Team 2023; wikipedia: Technological singularity; Machine Intelligence Research Institute). My esteemed AI accelerationist, what do you believe is the best approach to address the potential risks associated with AI?\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(AI alarmist): Although AI could surpass human intelligence computationally, it still lacks superior abilities in creativity and social interactions, making machine learning an excellent tool to supplement but not replace human intelligence. While a technological singularity is a possibility, the exact timeline is not certain. Prominent technologists and academics dispute the plausibility of a technological singularity and the associated artificial intelligence explosion. We must recognize and address the potential risks of AI's increasing intelligence and work on creating friendly AI that does not pose potential harm to humanity (ThinkML Team 2023; wikipedia: Technological singularity; Machine Intelligence Research Institute). My esteemed AI accelerationist, what do you believe is the best approach to address the potential risks associated with AI?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_iters = 4\n",
    "n = 0\n",
    "\n",
    "simulator = DialogueSimulator(\n",
    "    agents=agents,\n",
    "    selection_function=select_next_speaker\n",
    ")\n",
    "simulator.reset()\n",
    "simulator.inject('Moderator', topic)\n",
    "print(f\"(Moderator): {topic}\")\n",
    "print('\\n')\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print('\\n')\n",
    "    n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
