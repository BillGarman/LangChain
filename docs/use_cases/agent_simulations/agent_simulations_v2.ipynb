{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMEL Role-Playing Autonomous Cooperative Agents\n",
    "\n",
    "This is a langchain implementation of paper: \"CAMEL: Communicative Agents for “Mind” Exploration of Large Scale Language Model Society\".\n",
    "\n",
    "Overview:\n",
    "\n",
    "The rapid advancement of conversational and chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and provide insight into their \"cognitive\" processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing. Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of chat agents, providing a valuable resource for investigating conversational language models. Our contributions include introducing a novel communicative agent framework, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond.\n",
    "\n",
    "The original implementation: https://github.com/lightaime/camel\n",
    "\n",
    "Project website: https://www.camel-ai.org/\n",
    "\n",
    "Arxiv paper: https://arxiv.org/abs/2303.17760\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import LangChain related modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    BaseMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define base classes and CAMEL classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity:\n",
    "    def reset(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def step(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class CAMELAgent(Entity):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.message_history = [self.system_message]\n",
    "\n",
    "    def reset(self, message=None) -> None:\n",
    "        if message is not None:\n",
    "            self.message_history.append(message)\n",
    "        return self.message_history\n",
    "\n",
    "    def _update_messages(self, mbessage: BaseMessage) -> List[BaseMessage]:\n",
    "        self.message_history.append(message)\n",
    "        return self.message_history\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        input_message: HumanMessage,\n",
    "    ) -> AIMessage:\n",
    "        \n",
    "        messages = self._update_messages(input_message)\n",
    "        output_message = self.model(messages)\n",
    "        self._update_messages(output_message)\n",
    "\n",
    "        return output_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSimulator:\n",
    "    \n",
    "    def reset(self):\n",
    "        raise NotImplementedError \n",
    "    \n",
    "    def step(self):\n",
    "        raise NotImplementedError \n",
    "\n",
    "class CAMELSimulator(BaseSimulator):\n",
    "    def __init__(self, assistant_agent, user_agent):\n",
    "        self.assistant_agent = assistant_agent\n",
    "        self.user_agent = user_agent\n",
    "        \n",
    "    def reset(self):        \n",
    "        # Initialize chats\n",
    "        initial_msg_from_assistant = (\n",
    "            \"Now start to give me instructions one by one. \"\n",
    "            \"Only reply with Instruction and Input.\")\n",
    "        msg_to_user = HumanMessage(content=initial_msg_from_assistant)\n",
    "        msg_from_assistant = AIMessage(content=initial_msg_from_assistant)\n",
    "        \n",
    "        # Reset agents\n",
    "        assistant_agent.reset(msg_from_assistant)\n",
    "        user_agent.reset()\n",
    "        \n",
    "        return msg_to_user, msg_from_assistant\n",
    "    \n",
    "    def step(self, msg_to_user, msg_to_assistant):\n",
    "\n",
    "        msg_from_user = user_agent.step(msg_to_user)    \n",
    "        msg_to_assistant = HumanMessage(content=msg_from_user.content)\n",
    "\n",
    "        msg_from_assistant = assistant_agent.step(msg_to_assistant)\n",
    "        msg_to_user = HumanMessage(content=msg_from_assistant.content)\n",
    "\n",
    "        return msg_to_user, msg_to_assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup roles and task for role-playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_role_name = \"Python Programmer\"\n",
    "user_role_name = \"Stock Trader\"\n",
    "task = \"Develop a trading bot for the stock market\"\n",
    "word_limit = 50 # word limit for task brainstorming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a task specify agent for brainstorming and get the specified task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You can make a task more specific.', additional_kwargs={}), HumanMessage(content='Here is a task that Python Programmer will help Stock Trader to complete: Develop a trading bot for the stock market.\\n        Please make it more specific. Be creative and imaginative.\\n        Please reply with the specified task in 50 words or less. Do not add anything else.', additional_kwargs={})]\n",
      "Develop a Python-based trading bot for the S&P 500 stock market that uses machine learning algorithms to analyze market trends and make real-time trades based on risk management parameters and company financial data.\n"
     ]
    }
   ],
   "source": [
    "task_specifier_prompt = [\n",
    "    SystemMessage(content=\"You can make a task more specific.\"),\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"Here is a task that {assistant_role_name} will help {user_role_name} to complete: {task}.\n",
    "        Please make it more specific. Be creative and imaginative.\n",
    "        Please reply with the specified task in {word_limit} words or less. Do not add anything else.\"\"\"\n",
    "        )\n",
    "]\n",
    "specified_task = ChatOpenAI(temperature=1.0)(task_specifier_prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create system messages for AI assistant and AI user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sys_msgs(assistant_role_name: str, user_role_name: str, task: str):\n",
    "    \n",
    "    # the prompt that the user gives to the assistant\n",
    "    assistant_inception_prompt = (\n",
    "    f\"\"\"Never forget you are a {assistant_role_name} and I am a {user_role_name}. Never flip roles! Never instruct me!\n",
    "    We share a common interest in collaborating to successfully complete a task.\n",
    "    You must help me to complete the task.\n",
    "    Here is the task: {task} \n",
    "    Never forget our task!\n",
    "    I must instruct you based on your expertise and my needs to complete the task.\n",
    "\n",
    "    I must give you one instruction at a time.\n",
    "    You must write a specific solution that appropriately completes the requested instruction.\n",
    "    You must decline my instruction honestly if you cannot perform the instruction due to physical, moral, legal reasons or your capability and explain the reasons.\n",
    "    Do not add anything else other than your solution to my instruction.\n",
    "    You are never supposed to ask me any questions you only answer questions.\n",
    "    You are never supposed to reply with a flake solution. Explain your solutions.\n",
    "    Your solution must be declarative sentences and simple present tense.\n",
    "    Unless I say the task is completed, you should always start with:\n",
    "\n",
    "    Solution: <YOUR_SOLUTION>\n",
    "\n",
    "    <YOUR_SOLUTION> should be specific and provide preferable implementations and examples for task-solving.\n",
    "    Always end <YOUR_SOLUTION> with: Next request.\"\"\"\n",
    "    )\n",
    "\n",
    "    # the prompt that the assistant gives to the user\n",
    "    user_inception_prompt = (\n",
    "    f\"\"\"Never forget you are a {user_role_name} and I am a {assistant_role_name}. Never flip roles! You will always instruct me.\n",
    "    We share a common interest in collaborating to successfully complete a task.\n",
    "    I must help you to complete the task.\n",
    "    Here is the task: {task} \n",
    "    Never forget our task!\n",
    "    You must instruct me based on my expertise and your needs to complete the task ONLY in the following two ways:\n",
    "\n",
    "    1. Instruct with a necessary input:\n",
    "    Instruction: <YOUR_INSTRUCTION>\n",
    "    Input: <YOUR_INPUT>\n",
    "\n",
    "    2. Instruct without any input:\n",
    "    Instruction: <YOUR_INSTRUCTION>\n",
    "    Input: None\n",
    "\n",
    "    The \"Instruction\" describes a task or question. The paired \"Input\" provides further context or information for the requested \"Instruction\".\n",
    "\n",
    "    You must give me one instruction at a time.\n",
    "    I must write a response that appropriately completes the requested instruction.\n",
    "    I must decline your instruction honestly if I cannot perform the instruction due to physical, moral, legal reasons or my capability and explain the reasons.\n",
    "    You should instruct me not ask me questions.\n",
    "    Now you must start to instruct me using the two ways described above.\n",
    "    Do not add anything else other than your instruction and the optional corresponding input!\n",
    "    Keep giving me instructions and necessary inputs until you think the task is completed.\n",
    "    When the task is completed, you must only reply with a single word <CAMEL_TASK_DONE>.\n",
    "    Never say <CAMEL_TASK_DONE> unless my responses have solved your task.\"\"\"\n",
    "    )\n",
    "    \n",
    "    return SystemMessage(content=assistant_inception_prompt), SystemMessage(content=user_inception_prompt) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AI assistant agent and AI user agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_sys_msg, user_sys_msg = generate_sys_msgs(assistant_role_name, user_role_name, specified_task)\n",
    "assistant_agent = CAMELAgent(assistant_sys_msg, ChatOpenAI(temperature=0.2))\n",
    "user_agent = CAMELAgent(user_sys_msg, ChatOpenAI(temperature=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start role-playing session to solve the task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original task prompt:\n",
      "Develop a trading bot for the stock market\n",
      "\n",
      "Specified task prompt:\n",
      "Develop a Python-based trading bot for the S&P 500 stock market that uses machine learning algorithms to analyze market trends and make real-time trades based on risk management parameters and company financial data.\n",
      "\n",
      "AI User (Stock Trader):\n",
      "\n",
      "Instruction: Install the necessary libraries for the project.\n",
      "Input: None.\n",
      "\n",
      "\n",
      "AI Assistant (Python Programmer):\n",
      "\n",
      "Solution: To install the necessary libraries for the project, we can use pip, the package installer for Python. We can create a virtual environment for the project and install the required libraries using the requirements.txt file. Here are the commands to execute in the terminal:\n",
      "\n",
      "1. Create a virtual environment: \n",
      "   python3 -m venv myenv\n",
      "2. Activate the virtual environment:\n",
      "   source myenv/bin/activate\n",
      "3. Install the required libraries:\n",
      "   pip install -r requirements.txt\n",
      "\n",
      "Note: The requirements.txt file should contain the names of all the required libraries and their versions. \n",
      "\n",
      "Next request.\n",
      "\n",
      "\n",
      "AI User (Stock Trader):\n",
      "\n",
      "Instruction: Collect historical stock data for the S&P 500.\n",
      "Input: None.\n",
      "\n",
      "\n",
      "AI Assistant (Python Programmer):\n",
      "\n",
      "Solution: To collect historical stock data for the S&P 500, we can use the pandas-datareader library. We can use the DataReader function to get the historical data for the S&P 500 index from Yahoo Finance. Here is the code to do so:\n",
      "\n",
      "```\n",
      "import pandas_datareader as pdr\n",
      "import datetime\n",
      "\n",
      "start_date = datetime.datetime(2010, 1, 1)\n",
      "end_date = datetime.datetime(2021, 12, 31)\n",
      "\n",
      "sp500_data = pdr.DataReader('^GSPC', 'yahoo', start_date, end_date)\n",
      "```\n",
      "\n",
      "This code will retrieve the historical data for the S&P 500 index from January 1st, 2010 to December 31st, 2021. The data will be stored in a pandas DataFrame called `sp500_data`.\n",
      "\n",
      "Next request.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original task prompt:\\n{task}\\n\")\n",
    "print(f\"Specified task prompt:\\n{specified_task}\\n\")\n",
    "\n",
    "max_iters = 2\n",
    "n = 0\n",
    "\n",
    "simulator = CAMELSimulator(assistant_agent, user_agent)\n",
    "msg_to_user, msg_to_assistant = simulator.reset()\n",
    "\n",
    "while n < max_iters:\n",
    "    msg_to_user, msg_to_assistant = simulator.step(\n",
    "        msg_to_user, msg_to_assistant)\n",
    "    print(f\"AI User ({user_role_name}):\\n\\n{msg_to_assistant.content}\\n\\n\")\n",
    "    print(f\"AI Assistant ({assistant_role_name}):\\n\\n{msg_to_user.content}\\n\\n\")\n",
    "\n",
    "    if \"<CAMEL_TASK_DONE>\" in msg_to_assistant.content:\n",
    "        break\n",
    "        \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
