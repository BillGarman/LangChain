{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e9b619",
   "metadata": {},
   "source": [
    "# MarkdownHeaderTextSplitter\n",
    "\n",
    "The objective is to split a markdown file by aribrary delimiters.\n",
    "\n",
    "Each text split is associated with its associated delimiters as metadata.\n",
    " \n",
    "**Given this example:**\n",
    "\n",
    "# Foo\n",
    "\n",
    "## Bar\n",
    "\n",
    "Hi this is Jim\n",
    "\n",
    "Hi this is Joe\n",
    "\n",
    "## Baz\n",
    "\n",
    "Hi this is Molly\n",
    "\n",
    "**And these delimiters:**\n",
    "\n",
    "```\n",
    "[(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"\\n\", None)]\n",
    "```\n",
    "\n",
    "**We expect:** \n",
    "\n",
    "```\n",
    "{\"content\": \"Hi this is Jim\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Joe\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Molly\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Baz\"}},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c044f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20c5475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': ''}}\n"
     ]
    }
   ],
   "source": [
    "# Doc\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "# Test case 1\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f29056",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"content\": \"Hi this is Jim\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Joe\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Molly\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Baz\"}},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34521b8e",
   "metadata": {},
   "source": [
    "`Test case 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78617b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'This is an introductory paragraph.', 'metadata': {'Header 2': 'Overview', 'Header 1': ''}}\n",
      "{'content': 'This is a detailed paragraph.', 'metadata': {'Header 2': 'Details', 'Header 1': ''}}\n",
      "{'content': 'This is the conclusion.', 'metadata': {'Header 2': 'Details', 'Header 1': ''}}\n"
     ]
    }
   ],
   "source": [
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "markdown_document = '# Introduction\\n\\n## Overview\\n\\nThis is an introductory paragraph.\\\n",
    "\\n\\n## Details\\n\\nThis is a detailed paragraph.\\n\\n# Conclusion\\n\\nThis is the conclusion.'\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cfdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected\n",
    "{'content': 'This is an introductory paragraph.', 'metadata': {'Header 2': 'Overview', 'Header 1': 'Introduction'}}\n",
    "{'content': 'This is a detailed paragraph.', 'metadata': {'Header 2': 'Details', 'Header 1': 'Introduction'}}\n",
    "{'content': 'This is the conclusion.', 'metadata': {'Header 1': 'Conclusion'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f74dfa",
   "metadata": {},
   "source": [
    "`Test case 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17813ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Text under H3.', 'metadata': {'Header 3': 'H3', 'Header 2': 'H2', 'Header 1': 'H1'}}\n",
      "{'content': 'Text under H2_2.', 'metadata': {'Header 3': 'H3', 'Header 2': 'H2_2', 'Header 1': 'H1_2'}}\n"
     ]
    }
   ],
   "source": [
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "markdown_document = '# H1\\n\\n## H2\\n\\n### H3\\n\\nText under H3.\\n\\n# H1_2\\n\\n## H2_2\\n\\nText under H2_2.'\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'content': 'Text under H3.', 'metadata': {'Header 3': 'H3', 'Header 2': 'H2', 'Header 1': 'H1'}}\n",
    "{'content': 'Text under H2_2.', 'metadata': {'Header 2': 'H2_2', 'Header 1': 'H1_2'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add24254",
   "metadata": {},
   "source": [
    "`Test case 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20907fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Paragraph under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
      "{'content': 'Paragraph 2 under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
      "{'content': 'Paragraph under new Heading 1.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'New Heading 1'}}\n"
     ]
    }
   ],
   "source": [
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "markdown_document = '# Heading 1\\n\\n## Heading 2\\n\\nParagraph under Heading 2.\\\n",
    "\\n\\nParagraph 2 under Heading 2.\\n\\n# New Heading 1\\n\\nParagraph under new Heading 1.'\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'content': 'Paragraph under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
    "{'content': 'Paragraph 2 under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
    "{'content': 'Paragraph under new Heading 1.', 'metadata': {'Header 1': 'New Heading 1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea887e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9b993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e75ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aeb8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19abdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Hi this is Jim',\n",
       "  'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}},\n",
       " {'content': 'Hi this is Joe',\n",
       "  'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}},\n",
       " {'content': 'Hi this is Molly',\n",
       "  'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081361fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is JimHi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Test case 2\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636d0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Lance', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Three levels\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly'\n",
    "\n",
    "# Test case 3\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "\n",
    "# TODO: Reset header 3 Boo as empty\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f2870e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e48eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from typing import Dict, Any, List, Optional, Tuple, Union\n",
    "\n",
    "class MarkdownHeaderTextSplitter(TextSplitter):\n",
    "    \"\"\"Implementation of splitting markdown based on user-supplied delimiters.\n",
    "    The text associated with each delimiter is returned w/ delimier as metadata.\"\"\"\n",
    "\n",
    "    def __init__(self, splits: List[Tuple[str, Optional[str]]], **kwargs: Any):\n",
    "        super().__init__(**kwargs)\n",
    "        self.splits = sorted(splits, key=lambda x: (-len(x[0]), -x[0].count(\"#\")))\n",
    "\n",
    "    def split_text(self, text: str) -> List[Dict[str, Union[str, str]]]:\n",
    "        pattern = \"|\".join(\n",
    "            \"(%s\\\\s*(.*))\" % re.escape(sep) for sep, _ in self.splits if sep != \"\\n\"\n",
    "        )\n",
    "\n",
    "        chunks = []\n",
    "        current_metadata = {name: \"\" for sep, name in self.splits if name}\n",
    "        current_content = []\n",
    "\n",
    "        for line in text.splitlines(keepends=True):\n",
    "            stripped_line = line.lstrip()  # strip leading spaces\n",
    "            match = re.match(pattern, stripped_line)\n",
    "\n",
    "            if match:\n",
    "                if current_content:\n",
    "                    chunks.append(\n",
    "                        {\n",
    "                            \"content\": \"\".join(current_content).strip(),\n",
    "                            \"metadata\": dict(current_metadata),\n",
    "                        }\n",
    "                    )\n",
    "                    current_content = []\n",
    "\n",
    "                for sep, name in self.splits:\n",
    "                    if stripped_line.startswith(sep):\n",
    "                        if name is not None:\n",
    "                            # Update the rest of the line (after the separator) as the value for that header\n",
    "                            current_metadata[name] = stripped_line[len(sep):].strip()\n",
    "                            \n",
    "                            # Clear out metadata for all headers lower in hierarchy\n",
    "                            current_header_index = [index for index, (sep_, _) in enumerate(self.splits) if sep_ == sep][0]\n",
    "                            for header, index in [(name_, index) for index, (sep_, name_) in enumerate(self.splits) if name_]:\n",
    "                                if index > current_header_index:\n",
    "                                    current_metadata[header] = ''\n",
    "\n",
    "                        # Remove matched separator from the line to avoid confusing next header levels\n",
    "                        stripped_line = stripped_line[len(sep):].lstrip()\n",
    "                        break\n",
    "\n",
    "            elif not stripped_line and (\"\\n\", None) in self.splits:\n",
    "                if current_content:\n",
    "                    chunks.append(\n",
    "                        {\n",
    "                            \"content\": \"\".join(current_content).strip(),\n",
    "                            \"metadata\": dict(current_metadata),\n",
    "                        }\n",
    "                    )\n",
    "                    current_content = []\n",
    "\n",
    "            elif stripped_line:\n",
    "                current_content.append(line)  # append the original line (with leading spaces if any)\n",
    "\n",
    "        if current_content:\n",
    "            chunks.append(\n",
    "                {\n",
    "                    \"content\": \"\".join(current_content).strip(),\n",
    "                    \"metadata\": dict(current_metadata),\n",
    "                }\n",
    "            )\n",
    "        return [chunk for chunk in chunks if chunk[\"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ad61aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': ''}}\n"
     ]
    }
   ],
   "source": [
    "# Doc\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "# Test case 1\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633664ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6ca3059",
   "metadata": {},
   "source": [
    "`Modified Code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "495b72b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Lance', 'metadata': {'Header 3': 'Boo', 'Header 2': '', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Baz', 'Header 1': ''}}\n"
     ]
    }
   ],
   "source": [
    "class MarkdownHeaderTextSplitter(TextSplitter):\n",
    "    \n",
    "    def __init__(self, splits: List[Tuple[str, Optional[str]]], **kwargs: Any):\n",
    "        super().__init__(**kwargs)\n",
    "        self.splits = sorted(splits, key=lambda x: (-len(x[0]), -x[0].count('#')))\n",
    "\n",
    "    def split_text(self, text: str) -> List[Dict[str, Union[str, str]]]:\n",
    "        pattern = '|'.join('(%s\\\\s*(.*))' % re.escape(sep) for sep, _ in self.splits if sep != \"\\n\")\n",
    "        chunks = []\n",
    "        current_metadata = {name: '' for sep, name in self.splits if name}\n",
    "        current_content = []\n",
    "        \n",
    "        for line in text.splitlines(keepends=True):\n",
    "            stripped_line = line.strip()\n",
    "            match = re.match(pattern, stripped_line)\n",
    "\n",
    "            if match:\n",
    "                if current_content:\n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(),\n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    current_content = []\n",
    "\n",
    "                for sep, name in self.splits:\n",
    "                    if stripped_line.startswith(sep):\n",
    "                        if name is not None:\n",
    "                            current_metadata[name] = stripped_line.lstrip(sep).strip()\n",
    "                            current_header_index = [index for index, (sep_, _) in enumerate(self.splits) if sep_ == sep][0]\n",
    "                            for header_index, (sep_, name) in enumerate(self.splits):\n",
    "                                if header_index > current_header_index:\n",
    "                                    if name:\n",
    "                                        current_metadata[name] = ''\n",
    "                        break\n",
    "            elif not stripped_line and (\"\\n\", None) in self.splits:\n",
    "                if current_content:\n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(),\n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    current_content = []\n",
    "            elif stripped_line:\n",
    "                current_content.append(line)\n",
    "        \n",
    "        if current_content:\n",
    "            chunks.append({\n",
    "                'content': ''.join(current_content).strip(),\n",
    "                'metadata': dict(current_metadata)\n",
    "            })\n",
    "        return [chunk for chunk in chunks if chunk['content']]\n",
    "\n",
    "\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ea97813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Lance', 'metadata': {'Header 3': 'Boo', 'Header 2': '', 'Header 1': ''}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Baz', 'Header 1': ''}}\n"
     ]
    }
   ],
   "source": [
    "class MarkdownHeaderTextSplitter(TextSplitter):\n",
    "    \n",
    "    def __init__(self, splits: List[Tuple[str, Optional[str]]], **kwargs: Any):\n",
    "        super().__init__(**kwargs)\n",
    "        self.splits = sorted(splits, key=lambda x: (-len(x[0]), -x[0].count('#')))\n",
    "\n",
    "    def split_text(self, text: str) -> List[Dict[str, Union[str, str]]]:\n",
    "        pattern = '|'.join('(%s\\\\s*(.*))' % re.escape(sep) for sep, _ in self.splits if sep != \"\\n\")\n",
    "        chunks = []\n",
    "        current_metadata = {name: '' for sep, name in self.splits if name}\n",
    "        current_content = []\n",
    "\n",
    "        def remove_prefix(text, prefix):\n",
    "            if text.startswith(prefix):\n",
    "                return text[len(prefix):]\n",
    "            return text\n",
    "        \n",
    "        for line in text.splitlines(keepends=True):\n",
    "            stripped_line = line.strip()\n",
    "            match = re.match(pattern, stripped_line)\n",
    "\n",
    "            if match:\n",
    "                if current_content:\n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(),\n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    current_content = []\n",
    "\n",
    "                for sep, name in self.splits:\n",
    "                    if stripped_line.startswith(sep):\n",
    "                        if name is not None:\n",
    "                            current_metadata[name] = remove_prefix(stripped_line, sep).strip()\n",
    "                            current_header_index = [index for index, (sep_, _) in enumerate(self.splits) if sep_ == sep][0]\n",
    "                            for header_index, (sep_, name) in enumerate(self.splits):\n",
    "                                if header_index > current_header_index:\n",
    "                                    if name:\n",
    "                                        current_metadata[name] = ''\n",
    "                        break\n",
    "            elif not stripped_line and (\"\\n\", None) in self.splits:\n",
    "                if current_content:\n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(),\n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    current_content = []\n",
    "            elif stripped_line:\n",
    "                current_content.append(line)\n",
    "        \n",
    "        if current_content:\n",
    "            chunks.append({\n",
    "                'content': ''.join(current_content).strip(),\n",
    "                'metadata': dict(current_metadata)\n",
    "            })\n",
    "        return [chunk for chunk in chunks if chunk['content']]\n",
    "\n",
    "\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62863736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32428a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cc955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3504dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Lance', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Three levels\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly'\n",
    "\n",
    "# Test case 3\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "\n",
    "# TODO: Reset header 3 Boo as empty\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af59a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78fdd026",
   "metadata": {},
   "source": [
    "`Original Code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f865704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "class MarkdownHeaderTextSplitter(TextSplitter):\n",
    "    \n",
    "    def __init__(self, splits: List[Tuple[str, Optional[str]]], **kwargs: Any):\n",
    "        \n",
    "        # Sort by seperator length and the number of \"#\"\n",
    "        # E.g.,  Ensure \"###\" will come before \"##\" and \"#\"\n",
    "        # TODO: Both means of sorting may not be required \n",
    "        \"\"\"Create a new TextSplitter.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.splits = sorted(splits, key=lambda x: (-len(x[0]), -x[0].count('#')))\n",
    "\n",
    "    def split_text(self, text: str) -> List[Dict[str, Union[str, str]]]:\n",
    "        \n",
    "        # Regex matches any of the separators in self.splits (except for the newline)\n",
    "        # (Newlines create line breaks, which we may want to split, or separate MD headers and their contents)\n",
    "        pattern = '|'.join('(%s\\\\s*(.*))' % re.escape(sep) for sep, _ in self.splits if sep != \"\\n\")\n",
    "        \n",
    "        # Text chunk with metadata\n",
    "        chunks = []\n",
    "        \n",
    "        # Keys are names of metadata \n",
    "        #current_metadata = {name: '' for sep, name in self.splits if name is not None}\n",
    "        current_metadata = {name: '' for sep, name in self.splits if name}\n",
    "        current_content = []\n",
    "        \n",
    "        # Split by newlines, but preserve the exact formatting of the original text\n",
    "        for line in text.splitlines(keepends=True):\n",
    "            \n",
    "            # Removes any leading or trailing whitespace\n",
    "            stripped_line = line.strip()  \n",
    "            \n",
    "            # Match current line of text against the regular expression pattern\n",
    "            match = re.match(pattern, stripped_line)\n",
    "            \n",
    "            # If the line starts w/ a separator defined in splits (like \"#\" or \"##\"), it will be a match\n",
    "            # Start of a new chunk of content\n",
    "            if match:\n",
    "                \n",
    "                # See if we have accumulated content from previous lines \n",
    "                if current_content:  \n",
    "                    \n",
    "                    # If so, append it as a chunk and write the chunk since we hit a new seperator\n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(), \n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    # Reset the content  \n",
    "                    current_content = []  \n",
    "                    \n",
    "                # Check for the seperator\n",
    "                for sep, name in self.splits:\n",
    "                    if stripped_line.startswith(sep):\n",
    "                        if name is not None:\n",
    "                            # Update the rest of the line (after the separator) as the value for that header\n",
    "                            current_metadata[name] = stripped_line[len(sep):].strip()\n",
    "                            \n",
    "                            # If the separator is \"#\", it also clears out the metadata for \"Header 2\"\n",
    "                            # A new \"Header 1\" implies a new section of the document\n",
    "                            # TODO: This is brittle since there can be many header names\n",
    "                            #if sep == \"#\":\n",
    "                            #    current_metadata[\"Header 2\"] = ''   \n",
    "                            if sep == \"#\":\n",
    "                                # clear out metadata for all headers lower in hierarchy\n",
    "                                current_header_index = [index for index, (sep_, _) in enumerate(self.splits) if sep_ == sep][0]\n",
    "                                current_metadata_keys = list(current_metadata.keys())\n",
    "                                for header in current_metadata_keys:\n",
    "                                    header_index = [index for index, (_, name) in enumerate(self.splits) if name == header]\n",
    "                                    if header_index and header_index[0] > current_header_index:\n",
    "                                        del current_metadata[header]\n",
    "                        break\n",
    "            \n",
    "            # If the line is empty (i.e., only contains whitespace, or is completely empty) \n",
    "            # and newline (\"\\n\") is one of the separators, it appends the current content to \n",
    "            # the chunks list as a new chunk, and resets the current_content to an empty list  \n",
    "            elif not stripped_line and (\"\\n\", None) in self.splits:  \n",
    "                \n",
    "                # If we have accumulated content, append it as a chunk\n",
    "                if current_content:  \n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(), \n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    current_content = []  # reset the content\n",
    "            \n",
    "            # Apend non-empty lines\n",
    "            elif stripped_line:  \n",
    "                current_content.append(stripped_line)\n",
    "        \n",
    "        # Append the last chunk\n",
    "        if current_content:\n",
    "            chunks.append({\n",
    "                'content': ''.join(current_content).strip(), \n",
    "                'metadata': dict(current_metadata)\n",
    "            })\n",
    "        return [chunk for chunk in chunks if chunk['content']]\n",
    "\n",
    "# Doc\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "# Test case 1\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9edb507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Lance', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Three levels\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly'\n",
    "\n",
    "# Test case 3\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "\n",
    "# TODO: Reset header 3 Boo as empty\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a578b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610ceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
