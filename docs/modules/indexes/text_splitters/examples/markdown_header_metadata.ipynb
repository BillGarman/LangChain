{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e9b619",
   "metadata": {},
   "source": [
    "# MarkdownHeaderTextSplitter\n",
    "\n",
    "The objective is to split a MD file by aribrary delimiters and store context associated delimiters as metadata.\n",
    "\n",
    "Given this example:\n",
    "\n",
    "--- \n",
    "\n",
    "# Foo\n",
    "\n",
    "## Bar\n",
    "\n",
    "Hi this is Jim\n",
    "\n",
    "Hi this is Joe\n",
    "\n",
    "## Baz\n",
    "\n",
    "Hi this is Molly\n",
    "\n",
    "--- \n",
    "\n",
    "We expect: \n",
    "\n",
    "```\n",
    "[(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"\\n\", None)]\n",
    "{\"content\": \"Hi this is Jim\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Joe\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Molly\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Baz\"}},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9cffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a886ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "class MarkdownHeaderTextSplitter():\n",
    "    \n",
    "    def __init__(self, splits: List[Tuple[str, Optional[str]]]):\n",
    "        \n",
    "        # Sort by seperator length and the number of \"#\"\n",
    "        # E.g.,  Ensure \"###\" will come before \"##\" and \"#\"\n",
    "        # TODO: Both means of sorting may not be required \n",
    "        self.splits = sorted(splits, key=lambda x: (-len(x[0]), -x[0].count('#')))\n",
    "\n",
    "    def split_text(self, text: str) -> List[Dict[str, Union[str, str]]]:\n",
    "        \n",
    "        # Regex matches any of the separators in self.splits (except for the newline)\n",
    "        # (Newlines create line breaks, which we may want to split, or separate MD headers and their contents)\n",
    "        pattern = '|'.join('(%s\\\\s*(.*))' % re.escape(sep) for sep, _ in self.splits if sep != \"\\n\")\n",
    "        \n",
    "        # Text chunk with metadata\n",
    "        chunks = []\n",
    "        \n",
    "        # Keys are names of metadata \n",
    "        #current_metadata = {name: '' for sep, name in self.splits if name is not None}\n",
    "        current_metadata = {name: '' for sep, name in self.splits if name}\n",
    "        current_content = []\n",
    "        \n",
    "        # Split by newlines, but preserve the exact formatting of the original text\n",
    "        for line in text.splitlines(keepends=True):\n",
    "            \n",
    "            # Removes any leading or trailing whitespace\n",
    "            stripped_line = line.strip()  \n",
    "            \n",
    "            # Match current line of text against the regular expression pattern\n",
    "            match = re.match(pattern, stripped_line)\n",
    "            \n",
    "            # If the line starts w/ a separator defined in splits (like \"#\" or \"##\"), it will be a match\n",
    "            # Start of a new chunk of content\n",
    "            if match:\n",
    "                \n",
    "                # See if we have accumulated content from previous lines \n",
    "                if current_content:  \n",
    "                    \n",
    "                    # If so, append it as a chunk and write the chunk since we hit a new seperator\n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(), \n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    # Reset the content  \n",
    "                    current_content = []  \n",
    "                    \n",
    "                # Check for the seperator\n",
    "                for sep, name in self.splits:\n",
    "                    if stripped_line.startswith(sep):\n",
    "                        if name is not None:\n",
    "                            # Update the rest of the line (after the separator) as the value for that header\n",
    "                            current_metadata[name] = stripped_line[len(sep):].strip()\n",
    "                            \n",
    "                            # If the separator is \"#\", it also clears out the metadata for \"Header 2\"\n",
    "                            # A new \"Header 1\" implies a new section of the document\n",
    "                            # TODO: This is brittle since there can be many header names\n",
    "                            #if sep == \"#\":\n",
    "                            #    current_metadata[\"Header 2\"] = ''   \n",
    "                            if sep == \"#\":\n",
    "                                # clear out metadata for all headers lower in hierarchy\n",
    "                                current_header_index = [index for index, (sep_, _) in enumerate(self.splits) if sep_ == sep][0]\n",
    "                                current_metadata_keys = list(current_metadata.keys())\n",
    "                                for header in current_metadata_keys:\n",
    "                                    header_index = [index for index, (_, name) in enumerate(self.splits) if name == header]\n",
    "                                    if header_index and header_index[0] > current_header_index:\n",
    "                                        del current_metadata[header]\n",
    "                        break\n",
    "            \n",
    "            # If the line is empty (i.e., only contains whitespace, or is completely empty) \n",
    "            # and newline (\"\\n\") is one of the separators, it appends the current content to \n",
    "            # the chunks list as a new chunk, and resets the current_content to an empty list  \n",
    "            elif not stripped_line and (\"\\n\", None) in self.splits:  \n",
    "                \n",
    "                # If we have accumulated content, append it as a chunk\n",
    "                if current_content:  \n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(), \n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    current_content = []  # reset the content\n",
    "            \n",
    "            # Apend non-empty lines\n",
    "            elif stripped_line:  \n",
    "                current_content.append(stripped_line)\n",
    "        \n",
    "        # Append the last chunk\n",
    "        if current_content:\n",
    "            chunks.append({\n",
    "                'content': ''.join(current_content).strip(), \n",
    "                'metadata': dict(current_metadata)\n",
    "            })\n",
    "        return [chunk for chunk in chunks if chunk['content']]\n",
    "\n",
    "# Doc\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "# Test case 1\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081361fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is JimHi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Test case 2\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636d0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Lance', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Three levels\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly'\n",
    "\n",
    "# Test case 3\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "\n",
    "# TODO: Reset header 3 Boo as empty\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a55162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
