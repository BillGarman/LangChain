{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e9b619",
   "metadata": {},
   "source": [
    "# MarkdownHeaderTextSplitter\n",
    "\n",
    "The objective is to split a markdown file by aribrary delimiters.\n",
    "\n",
    "Each text split is associated with its associated delimiters as metadata.\n",
    " \n",
    "**Given this example:**\n",
    "\n",
    "# Foo\n",
    "\n",
    "## Bar\n",
    "\n",
    "Hi this is Jim\n",
    "\n",
    "Hi this is Joe\n",
    "\n",
    "## Baz\n",
    "\n",
    "Hi this is Molly\n",
    "\n",
    "**And these delimiters:**\n",
    "\n",
    "```\n",
    "[(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"\\n\", None)]\n",
    "```\n",
    "\n",
    "**We expect:** \n",
    "\n",
    "```\n",
    "{\"content\": \"Hi this is Jim\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Joe\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Molly\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Baz\"}},\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa9012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41722f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Doc\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "# Test case 1\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"content\": \"Hi this is Jim\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Joe\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Bar\"}},\n",
    "{\"content\": \"Hi this is Molly\", metadata={\"Header 1\": \"Foo\", \"Header 2\": \"Baz\"}},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c3ded",
   "metadata": {},
   "source": [
    "`Test case 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47fd042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'This is an introductory paragraph.', 'metadata': {'Header 2': 'Overview', 'Header 1': 'Introduction'}}\n",
      "{'content': 'This is a detailed paragraph.', 'metadata': {'Header 2': 'Details', 'Header 1': 'Introduction'}}\n",
      "{'content': 'This is the conclusion.', 'metadata': {'Header 2': 'Details', 'Header 1': 'Conclusion'}}\n"
     ]
    }
   ],
   "source": [
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "markdown_document = '# Introduction\\n\\n## Overview\\n\\nThis is an introductory paragraph.\\\n",
    "\\n\\n## Details\\n\\nThis is a detailed paragraph.\\n\\n# Conclusion\\n\\nThis is the conclusion.'\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected\n",
    "{'content': 'This is an introductory paragraph.', 'metadata': {'Header 2': 'Overview', 'Header 1': 'Introduction'}}\n",
    "{'content': 'This is a detailed paragraph.', 'metadata': {'Header 2': 'Details', 'Header 1': 'Introduction'}}\n",
    "{'content': 'This is the conclusion.', 'metadata': {'Header 1': 'Conclusion'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c295fe76",
   "metadata": {},
   "source": [
    "`Test case 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca1f09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Text under H3.', 'metadata': {'Header 3': 'H3', 'Header 2': 'H2', 'Header 1': 'H1'}}\n",
      "{'content': 'Text under H2_2.', 'metadata': {'Header 3': 'H3', 'Header 2': 'H2_2', 'Header 1': 'H1_2'}}\n"
     ]
    }
   ],
   "source": [
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "markdown_document = '# H1\\n\\n## H2\\n\\n### H3\\n\\nText under H3.\\n\\n# H1_2\\n\\n## H2_2\\n\\nText under H2_2.'\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbbfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'content': 'Text under H3.', 'metadata': {'Header 3': 'H3', 'Header 2': 'H2', 'Header 1': 'H1'}}\n",
    "{'content': 'Text under H2_2.', 'metadata': {'Header 2': 'H2_2', 'Header 1': 'H1_2'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56744b6",
   "metadata": {},
   "source": [
    "`Test case 4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9484a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Paragraph under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
      "{'content': 'Paragraph 2 under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
      "{'content': 'Paragraph under new Heading 1.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'New Heading 1'}}\n"
     ]
    }
   ],
   "source": [
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "markdown_document = '# Heading 1\\n\\n## Heading 2\\n\\nParagraph under Heading 2.\\\n",
    "\\n\\nParagraph 2 under Heading 2.\\n\\n# New Heading 1\\n\\nParagraph under new Heading 1.'\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'content': 'Paragraph under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
    "{'content': 'Paragraph 2 under Heading 2.', 'metadata': {'Header 2': 'Heading 2', 'Header 1': 'Heading 1'}}\n",
    "{'content': 'Paragraph under new Heading 1.', 'metadata': {'Header 1': 'New Heading 1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8fef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c93e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2d238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c15f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19abdaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Hi this is Jim',\n",
       "  'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}},\n",
       " {'content': 'Hi this is Joe',\n",
       "  'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}},\n",
       " {'content': 'Hi this is Molly',\n",
       "  'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081361fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is JimHi this is Joe', 'metadata': {'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Test case 2\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636d0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Hi this is Jim', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Joe', 'metadata': {'Header 3': '', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Lance', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Bar', 'Header 1': 'Foo'}}\n",
      "{'content': 'Hi this is Molly', 'metadata': {'Header 3': 'Boo', 'Header 2': 'Baz', 'Header 1': 'Foo'}}\n"
     ]
    }
   ],
   "source": [
    "# Three levels\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly'\n",
    "\n",
    "# Test case 3\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    "\n",
    "# TODO: Reset header 3 Boo as empty\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961e316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37165da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9040b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c820f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a55162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from typing import Dict, Any, List, Optional, Tuple, Union\n",
    "\n",
    "class MarkdownHeaderTextSplitter(TextSplitter):\n",
    "    \n",
    "    def __init__(self, splits: List[Tuple[str, Optional[str]]], **kwargs: Any):\n",
    "        \n",
    "        # Sort by seperator length and the number of \"#\"\n",
    "        # E.g.,  Ensure \"###\" will come before \"##\" and \"#\"\n",
    "        # TODO: Both means of sorting may not be required \n",
    "        \"\"\"Create a new TextSplitter.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.splits = sorted(splits, key=lambda x: (-len(x[0]), -x[0].count('#')))\n",
    "\n",
    "    def split_text(self, text: str) -> List[Dict[str, Union[str, str]]]:\n",
    "        \n",
    "        # Regex matches any of the separators in self.splits (except for the newline)\n",
    "        # (Newlines create line breaks, which we may want to split, or separate MD headers and their contents)\n",
    "        pattern = '|'.join('(%s\\\\s*(.*))' % re.escape(sep) for sep, _ in self.splits if sep != \"\\n\")\n",
    "        \n",
    "        # Text chunk with metadata\n",
    "        chunks = []\n",
    "        \n",
    "        # Keys are names of metadata \n",
    "        #current_metadata = {name: '' for sep, name in self.splits if name is not None}\n",
    "        current_metadata = {name: '' for sep, name in self.splits if name}\n",
    "        current_content = []\n",
    "        \n",
    "        # Split by newlines, but preserve the exact formatting of the original text\n",
    "        for line in text.splitlines(keepends=True):\n",
    "            \n",
    "            # Removes any leading or trailing whitespace\n",
    "            stripped_line = line.strip()  \n",
    "            \n",
    "            # Match current line of text against the regular expression pattern\n",
    "            match = re.match(pattern, stripped_line)\n",
    "            \n",
    "            # If the line starts w/ a separator defined in splits (like \"#\" or \"##\"), it will be a match\n",
    "            # Start of a new chunk of content\n",
    "            if match:\n",
    "                \n",
    "                # See if we have accumulated content from previous lines \n",
    "                if current_content:  \n",
    "                    \n",
    "                    # If so, append it as a chunk and write the chunk since we hit a new seperator\n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(), \n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    # Reset the content  \n",
    "                    current_content = []  \n",
    "                    \n",
    "                # Check for the seperator\n",
    "                for sep, name in self.splits:\n",
    "                    if stripped_line.startswith(sep):\n",
    "                        if name is not None:\n",
    "                            # Update the rest of the line (after the separator) as the value for that header\n",
    "                            current_metadata[name] = stripped_line[len(sep):].strip()\n",
    "                            \n",
    "                            # If the separator is \"#\", it also clears out the metadata for \"Header 2\"\n",
    "                            # A new \"Header 1\" implies a new section of the document\n",
    "                            # TODO: This is brittle since there can be many header names\n",
    "                            #if sep == \"#\":\n",
    "                            #    current_metadata[\"Header 2\"] = ''   \n",
    "                            ''' '''\n",
    "                            if sep == \"#\":\n",
    "                                # clear out metadata for all headers lower in hierarchy\n",
    "                                current_header_index = [index for index, (sep_, _) in enumerate(self.splits) if sep_ == sep][0]\n",
    "                                current_metadata_keys = list(current_metadata.keys())\n",
    "                                for header in current_metadata_keys:\n",
    "                                    header_index = [index for index, (_, name) in enumerate(self.splits) if name == header]\n",
    "                                    if header_index and header_index[0] > current_header_index:\n",
    "                                        del current_metadata[header]\n",
    "                                        \n",
    "                            if sep == \"#\":\n",
    "                            # clear out metadata for all headers lower in hierarchy\n",
    "                            current_metadata_keys = list(current_metadata.keys())\n",
    "                            for header in current_metadata_keys:\n",
    "                                header_index = [index for index, (_, name) in enumerate(self.splits) if name == header]\n",
    "                                if header_index and header_index[0] > 0: # All headers with index higher than 0 are lower in hierarchy than '#'\n",
    "                                    del current_metadata[header]\n",
    "\n",
    "                        break\n",
    "            \n",
    "            # If the line is empty (i.e., only contains whitespace, or is completely empty) \n",
    "            # and newline (\"\\n\") is one of the separators, it appends the current content to \n",
    "            # the chunks list as a new chunk, and resets the current_content to an empty list  \n",
    "            elif not stripped_line and (\"\\n\", None) in self.splits:  \n",
    "                \n",
    "                # If we have accumulated content, append it as a chunk\n",
    "                if current_content:  \n",
    "                    chunks.append({\n",
    "                        'content': ''.join(current_content).strip(), \n",
    "                        'metadata': dict(current_metadata)\n",
    "                    })\n",
    "                    current_content = []  # reset the content\n",
    "            \n",
    "            # Apend non-empty lines\n",
    "            elif stripped_line:  \n",
    "                current_content.append(stripped_line)\n",
    "        \n",
    "        # Append the last chunk\n",
    "        if current_content:\n",
    "            chunks.append({\n",
    "                'content': ''.join(current_content).strip(), \n",
    "                'metadata': dict(current_metadata)\n",
    "            })\n",
    "        return [chunk for chunk in chunks if chunk['content']]\n",
    "\n",
    "# Doc\n",
    "markdown_document = '# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ## Baz\\n\\n Hi this is Molly' \n",
    "    \n",
    "# Test case 1\n",
    "splits = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"\\n\", None)\n",
    "]\n",
    " \n",
    "markdown_splitter = MarkdownHeaderTextSplitter(splits=splits)\n",
    "chunked_docs = markdown_splitter.split_text(markdown_document)\n",
    "for chunk in chunked_docs:\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
