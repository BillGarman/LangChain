{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2326605c",
   "metadata": {},
   "source": [
    "# Embeddings Caching\n",
    "\n",
    "This notebook goes over how to cache embeddings using the Embeddings class in LangChain.\n",
    "\n",
    "The BaseEmbeddingsCache class is an interface for a cache that stores embeddings for given text. An embeddings cache can be provided as an optional argument when constructing an Embeddings class.\n",
    "\n",
    "The BaseEmbeddingsCache class in LangChain exposes two methods: `lookup` and `update`. These are analogous to the methods of the  LLMCache, except that the key only consists of the SHA256 hash of the provided text and does not include the model name. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5072bea",
   "metadata": {},
   "source": [
    "## InMemoryEmbeddingsCache\n",
    "\n",
    "Let's look at a basic example of using the InMemoryEmbeddingsCache with the OpenAI Embeddings class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433223e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e31cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryEmbeddingsCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d7bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = InMemoryEmbeddingsCache()\n",
    "embeddings = OpenAIEmbeddings(embeddings_cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4147fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9fa1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.07 ms, sys: 5.3 ms, total: 8.37 ms\n",
      "Wall time: 295 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2cfa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.01273756567388773, -0.018157944083213806, 0.009503343142569065, -0.04341445863246918, -0.03418117016553879...'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(query_result[:5])[:-1] + '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107c2aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 9 µs, total: 9 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The second time it is, so it goes faster\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "333bb33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.01273756567388773, -0.018157944083213806, 0.009503343142569065, -0.04341445863246918, -0.03418117016553879...'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(query_result[:5])[:-1] + '...'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4397d2",
   "metadata": {},
   "source": [
    "## RedisEmbeddingsCache\n",
    "\n",
    "Let's look another example of using the RedisEmbeddingsCache with the OpenAI Embeddings class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57f030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same thing with a Redis cache\n",
    "# (make sure your local Redis instance is running first before running this example)\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from redis import Redis\n",
    "from langchain.cache import RedisEmbeddingsCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88ac388",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = RedisEmbeddingsCache(redis_=Redis())\n",
    "embeddings = OpenAIEmbeddings(embeddings_cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffcbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3db1609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 ms, sys: 669 µs, total: 41.7 ms\n",
      "Wall time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "query_result = embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ad6cc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.012754085473716259, -0.018176019191741943, 0.009512502700090408, -0.04345264658331871, -0.034216709434986115...'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(query_result[:5])[:-1] + '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be1053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 297 µs, sys: 0 ns, total: 297 µs\n",
      "Wall time: 271 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The second time it is, so it goes faster\n",
    "query_result = embeddings.embed_query(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
