{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL Flexible Agent, going beyond SQL queries\n",
    "The classical ZeroShotAgent always forces to use a tool which makes sense when the tool can finish the work better than AI, however, there are many cases, AI is better than tools, esp. when generation is needed.\n",
    "\n",
    "One example, when user uses Spark, sometimes, we want the model to give us suggestions of how to write some queries to assist our work instead of doing the query for us directly. (Letting the AI doing the query is a valid case but it's not the only case) The power of LLM is generation. It's able to provide more creative and complex answer, which includes providing suggestions to human.\n",
    "\n",
    "In this notebook, we present how to enable AI's creativity in the classical MRKL framework through a freestyle tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/14 10:02:38 WARN Utils: Your hostname, Mikes-Mac-mini.local resolves to a loopback address: 127.0.0.1; using 192.168.68.115 instead (on interface en1)\n",
      "23/05/14 10:02:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/14 10:02:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/14 10:02:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "schema = \"langchain_example\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {schema}\")\n",
    "spark.sql(f\"USE {schema}\")\n",
    "csv_file_path = \"../toolkits/examples/titanic.csv\"\n",
    "table = \"titanic\"\n",
    "spark.read.csv(csv_file_path, header=True, inferSchema=True).write.mode('overwrite').saveAsTable(table)\n",
    "spark.table(table).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_spark_sql_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.spark_sql import SparkSQL\n",
    "\n",
    "spark_sql = SparkSQL(schema=schema)\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4\")\n",
    "agent_executor = create_spark_sql_agent(\n",
    "    db=spark_sql,\n",
    "    llm=llm,\n",
    "    enable_memory=True,\n",
    "    enable_freestyle=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: list_tables_sql_db\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mtitanic\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to see the schema of the titanic table to understand the columns and data.\n",
      "Action: schema_sql_db\n",
      "Action Input: titanic\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mCREATE TABLE langchain_example.titanic (\n",
      "  PassengerId INT,\n",
      "  Survived INT,\n",
      "  Pclass INT,\n",
      "  Name STRING,\n",
      "  Sex STRING,\n",
      "  Age DOUBLE,\n",
      "  SibSp INT,\n",
      "  Parch INT,\n",
      "  Ticket STRING,\n",
      "  Fare DOUBLE,\n",
      "  Cabin STRING,\n",
      "  Embarked STRING)\n",
      ";\n",
      "\n",
      "/*\n",
      "3 rows from titanic table:\n",
      "PassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
      "1\t0\t3\tBraund, Mr. Owen Harris\tmale\t22.0\t1\t0\tA/5 21171\t7.25\tNone\tS\n",
      "2\t1\t1\tCumings, Mrs. John Bradley (Florence Briggs Thayer)\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
      "3\t1\t3\tHeikkinen, Miss. Laina\tfemale\t26.0\t0\t0\tSTON/O2. 3101282\t7.925\tNone\tS\n",
      "*/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the most expensive class, which is related to the Fare column. I will write two different queries to find the most expensive class.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAI is allowed to generate the answer when it has the confidence.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have confidence in writing two different queries to find the most expensive class.\n",
      "Action: free_style\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAI is allowed to generate the answer when it has the confidence.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Here are two different ways to query the most expensive class:\n",
      "\n",
      "1. SELECT Pclass, MAX(Fare) as Max_Fare FROM titanic GROUP BY Pclass ORDER BY Max_Fare DESC LIMIT 1;\n",
      "\n",
      "2. SELECT Pclass, Fare FROM titanic WHERE Fare = (SELECT MAX(Fare) FROM titanic) LIMIT 1;\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are two different ways to query the most expensive class:\\n\\n1. SELECT Pclass, MAX(Fare) as Max_Fare FROM titanic GROUP BY Pclass ORDER BY Max_Fare DESC LIMIT 1;\\n\\n2. SELECT Pclass, Fare FROM titanic WHERE Fare = (SELECT MAX(Fare) FROM titanic) LIMIT 1;'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"give me two different ways to query the most expensive class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: list_tables_sql_db\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mtitanic\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should check the schema of the titanic table to see if the columns I used in the queries are correct.\n",
      "Action: schema_sql_db\n",
      "Action Input: titanic\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mCREATE TABLE langchain_example.titanic (\n",
      "  PassengerId INT,\n",
      "  Survived INT,\n",
      "  Pclass INT,\n",
      "  Name STRING,\n",
      "  Sex STRING,\n",
      "  Age DOUBLE,\n",
      "  SibSp INT,\n",
      "  Parch INT,\n",
      "  Ticket STRING,\n",
      "  Fare DOUBLE,\n",
      "  Cabin STRING,\n",
      "  Embarked STRING)\n",
      ";\n",
      "\n",
      "/*\n",
      "3 rows from titanic table:\n",
      "PassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
      "1\t0\t3\tBraund, Mr. Owen Harris\tmale\t22.0\t1\t0\tA/5 21171\t7.25\tNone\tS\n",
      "2\t1\t1\tCumings, Mrs. John Bradley (Florence Briggs Thayer)\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
      "3\t1\t3\tHeikkinen, Miss. Laina\tfemale\t26.0\t0\t0\tSTON/O2. 3101282\t7.925\tNone\tS\n",
      "*/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe schema of the titanic table matches the columns I used in the queries. Now I should check if the queries are correct.\n",
      "Action: query_checker_sql_db\n",
      "Action Input: SELECT Pclass, MAX(Fare) as Max_Fare FROM titanic GROUP BY Pclass ORDER BY Max_Fare DESC LIMIT 1;\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe original query seems to be correct. There are no common mistakes present. Here's the original query again:\n",
      "\n",
      "SELECT Pclass, MAX(Fare) as Max_Fare FROM titanic GROUP BY Pclass ORDER BY Max_Fare DESC LIMIT 1;\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe first query is correct. Now I should check the second query.\n",
      "Action: query_checker_sql_db\n",
      "Action Input: SELECT Pclass, Fare FROM titanic WHERE Fare = (SELECT MAX(Fare) FROM titanic) LIMIT 1;\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe original query seems to be correct. There are no common mistakes present. Here's the original query again:\n",
      "\n",
      "SELECT Pclass, Fare FROM titanic WHERE Fare = (SELECT MAX(Fare) FROM titanic) LIMIT 1;\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Yes, both queries are accurate.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, both queries are accurate.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"are they accurate?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: list_tables_sql_db\n",
      "Action Input: \u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mtitanic\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI know the table I need to query is the titanic table. I will modify the second query to find the second most expensive class.\n",
      "Action: query_checker_sql_db\n",
      "Action Input: SELECT Pclass, Fare FROM titanic WHERE Fare = (SELECT DISTINCT Fare FROM titanic ORDER BY Fare DESC LIMIT 1 OFFSET 1) LIMIT 1;\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe original query seems to be correct. It is trying to find the second highest fare and its corresponding Pclass from the titanic dataset. Here's the query again:\n",
      "\n",
      "SELECT Pclass, Fare FROM titanic WHERE Fare = (SELECT DISTINCT Fare FROM titanic ORDER BY Fare DESC LIMIT 1 OFFSET 1) LIMIT 1;\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe query is correct, so I will execute it to find the second most expensive class.\n",
      "Action: query_sql_db\n",
      "Action Input: SELECT Pclass, Fare FROM titanic WHERE Fare = (SELECT DISTINCT Fare FROM titanic ORDER BY Fare DESC LIMIT 1 OFFSET 1) LIMIT 1;\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[('1', '263.0')]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The second most expensive class is class 1 with a fare of 263.0.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The second most expensive class is class 1 with a fare of 263.0.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"cool, then let's use the second solution and query the second most expensive\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Logical, Physical Plans\n",
    "In the example below, we will show how AI uses Logical and Physical plan to further explain the executed query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "schema = \"langchain_example\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {schema}\")\n",
    "spark.sql(f\"USE {schema}\")\n",
    "csv_file_path = \"../toolkits/examples/titanic.csv\"\n",
    "table = \"titanic\"\n",
    "spark.read.csv(csv_file_path, header=True, inferSchema=True).write.mode('overwrite').saveAsTable(table)\n",
    "spark.table(table).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_spark_sql_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.spark_sql import SparkSQL\n",
    "\n",
    "spark_sql = SparkSQL(schema=schema)\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4\")\n",
    "agent_executor = create_spark_sql_agent(\n",
    "    db=spark_sql,\n",
    "    llm=llm,\n",
    "    enable_memory=True,\n",
    "    enable_freestyle=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: list_tables_sql_db\n",
      "Action Input: \"\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mtitanic\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should check the schema of the titanic table to understand the columns and their data types.\n",
      "Action: schema_sql_db\n",
      "Action Input: \"titanic\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mCREATE TABLE langchain_example.titanic (\n",
      "  PassengerId INT,\n",
      "  Survived INT,\n",
      "  Pclass INT,\n",
      "  Name STRING,\n",
      "  Sex STRING,\n",
      "  Age DOUBLE,\n",
      "  SibSp INT,\n",
      "  Parch INT,\n",
      "  Ticket STRING,\n",
      "  Fare DOUBLE,\n",
      "  Cabin STRING,\n",
      "  Embarked STRING)\n",
      ";\n",
      "\n",
      "/*\n",
      "3 rows from titanic table:\n",
      "PassengerId\tSurvived\tPclass\tName\tSex\tAge\tSibSp\tParch\tTicket\tFare\tCabin\tEmbarked\n",
      "1\t0\t3\tBraund, Mr. Owen Harris\tmale\t22.0\t1\t0\tA/5 21171\t7.25\tNone\tS\n",
      "2\t1\t1\tCumings, Mrs. John Bradley (Florence Briggs Thayer)\tfemale\t38.0\t1\t0\tPC 17599\t71.2833\tC85\tC\n",
      "3\t1\t3\tHeikkinen, Miss. Laina\tfemale\t26.0\t0\t0\tSTON/O2. 3101282\t7.925\tNone\tS\n",
      "*/\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I know the schema of the titanic table, I can write a query to find the number of tickets sold in the second most expensive class. I will first find the average fare for each class, then find the second most expensive class, and finally count the number of tickets sold in that class.\n",
      "Action: query_checker_sql_db\n",
      "Action Input: \"WITH class_fares AS (SELECT Pclass, AVG(Fare) as avg_fare FROM titanic GROUP BY Pclass ORDER BY avg_fare DESC) SELECT COUNT(*) FROM titanic WHERE Pclass = (SELECT Pclass FROM class_fares LIMIT 1 OFFSET 1)\"\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe original query seems to be correct. Here it is reproduced:\n",
      "\n",
      "WITH class_fares AS (SELECT Pclass, AVG(Fare) as avg_fare FROM titanic GROUP BY Pclass ORDER BY avg_fare DESC) SELECT COUNT(*) FROM titanic WHERE Pclass = (SELECT Pclass FROM class_fares LIMIT 1 OFFSET 1)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mSince the query is correct, I can now execute it to find the number of tickets sold in the second most expensive class.\n",
      "Action: query_sql_db\n",
      "Action Input: \"WITH class_fares AS (SELECT Pclass, AVG(Fare) as avg_fare FROM titanic GROUP BY Pclass ORDER BY avg_fare DESC) SELECT COUNT(*) FROM titanic WHERE Pclass = (SELECT Pclass FROM class_fares LIMIT 1 OFFSET 1)\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[('184',)]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: There were 184 tickets sold in the second most expensive class.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There were 184 tickets sold in the second most expensive class.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"how many tickets sold in the second most expensive class?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: list_tables_sql_db\n",
      "Action Input: \"\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mtitanic\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to find the second most expensive class and count the number of tickets sold in that class. I will write a query to achieve this and then get the logical and physical plans.\n",
      "Action: query_checker_sql_db\n",
      "Action Input: SELECT COUNT(*) FROM titanic WHERE Pclass = (SELECT Pclass FROM (SELECT Pclass, AVG(Fare) as avg_fare FROM titanic GROUP BY Pclass ORDER BY avg_fare DESC LIMIT 1 OFFSET 1) as second_most_expensive_class)\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe original query seems to be correct. Here it is reproduced:\n",
      "\n",
      "SELECT COUNT(*) FROM titanic WHERE Pclass = (SELECT Pclass FROM (SELECT Pclass, AVG(Fare) as avg_fare FROM titanic GROUP BY Pclass ORDER BY avg_fare DESC LIMIT 1 OFFSET 1) as second_most_expensive_class)\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the correct query, I will get the logical and physical plans for it.\n",
      "Action: get_logical_physical_plans_from_sql_db\n",
      "Action Input: SELECT COUNT(*) FROM titanic WHERE Pclass = (SELECT Pclass FROM (SELECT Pclass, AVG(Fare) as avg_fare FROM titanic GROUP BY Pclass ORDER BY avg_fare DESC LIMIT 1 OFFSET 1) as second_most_expensive_class)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('COUNT(1), None)]\n",
      "+- 'Filter ('Pclass = scalar-subquery#356 [])\n",
      "   :  +- 'Project ['Pclass]\n",
      "   :     +- 'SubqueryAlias second_most_expensive_class\n",
      "   :        +- 'GlobalLimit 1\n",
      "   :           +- 'LocalLimit 1\n",
      "   :              +- 'Offset 1\n",
      "   :                 +- 'Sort ['avg_fare DESC NULLS LAST], true\n",
      "   :                    +- 'Aggregate ['Pclass], ['Pclass, 'AVG('Fare) AS avg_fare#355]\n",
      "   :                       +- 'UnresolvedRelation [titanic], [], false\n",
      "   +- 'UnresolvedRelation [titanic], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "count(1): bigint\n",
      "Aggregate [count(1) AS count(1)#371L]\n",
      "+- Filter (Pclass#67 = scalar-subquery#356 [])\n",
      "   :  +- Project [Pclass#361]\n",
      "   :     +- SubqueryAlias second_most_expensive_class\n",
      "   :        +- GlobalLimit 1\n",
      "   :           +- LocalLimit 1\n",
      "   :              +- Offset 1\n",
      "   :                 +- Sort [avg_fare#355 DESC NULLS LAST], true\n",
      "   :                    +- Aggregate [Pclass#361], [Pclass#361, avg(Fare#368) AS avg_fare#355]\n",
      "   :                       +- SubqueryAlias spark_catalog.langchain_example.titanic\n",
      "   :                          +- Relation spark_catalog.langchain_example.titanic[PassengerId#359,Survived#360,Pclass#361,Name#362,Sex#363,Age#364,SibSp#365,Parch#366,Ticket#367,Fare#368,Cabin#369,Embarked#370] parquet\n",
      "   +- SubqueryAlias spark_catalog.langchain_example.titanic\n",
      "      +- Relation spark_catalog.langchain_example.titanic[PassengerId#65,Survived#66,Pclass#67,Name#68,Sex#69,Age#70,SibSp#71,Parch#72,Ticket#73,Fare#74,Cabin#75,Embarked#76] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [count(1) AS count(1)#371L]\n",
      "+- Project\n",
      "   +- Filter (isnotnull(Pclass#67) AND (Pclass#67 = scalar-subquery#356 []))\n",
      "      :  +- GlobalLimit 1\n",
      "      :     +- Offset 1\n",
      "      :        +- LocalLimit 2\n",
      "      :           +- Project [Pclass#361]\n",
      "      :              +- Sort [avg_fare#355 DESC NULLS LAST], true\n",
      "      :                 +- Aggregate [Pclass#361], [Pclass#361, avg(Fare#368) AS avg_fare#355]\n",
      "      :                    +- Project [Pclass#361, Fare#368]\n",
      "      :                       +- Relation spark_catalog.langchain_example.titanic[PassengerId#359,Survived#360,Pclass#361,Name#362,Sex#363,Age#364,SibSp#365,Parch#366,Ticket#367,Fare#368,Cabin#369,Embarked#370] parquet\n",
      "      +- Relation spark_catalog.langchain_example.titanic[PassengerId#65,Survived#66,Pclass#67,Name#68,Sex#69,Age#70,SibSp#71,Parch#72,Ticket#73,Fare#74,Cabin#75,Embarked#76] parquet\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[], functions=[count(1)], output=[count(1)#371L])\n",
      "   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=453]\n",
      "      +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#374L])\n",
      "         +- Project\n",
      "            +- Filter (isnotnull(Pclass#67) AND (Pclass#67 = Subquery subquery#356, [id=#447]))\n",
      "               :  +- Subquery subquery#356, [id=#447]\n",
      "               :     +- AdaptiveSparkPlan isFinalPlan=false\n",
      "               :        +- TakeOrderedAndProject(limit=2, orderBy=[avg_fare#355 DESC NULLS LAST], output=[Pclass#361])\n",
      "               :           +- HashAggregate(keys=[Pclass#361], functions=[avg(Fare#368)], output=[Pclass#361, avg_fare#355])\n",
      "               :              +- Exchange hashpartitioning(Pclass#361, 200), ENSURE_REQUIREMENTS, [plan_id=444]\n",
      "               :                 +- HashAggregate(keys=[Pclass#361], functions=[partial_avg(Fare#368)], output=[Pclass#361, sum#377, count#378L])\n",
      "               :                    +- FileScan parquet spark_catalog.langchain_example.titanic[Pclass#361,Fare#368] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/skcoirz/GitHub/LangChain/docs/modules/agents/agents/spark-..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Pclass:int,Fare:double>\n",
      "               +- FileScan parquet spark_catalog.langchain_example.titanic[Pclass#67] Batched: true, DataFilters: [isnotnull(Pclass#67)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/skcoirz/GitHub/LangChain/docs/modules/agents/agents/spark-..., PartitionFilters: [], PushedFilters: [IsNotNull(Pclass)], ReadSchema: struct<Pclass:int>\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The optimized logical plan for the query is as follows:\n",
      "\n",
      "1. The query starts with a scalar subquery to find the second most expensive class by calculating the average fare for each class and ordering them in descending order. The subquery is then used in the main query.\n",
      "2. The main query performs a Filter operation to remove any rows with null Pclass values and to keep only the rows where Pclass equals the second most expensive class.\n",
      "3. The Aggregate operation is used to count the number of rows in the result, which represents the number of tickets sold in the second most expensive class.\n",
      "\n",
      "The physical plan uses AdaptiveSparkPlan, HashAggregate, Exchange, and FileScan operations to execute the query efficiently.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The optimized logical plan for the query is as follows:\\n\\n1. The query starts with a scalar subquery to find the second most expensive class by calculating the average fare for each class and ordering them in descending order. The subquery is then used in the main query.\\n2. The main query performs a Filter operation to remove any rows with null Pclass values and to keep only the rows where Pclass equals the second most expensive class.\\n3. The Aggregate operation is used to count the number of rows in the result, which represents the number of tickets sold in the second most expensive class.\\n\\nThe physical plan uses AdaptiveSparkPlan, HashAggregate, Exchange, and FileScan operations to execute the query efficiently.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"how's it optimized by spark? explain the optimized logical plan to me.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
