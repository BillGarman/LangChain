{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841562af-b0da-4798-bed1-2975d565f560",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chat Message History\n",
    "\n",
    "In LangChain, `BaseChatMessageHistory` is the main interface for storing and accessing saved conversation data. \n",
    "\n",
    "In this section, we will talk about different types of chat message history available in LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3721c-6ebb-4c0d-a776-ff4d812b60e3",
   "metadata": {},
   "source": [
    "## ChatMessageHistory\n",
    "\n",
    "`ChatMessageHistory` is a simple object that stores the conversation data as a list of messaage objects **in memory**. Note that the conversation data will **not** be persisted, i.e. all data is gone when the program exits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc097b94-8c24-49d7-90c4-6d44a8b8f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0478220f-3319-4c34-8138-c71387895e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    memory=ConversationBufferMemory(chat_memory=history)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b6a85f-add5-46d1-9027-cb0e6d53ad9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765e8ca8-fd4b-49ad-b452-c467d39440f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello!', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Hello there! How can I assist you today?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0c82c-209f-4b75-9cd9-7c431ed27f40",
   "metadata": {},
   "source": [
    "## FileChatMessageHistory\n",
    "\n",
    "`FileChatMessageHistory` persists the data in the local filesystem as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38556547-949b-4b56-8406-9780bc0f2681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import FileChatMessageHistory\n",
    "\n",
    "history = FileChatMessageHistory(\"our_conversation.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfa6013-3fd9-46eb-88f3-19e78089a8e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    memory=ConversationBufferMemory(chat_memory=history)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b88426-efee-4239-b784-e566a0a62708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f0105d4-97eb-4374-a5f7-187e90010fff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"type\": \"human\", \"data\": {\"content\": \"Hello!\", \"additional_kwargs\": {}, \"example\": false}}, {\"type\": \"ai\", \"data\": {\"content\": \"Hello there! How can I assist you today?\", \"additional_kwargs\": {}, \"example\": false}}]"
     ]
    }
   ],
   "source": [
    "!cat our_conversation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc98ca0-1f3b-45fe-b20e-da69d8a98718",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Database-backed chat message history\n",
    "\n",
    "LangChain supports storing chat history in different type of database. Below are some examples:\n",
    "\n",
    "- Redis using `RedisChatMessageHistory`.\n",
    "- Postgres using `PostgresChatMessageHistory`.\n",
    "- DynamoDB using `DynamoDBChatMessageHistory`.\n",
    "- Azure CosmosDB using `CosmosDBChatMessageHistory`.\n",
    "\n",
    "You can find a full list of supported database [here](../how_to_guides.rst)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
