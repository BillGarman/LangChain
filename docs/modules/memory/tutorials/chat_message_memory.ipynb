{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4cdc23a-2c3f-474d-984e-4f5d6fc82e0c",
   "metadata": {},
   "source": [
    "# Chat Message Memory\n",
    "\n",
    "Chat Message Memory specializes in storing conversation history between human and an LLM model. \n",
    "\n",
    "In LangChain, chat message memory is composed of two main parts, the memory class itself and the `BaseChatMessageHistory` object it is wrapping on. `BaseChatMessageHistory` object defines how conversation history data is serialized and persisted, such as through a local file system or external database. The memory class controls how the chat message memory is presented to the LLM model in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003b1f86-c0ea-40bb-9841-216e470e40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to show initialization and explicitly show which part is which part.\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory, ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "# ConversationBufferMemory is a chat message memory object.\n",
    "chat_memory = ConversationBufferMemory(\n",
    "    chat_memory=chat_history # <-- This is the `BaseChatMessageHistory` object\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da1e6086-7294-42cb-970d-147de0114713",
   "metadata": {
    "tags": []
   },
   "source": [
    "If you do not explicitly define a `BaseChatMessageHistory` object in `chat_memory` argument during initialization, chat message memory will use a default message storage option, which is `ChatMessageHistory`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18a3a41b-7698-4804-be42-19669c4735c1",
   "metadata": {},
   "source": [
    "## Type of chat memory\n",
    "\n",
    "In this section, we will show some examples of memory classes available in LangChain. You can learn more about various types of `BaseChatMessageHistory` in another notebook [here](./chat_message_history.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db296668-c9d3-4755-90ab-43d8689e134a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ConversationBufferMemory\n",
    "\n",
    "We first start with `ConversationBufferMemory` which is just a simple wrapper around the underlying `BaseChatMessageHistory` that return the messages stored in it without any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a3984f-e1a8-434e-b51f-2e39e6a91e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We create a chat message history that stores some dummy conversation.\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "chat_history.add_user_message(\"Hello!\")\n",
    "chat_history.add_ai_message(\"Hey there, how may I assist you today?\")\n",
    "chat_history.add_user_message(\"Answer briefly. What are the first 3 colors of a rainbow?\")\n",
    "chat_history.add_ai_message(\"The first three colors of a rainbow are red, orange, and yellow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b176c10-eaff-4540-ac93-a76d15aefb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "memory = ConversationBufferMemory(chat_memory=chat_history)\n",
    "chat_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54804ec2-e8f4-408f-b370-153d4317749f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello!\n",
      "AI: Hey there, how may I assist you today?\n",
      "Human: Answer briefly. What are the first 3 colors of a rainbow?\n",
      "AI: The first three colors of a rainbow are red, orange, and yellow.\n",
      "Human: And the next 4?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The next four colors of a rainbow are green, blue, indigo, and violet.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"And the next 4?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df32c158-fb0e-4efb-b4b2-e7071698b39f",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory\n",
    "\n",
    "While `ConversationBufferMemory` is the most accurate way to incorporate information about previous conversations when querying an LLM, it is certainly not the most efficient way, especially when the model context length is low. Besides, when it holds conversation data longer than the context length supported by the LLM model, unexpected behaviors may occur during the LLM output generation process.\n",
    "\n",
    "`ConversationBufferWindowMemory` mitigates the problem by returning only the last K interactions. In other words, it keeps a sliding window of the most recent interactions to minimize the chance the returned messages will exceed the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74e24ab-aed4-4325-a0d3-028f37bd3bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, chat_memory=chat_history) # Only incorporate the last 2 interactions\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd97103-ab8f-41f4-b435-ccb7fc3254a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Answer briefly. What are the first 3 colors of a rainbow?\n",
      "AI: The first three colors of a rainbow are red, orange, and yellow.\n",
      "Human: And the next 4?\n",
      "AI: The next four colors of a rainbow are green, blue, indigo, and violet.\n",
      "Human: That's interesting? Why do rainbows have so many colors?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Rainbows have so many colors because they are caused by the refraction and reflection of sunlight through water droplets in the air. This process separates the different wavelengths of light, creating the spectrum of colors we see in a rainbow.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"That's interesting? Why do rainbows have so many colors?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ee8490c-c1f4-47db-aa49-6e9b362ed58a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ConversationSummaryMemory\n",
    "\n",
    "`ConversationSummaryMemory` adopts a different approach. Instead of outputing previous conversation verbatim, it generates a summary of previous conversation. This allows us to incorporate more information from previous interactions, at the expense of detailness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c988561-9dc6-4d6a-a480-b69e3127bb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    chat_memory=chat_history, \n",
    "    llm=ChatOpenAI(temperature=0) # <-- You need an LLM to summarize the conversation.\n",
    ")\n",
    "conversation = ConversationChain(\n",
    "    llm=chat_model,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b5a11f-30d6-48be-b433-1efa3b828084",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "The human greets the AI and asks it to name the first three colors of a rainbow. The AI responds with \"red, orange, and yellow\" and when asked for the next four, it says \"green, blue, indigo, and violet.\" The human asks why rainbows have so many colors, and the AI explains that it's due to the refraction and reflection of sunlight through water droplets in the air, which separates the different wavelengths of light and creates the spectrum of colors we see in a rainbow.\n",
      "Human: It is so hard to remember the order of the colors!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, it can be difficult to remember the order of the colors in a rainbow. One way to remember is to use the acronym ROYGBIV, which stands for red, orange, yellow, green, blue, indigo, and violet.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"It is so hard to remember the order of the colors!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbebca73-7210-4c1a-be76-2560fa632100",
   "metadata": {},
   "source": [
    "These are just a handful of chat message memories available in LangChain. You can go [here]() to see the full list of memory classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9376a14d-5256-47f0-b303-a4c54e8132fa",
   "metadata": {},
   "source": [
    "## Output type\n",
    "\n",
    "By default, chat message memory classes in LangChain will return string when accessed using `load_memory_variables`. Most memory class (with the exception of `ConversationStringBufferHistory`) exposes the `return_messages` boolean field during initialization, which when set to `True`, return a list of messages objects instead of string. This can be helpful when you are using `MessagePlaceholder` (see [Chat Prompt Template](../../prompts/chat_prompt_template.ipynb) if you are unsure what it is) instead of prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f91e4881-93df-4a99-89ba-16bb4dee1a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    chat_memory=chat_history,\n",
    "    k=3,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba45eb1e-def4-4be0-8159-c31e03930147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='And the next 4?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The next four colors of a rainbow are green, blue, indigo, and violet.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content=\"That's interesting? Why do rainbows have so many colors?\", additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Rainbows have so many colors because they are caused by the refraction and reflection of sunlight through water droplets in the air. This process separates the different wavelengths of light, creating the spectrum of colors we see in a rainbow.', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='It is so hard to remember the order of the colors!', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='Yes, it can be difficult to remember the order of the colors in a rainbow. One way to remember is to use the acronym ROYGBIV, which stands for red, orange, yellow, green, blue, indigo, and violet.', additional_kwargs={}, example=False)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71b926e0-047a-42d5-9456-1e2076bc2723",
   "metadata": {},
   "source": [
    "## String output customization\n",
    "\n",
    "When formatted as a string, you can customize the name of the entity using `human_prefix` and `ai_prefix`. This setting has no effect when the output is a message object (i.e. when `return_messages` is `True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d35cc0-5e58-4a97-951d-eae111d61cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    chat_memory=chat_history,\n",
    "    k=3,\n",
    "    human_prefix=\"Learner\",\n",
    "    ai_prefix=\"Teacher\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24a88bb-5ee8-4115-9118-d7005bbb02a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner: And the next 4?\n",
      "Teacher: The next four colors of a rainbow are green, blue, indigo, and violet.\n",
      "Learner: That's interesting? Why do rainbows have so many colors?\n",
      "Teacher: Rainbows have so many colors because they are caused by the refraction and reflection of sunlight through water droplets in the air. This process separates the different wavelengths of light, creating the spectrum of colors we see in a rainbow.\n",
      "Learner: It is so hard to remember the order of the colors!\n",
      "Teacher: Yes, it can be difficult to remember the order of the colors in a rainbow. One way to remember is to use the acronym ROYGBIV, which stands for red, orange, yellow, green, blue, indigo, and violet.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
