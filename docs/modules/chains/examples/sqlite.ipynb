{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed6aab1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SQL Chain example\n",
    "\n",
    "This example demonstrates the use of the `SQLDatabaseChain` for answering questions over a database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f66479",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Under the hood, LangChain uses SQLAlchemy to connect to SQL databases. The `SQLDatabaseChain` can therefore be used with any SQL dialect supported by SQLAlchemy, such as MS SQL, MySQL, MariaDB, PostgreSQL, Oracle SQL, and SQLite. Please refer to the SQLAlchemy documentation for more information about requirements for connecting to your database. For example, a connection to MySQL requires an appropriate connector such as PyMySQL. A URI for a MySQL connection might look like: `mysql+pymysql://user:pass@some_mysql_db_address/db_name`\n",
    "\n",
    "This demonstration uses SQLite and the example Chinook database.\n",
    "To set it up, follow the instructions on https://database.guide/2-sample-databases-sqlite/, placing the `.db` file in a notebooks folder at the root of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e27d88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ede462",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\")\n",
    "llm = OpenAI(temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1e692e",
   "metadata": {},
   "source": [
    "**NOTE:** For data-sensitive projects, you can specify `return_direct=True` in the `SQLDatabaseChain` initialization to directly return the output of the SQL query without any additional formatting. This prevents the LLM from seeing any contents within the database. Note, however, the LLM still has access to the database scheme (i.e. dialect, table and key names) by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff81df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "db_chain.run(\"How many employees are there?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf8a5248",
   "metadata": {},
   "source": [
    "## Use Query Checker\n",
    "Sometimes the Language Model generates invalid SQL with small mistakes that can be self-corrected using the same technique used by the SQL Database Agent to try and fix the SQL using the LLM. You can simply specify this option when creating the chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e395db",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True, use_query_checker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"List all the albums by Aerosmith?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2cba6",
   "metadata": {},
   "source": [
    "## Customize Prompt\n",
    "You can also customize the prompt that is used. Here is an example prompting it to understand that foobar is the same as the Employee table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_DEFAULT_TEMPLATE = \"\"\"Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "Use the following format:\n",
    "\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Final answer here\"\n",
    "\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}\n",
    "\n",
    "If someone asks for the table foobar, they really mean the employee table.\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"dialect\"], template=_DEFAULT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, prompt=PROMPT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"How many employees are there in the foobar table?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d8b969",
   "metadata": {},
   "source": [
    "## Return Intermediate Steps\n",
    "\n",
    "You can also return the intermediate steps of the SQLDatabaseChain. This allows you to access the SQL statement that was generated, as well as the result of running that against the SQL Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38559487",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, prompt=PROMPT, verbose=True, use_query_checker=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b6af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = db_chain(\"How many employees are there in the foobar table?\")\n",
    "result[\"intermediate_steps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408f800",
   "metadata": {},
   "source": [
    "## Choosing how to limit the number of rows returned\n",
    "If you are querying for several rows of a table you can select the maximum number of results you want to get by using the 'top_k' parameter (default is 10). This is useful for avoiding query results that exceed the prompt max length or consume tokens unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adaa799",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True, use_query_checker=True, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"What are some example tracks by composer Johann Sebastian Bach?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5e936",
   "metadata": {},
   "source": [
    "## Adding example rows from each table\n",
    "Sometimes, the format of the data is not obvious and it is optimal to include a sample of rows from the tables in the prompt to allow the LLM to understand the data before providing a final query. Here we will use this feature to let the LLM know that artists are saved with their full names by providing two rows from the `Track` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\n",
    "    \"sqlite:///../../../../notebooks/Chinook.db\",\n",
    "    include_tables=['Track'], # we include only one table to save tokens in the prompt :)\n",
    "    sample_rows_in_table_info=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c0b4d",
   "metadata": {},
   "source": [
    "The sample rows are added to the prompt after each corresponding table's column information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de86267",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, use_query_checker=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e05d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"What are some example tracks by Bach?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94e948",
   "metadata": {},
   "source": [
    "### Custom Table Info\n",
    "In some cases, it can be useful to provide custom table information instead of using the automatically generated table definitions and the first `sample_rows_in_table_info` sample rows. For example, if you know that the first few rows of a table are uninformative, it could help to manually provide example rows that are more diverse or provide more information to the model. It is also possible to limit the columns that will be visible to the model if there are unnecessary columns. \n",
    "\n",
    "This information can be provided as a dictionary with table names as the keys and table information as the values. For example, let's provide a custom definition and sample rows for the Track table with only a few columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad33ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_table_info = {\n",
    "    \"Track\": \"\"\"CREATE TABLE Track (\n",
    "\t\"TrackId\" INTEGER NOT NULL, \n",
    "\t\"Name\" NVARCHAR(200) NOT NULL,\n",
    "\t\"Composer\" NVARCHAR(220),\n",
    "\tPRIMARY KEY (\"TrackId\")\n",
    ")\n",
    "/*\n",
    "3 rows from Track table:\n",
    "TrackId\tName\tComposer\n",
    "1\tFor Those About To Rock (We Salute You)\tAngus Young, Malcolm Young, Brian Johnson\n",
    "2\tBalls to the Wall\tNone\n",
    "3\tMy favorite song ever\tThe coolest composer of all time\n",
    "*/\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db144352",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\n",
    "    \"sqlite:///../../../../notebooks/Chinook.db\",\n",
    "    include_tables=['Track', 'Playlist'],\n",
    "    sample_rows_in_table_info=2,\n",
    "    custom_table_info=custom_table_info)\n",
    "\n",
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6f507",
   "metadata": {},
   "source": [
    "Note how our custom table definition and sample rows for `Track` overrides the `sample_rows_in_table_info` parameter. Tables that are not overridden by `custom_table_info`, in this example `Playlist`, will have their table info gathered automatically as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbda4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n",
    "db_chain.run(\"What are some example tracks by Bach?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ae15a",
   "metadata": {},
   "source": [
    "## SQLDatabaseSequentialChain\n",
    "\n",
    "Chain for querying SQL database that is a sequential chain.\n",
    "\n",
    "The chain is as follows:\n",
    "\n",
    "    1. Based on the query, determine which tables to use.\n",
    "    2. Based on those tables, call the normal SQL database chain.\n",
    "\n",
    "This is useful in cases where the number of tables in the database is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SQLDatabaseSequentialChain\n",
    "db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SQLDatabaseSequentialChain.from_llm(llm, db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95017b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"How many employees are also customers?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eb39db6",
   "metadata": {},
   "source": [
    "## Using Local Language Models\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ab11cb9",
   "metadata": {},
   "source": [
    "Sometimes you may not have the luxury of using OpenAI or other service-hosted large language model. You can, ofcourse, try to use the `SQLDatabaseChain` with a local model, but will quickly realize that most models you can run locally even with a large GPU struggle to generate the right output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "# Note: This is a relatively small (750m param) model and cannot be expected to generate few shot SQL, however you do need a decent GPU to run it locally\n",
    "# https://huggingface.co/juierror/flan-t5-text2sql-with-schema\n",
    "local_llm = HuggingFacePipeline.from_model_id(model_id=\"juierror/flan-t5-text2sql-with-schema\", task=\"text2text-generation\", model_kwargs={\"temperature\":0, \"max_length\":1024}, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import SQLDatabase, SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///../../../../notebooks/Chinook.db\", include_tables=['Artist', 'Genre'])\n",
    "local_chain = SQLDatabaseChain(llm=local_llm, database=db, verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1633c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many artists are there?\"\n",
    "try:\n",
    "    result = local_chain(query)\n",
    "    print(result)\n",
    "except Exception as exc:\n",
    "    # The model will most likely fail to generate SQL, but you can log its inputs\n",
    "    # and outputs so that you can hand-correct them and use for few shot prompt\n",
    "    # examples later.\n",
    "    example = {}\n",
    "    for step in exc.intermediate_steps:\n",
    "        if isinstance(step, dict):\n",
    "            for key in step:\n",
    "                if key == \"input\":\n",
    "                    example[key] = query  # use the original query since the llm adds a suffix\n",
    "                elif key == \"table_info\":\n",
    "                    example[key] = step[key]\n",
    "        else:\n",
    "            example[\"sql_cmd\"] = step\n",
    "\n",
    "    # print for now, in reality you may want to write this out to a YAML or database for manual fixups offline\n",
    "    for key in example:\n",
    "        print(key + \":\")\n",
    "        print(example[key])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da618de6",
   "metadata": {},
   "source": [
    "Run the snippet above a few times, or log exceptions in your deployed environment, to collect lots of examples of inputs, table_info and sql_cmd generated by your language model. The sql_cmd values will be incorrect (since they generated an exception) and you can manually fix them up to build a collection of examples, e.g. here we are using YAML to keep a neat record of our inputs and corrected SQL output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run pip install pyyaml chromadb\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_EXAMPLES = \"\"\"\n",
    "- input: How many artists are there?\n",
    "  table_info: |\n",
    "    CREATE TABLE \"Artist\" (\n",
    "        \"ArtistId\" INTEGER NOT NULL, \n",
    "        \"Name\" NVARCHAR(120), \n",
    "        PRIMARY KEY (\"ArtistId\")\n",
    "    )\n",
    "\n",
    "    /*\n",
    "    3 rows from Artist table:\n",
    "    ArtistId\tName\n",
    "    1\tAC/DC\n",
    "    2\tAccept\n",
    "    3\tAerosmith\n",
    "    */\n",
    "  sql_cmd: SELECT COUNT * FROM \"Artist\";\n",
    "- input: list all the genres\n",
    "  table_info: |\n",
    "    CREATE TABLE \"Genre\" (\n",
    "      \"GenreId\" INTEGER NOT NULL, \n",
    "      \"Name\" NVARCHAR(120), \n",
    "      PRIMARY KEY (\"GenreId\")\n",
    "    )\n",
    "\n",
    "    /*\n",
    "    3 rows from Genre table:\n",
    "    GenreId\tName\n",
    "    1\tRock\n",
    "    2\tJazz\n",
    "    3\tMetal\n",
    "    */\n",
    "  sql_cmd: SELECT * from \"Genre\";\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b13b4d5",
   "metadata": {},
   "source": [
    "Now that you have some examples (with manually corrected output SQL), you can do few shot prompt seeding the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d174f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.chains.sql_database.prompt import _mysql_prompt, PROMPT_SUFFIX\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts.example_selector.semantic_similarity import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"table_info\", \"input\", \"sql_cmd\"],\n",
    "    template=\"{table_info}\\n\\nQuestion: {input}\\nSQLQuery: {sql_cmd}\",\n",
    ")\n",
    "\n",
    "examples_dict = yaml.safe_load(YAML_EXAMPLES)\n",
    "\n",
    "local_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "                        # This is the list of examples available to select from.\n",
    "                        examples_dict,\n",
    "                        # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "                        local_embeddings,\n",
    "                        # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "                        Chroma,  # type: ignore\n",
    "                        # This is the number of examples to produce and include per prompt\n",
    "                        k=min(3, len(examples_dict)),\n",
    "                    )\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=_mysql_prompt + \"Here are some examples:\",\n",
    "    suffix=PROMPT_SUFFIX,\n",
    "    input_variables=[\"table_info\", \"input\", \"top_k\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2324e41f",
   "metadata": {},
   "source": [
    "The model should do better now, especially for inputs similar to the examples you have seeded it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcf76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_chain = SQLDatabaseChain(llm=local_llm, database=db, prompt=few_shot_prompt, use_query_checker=True, verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = local_chain(\"List all the artists\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
