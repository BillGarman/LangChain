{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ad998d",
   "metadata": {},
   "source": [
    "# Multihop Task Execution with OpenAPI\n",
    "\n",
    "Using robust OpenAPI Chain primitives, LLM Chains can efficiently plan and combine calls across multiple endpoints. This notebook demonstrates a sample composition of Speak and Klarna APIs.\n",
    "\n",
    "For a detailed walkthrough, see the [OpenAPI Operation Chain](openapi.ipynb) notebook.\n",
    "\n",
    "### First, import dependencies and load the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6593f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, OpenAPIEndpointChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.requests import Requests\n",
    "from langchain.tools import APIOperation, OpenAPISpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd720860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the LLM to use. Here, we use text-davinci-003\n",
    "llm = OpenAI(temperature=0, max_tokens=700) # You can swap between different core LLM's here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadac9d",
   "metadata": {},
   "source": [
    "### Next, load the OpenAPI specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b208ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    }
   ],
   "source": [
    "speak_spec = OpenAPISpec.from_url(\"https://api.speak.com/openapi.yaml\")\n",
    "klarna_spec = OpenAPISpec.from_url(\"https://www.klarna.com/us/shopping/public/openai/v0/api-docs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b99ae1",
   "metadata": {},
   "source": [
    "### Create the OpenAPIEndpointChain\n",
    "\n",
    "Create an OpenAPIEndpointChain for each of the API's HTTP methods. For larger OpenAPI specs, you may find it easier to select a subset of the operations that work well together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46ffd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# Headers can be passed in for user authentication to the endpoint.\n",
    "def make_chains(spec, headers: Optional[dict] = None) -> list:\n",
    "    \"\"\"Create a chain for each endpoint in the OpenAPI spec.\"\"\"\n",
    "    operation_chains = []\n",
    "    for path in spec.paths:\n",
    "        for method in spec.get_methods_for_path(path):\n",
    "            api_operation = APIOperation.from_openapi_spec(spec, path, method)\n",
    "            chain = OpenAPIEndpointChain.from_api_operation(\n",
    "                api_operation, \n",
    "                llm, \n",
    "                requests=Requests(headers=headers), \n",
    "                verbose=False,\n",
    "                return_intermediate_steps=True # Return request and response text\n",
    "            )\n",
    "            operation_chains.append(chain)\n",
    "    return operation_chains\n",
    "klarna_llm_chains = make_chains(klarna_spec)\n",
    "speak_llm_chains = make_chains(speak_spec)\n",
    "llm_chains = klarna_llm_chains + speak_llm_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7336f",
   "metadata": {},
   "source": [
    "### Create the Planner Chain\n",
    "\n",
    "This chain generates a single plan based on the user's query that will be executed by the selected tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a979c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the APIs into a simple list\n",
    "apis_format = \"\\n\".join([\n",
    "    f\" - {chain.api_operation.operation_id}: {chain.api_operation.description}\" for chain in llm_chains\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "794380ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_template = \"\"\"You are trying to answer the following question by querying one more more API's then communicating the answer:\n",
    "\n",
    "> Question: {question}\n",
    "\n",
    "You have access to the following helpers who can interact with APIs.\n",
    "\n",
    "{apis}\n",
    "\n",
    "Think how to best use the helpers, then select which helpers you want to ask for assistance and in what order. Use the following format:\n",
    "\n",
    "Thoughts: <Think about why the plan (and its order) is the best.\n",
    "Be detailed.\n",
    ">\n",
    "\n",
    "Plan:\n",
    "1. HELPER_NAME: <Instructions relating what you want the helper to assist with, why your asking, and how to summarize the information in natural language.>\n",
    "2. HELPER_NAME: ...\n",
    "...\n",
    "\n",
    "BEGIN:\n",
    "(remember to think step by step)\n",
    "Thoughts:\"\"\"\n",
    "\n",
    "verbose = False\n",
    "prompt = PromptTemplate.from_template(plan_template)\n",
    "planner_chain = LLMChain(llm=llm, prompt=prompt, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699de703",
   "metadata": {},
   "source": [
    "### Fetch the user query and generate a plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5355ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I have an end of year party for my Italian class and have to buy some Italian clothes for it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d26733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_plan = planner_chain.run(question=user_input, apis=apis_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a490e",
   "metadata": {},
   "source": [
    "### Parse the plan into constituent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "194e2486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('productsUsingGET',\n",
       "  'Find Italian clothing that I can buy for the end of year party.'),\n",
       " ('translate', 'Translate the phrase \"end of year party\" into Italian.'),\n",
       " ('explainPhrase',\n",
       "  'Explain the meaning of the phrase \"end of year party\" in Italian.'),\n",
       " ('explainTask',\n",
       "  'Explain the best way to say or do something in the specific situation of buying Italian clothes for the end of year party.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "plan = raw_plan.split('Plan:')[1].strip()\n",
    "parsed_plan = list(re.findall(\"^\\d+\\.\\s*(.*)\", plan, re.MULTILINE))\n",
    "actions_and_inputs = [tuple(step.split(': ', 1)) for step in parsed_plan]\n",
    "actions_and_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6179a76e",
   "metadata": {},
   "source": [
    "### Execute the steps\n",
    "\n",
    "Since this chain creates stepwise dependencies, we execute sequentially. You can also prompt the planner to make parallel plans and use the MapReduceChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6431cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Helper 0 said: \"I found several Italian clothing items that you can buy for the end of year party. Check out the following products: OH LÀ LÀ CHÉRI A Lace In Your Heart Bralette Set - Italian Plum/Black, OH LÀ LÀ CHÉRI Valentine Soft Cup Babydoll Chemise & G-String Thong - Italian Plum, Cole Haan Men's Wool-Blend Italian Topcoat, Hugo Boss Men's Slim-Fit Italian Virgin Wool Sport Coat, Billion aire Italian Couture Cotton Hooded Sweatsuit gray, eberjey Short Organic Cotton Pajama Set Italian Rose, Aubade Womens Danse Des Sens Italian Brief, OH LÀ LÀ CHÉRI Thea Lace Trim Satin Wrap - Italian Plum/Black, Alé Colour Block Short Sleeve Jersey Men - Italian Blue, and Boss Italian-Leather Belt with Branded Metal Trim - Brown.\"\n",
      "- Helper 1 said: \"ERROR parsing response.\"\n",
      "- Helper 2 said: \"I attempted to call an API, but there was an error parsing the response. Please try again later.\"\n",
      "- Helper 3 said: \"In Italy, fashion is a very important part of life, so you can definitely use this as an excuse to buy some Italian clothes or accessories and show them off at your next end-of-year celebration! You can say something like 'Vorrei comprare dei vestiti italiani per la nostra festa di fine anno.' for a polite and formal tone, or 'Mi servono degli abiti alla moda italiana da sfoggiare alla festa.' for a stylish and casual tone, or 'Dobbiamo fare shopping e trovare qualcosa di figo per la nostra celebrazione!' for a very informal and slangy tone.\"\n"
     ]
    }
   ],
   "source": [
    "# Facilitate easy lookup by operation ID\n",
    "apis_dict = {\n",
    "    chain.api_operation.operation_id: chain for chain in llm_chains\n",
    "}\n",
    "\n",
    "# The intermediate steps also contain nested information if you want to further\n",
    "# inspect the delegated tasks.\n",
    "intermediate_steps = []\n",
    "for action, action_input in actions_and_inputs:\n",
    "    if intermediate_steps:\n",
    "        prev_output = intermediate_steps[-1][\"output\"]\n",
    "        action_input = f\"{action_input}\\n\\n Information from the previous step: {prev_output}\"\n",
    "    intermediate_steps.append(apis_dict[action]({\"instructions\": action_input}))\n",
    "\n",
    "# Format the output of each step\n",
    "step_outputs = \"\\n\".join([\n",
    "    f\"- Helper {i} said: \\\"{step['output']}\\\"\" \n",
    "    for i, step \n",
    "    in enumerate(intermediate_steps)\n",
    "])\n",
    "print(step_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42793a93",
   "metadata": {},
   "source": [
    "### Synthesize a final response\n",
    "\n",
    "Use the collected information to synthesize a response to the original user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c84128",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer_template = \"\"\"Please answer the user's question as best as you are able using the gathered information.\n",
    "\n",
    "Fetched information\n",
    "---\n",
    "\n",
    "{step_outputs}\n",
    "\n",
    "Original Question\n",
    "----\n",
    "> User: {question} - Share relevant information where appropriate! I haven't read anything above.\n",
    "\n",
    "RESPONSE\n",
    "----\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(synthesizer_template)\n",
    "response_synthesizer = LLMChain(llm=llm, prompt=prompt, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "661eaa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It sounds like you're looking for some Italian clothing items for your end of year party! Helper 0 has provided a list of Italian clothing items that you can buy, such as OH LÀ LÀ CHÉRI A Lace In Your Heart Bralette Set - Italian Plum/Black, Cole Haan Men's Wool-Blend Italian Topcoat, and Hugo Boss Men's Slim-Fit Italian Virgin Wool Sport Coat. Additionally, Helper 3 has provided some useful phrases in Italian that you can use when shopping for Italian clothes, such as 'Vorrei comprare dei vestiti italiani per la nostra festa di fine anno.' for a polite and formal tone, or 'Mi servono degli abiti alla moda italiana da sfoggiare alla festa.' for a stylish and casual tone.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the result a user would see for their original query\n",
    "response_synthesizer.run(question=user_input, step_outputs=step_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d92a8",
   "metadata": {},
   "source": [
    "### Adding more endpoints\n",
    "\n",
    "You may think \"these sound a lot like Agent tools.\" And you'd be right! Let's add more endpoints and mix with other tools to form a more complex chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca9dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.tools import Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d132cc",
   "metadata": {},
   "source": [
    "Adding the Spoonacular endpoints.\n",
    "\n",
    "1. Go to the [Spoonacular API Console](https://spoonacular.com/food-api/console#Dashboard) and make a free account.\n",
    "2. Click on `Profile` and copy your API key below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2368b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n"
     ]
    }
   ],
   "source": [
    "spoonacular_spec = OpenAPISpec.from_url(\"https://spoonacular.com/application/frontend/downloads/spoonacular-openapi-3.json\")\n",
    "spoonacular_api_key = \"\" # Copy from the API Console\n",
    "spoonacular_llm_chains = make_chains(\n",
    "    spoonacular_spec,\n",
    "    headers={\"x-api-key\": spoonacular_api_key}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea3e6d",
   "metadata": {},
   "source": [
    "### Wrap Endpoints as Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a6edac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chain_to_tool(chain: OpenAPIEndpointChain, domain_title: str) -> Tool:\n",
    "    expanded_name = f'{domain_title.replace(\" \", \"_\")}.{chain.api_operation.operation_id}'\n",
    "    return Tool(\n",
    "        name=expanded_name,\n",
    "        func=chain,\n",
    "        description=chain.api_operation.description\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8467010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 103 endpoint tools\n"
     ]
    }
   ],
   "source": [
    "klarna_tools = [chain_to_tool(chain, klarna_spec.info.title) for chain in klarna_llm_chains]\n",
    "speak_tools = [chain_to_tool(chain, speak_spec.info.title) for chain in speak_llm_chains]\n",
    "spoonacular_tools = [chain_to_tool(chain, spoonacular_spec.info.title) for chain in spoonacular_llm_chains]\n",
    "all_tools = klarna_tools + speak_tools + spoonacular_tools\n",
    "print(f\"Loaded {len(all_tools)} endpoint tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0385e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the query more complex!\n",
    "user_input = (\n",
    "    \"I'm learing Italian, and my language class is having an end of year party... \"\n",
    "    \" Could you help me find an Italian outfit to wear and\"\n",
    "    \" an appropriate recipe to prepare so I can present for the class in Italian?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0214d8",
   "metadata": {},
   "source": [
    "### Generate a plan\n",
    "\n",
    "Use the planner_chain to decide which tools to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a3571e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Open_AI_Klarna_product_Api.productsUsingGET',\n",
       "  'Search for Italian-style clothing.'),\n",
       " ('spoonacular_API.searchRecipes', 'Search for Italian recipes.'),\n",
       " ('spoonacular_API.getRecipeInformation',\n",
       "  'Get detailed information about the recipe, such as ingredients, nutrition, diet and allergen information.'),\n",
       " ('Speak.translate', 'Translate the recipe instructions into Italian.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_list = \"\\n\".join([f\" - {tool.name}: {tool.description}\" for tool in all_tools])\n",
    "\n",
    "# We'll re-use the user question from above. Let's see what the Planning chain cooks up!\n",
    "raw_plan = planner_chain.run(question=user_input, apis=tools_list)\n",
    "\n",
    "# Re-use the simple parsing from above\n",
    "plan = raw_plan.split('Plan:')[1].strip()\n",
    "parsed_plan = list(re.findall(\"^\\d+\\.\\s*(.*)\", plan, re.MULTILINE))\n",
    "actions_and_inputs = [tuple(step.split(': ', 1)) for step in parsed_plan]\n",
    "actions_and_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455eee77",
   "metadata": {},
   "source": [
    "### Run the selected tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2906d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_dict = {tool.name: tool for tool in all_tools}\n",
    "\n",
    "# The intermediate steps also contain nested information if you want to further\n",
    "# inspect the delegated tasks.\n",
    "intermediate_steps = []\n",
    "for action, tool_input in actions_and_inputs:\n",
    "    if intermediate_steps:\n",
    "        prev_output = intermediate_steps[-1][\"output\"]\n",
    "        # In non-sequential plan, we would parse what information to pass to the selected tool\n",
    "        tool_input = f\"{action_input}\\n\\n Information from the previous step: {prev_output}\"\n",
    "    intermediate_steps.append(tools_dict[action](tool_input))\n",
    "\n",
    "# Format the output of each step\n",
    "step_outputs = \"\\n\".join([\n",
    "    f\"- {step['output']}\" \n",
    "    for step \n",
    "    in intermediate_steps\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96caae",
   "metadata": {},
   "source": [
    "### Synthesize the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3566bb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ciao! Per trovare un outfit alla moda italiana per la tua festa di fine anno, ti consigliamo di dare un'occhiata ai prodotti che abbiamo trovato nella nostra API: OH LÀ LÀ CHÉRI A Lace In Your Heart Bralette Set - Italian Plum/Black, Design Toscano Portare Acqua Italian-Style Stone Bonded Sculptural Fountain, e Levi's 501 Original Style Shrink-to-fit Jeans. Per trovare una ricetta appropriata, potresti provare a cercare frasi come: 'Voglio preparare una ricetta italiana per la festa di fine anno', 'Quali sono le ricette più popolari in Italia?' o 'Ho bisogno di una ricetta italiana per questa occasione importante.' Speriamo che questo ti aiuti!\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_synthesizer.run(question=user_input, step_outputs=step_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fcda5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goditi il pasto!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_dict['Speak.translate'].run(\"Tell the LangChain audience to 'enjoy the meal' in Italian, please!\")['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed706d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
