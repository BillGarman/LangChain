{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ad998d",
   "metadata": {},
   "source": [
    "# Multihop Task Execution with OpenAPI\n",
    "\n",
    "Using robust OpenAPI Chain primitives, LLM Chains can efficiently plan and combine calls across multiple endpoints. This notebook demonstrates a sample composition of Speak and Klarna APIs.\n",
    "\n",
    "For a detailed walkthrough, see the [OpenAPI Operation Chain](openapi.ipynb) notebook.\n",
    "\n",
    "### First, import dependencies and load the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6593f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain.chains import LLMChain, OpenAPIEndpointChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.requests import Requests\n",
    "from langchain.tools import APIOperation, OpenAPISpec\n",
    "from langchain.agents import AgentType, Tool, initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd720860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the LLM to use. Here, we use text-davinci-003\n",
    "llm = OpenAI(temperature=0, max_tokens=700) # You can swap between different core LLM's here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadac9d",
   "metadata": {},
   "source": [
    "### Next, load the OpenAPI specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b208ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
      "Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    }
   ],
   "source": [
    "speak_spec = OpenAPISpec.from_url(\"https://api.speak.com/openapi.yaml\")\n",
    "klarna_spec = OpenAPISpec.from_url(\"https://www.klarna.com/us/shopping/public/openai/v0/api-docs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b99ae1",
   "metadata": {},
   "source": [
    "### Create the OpenAPIEndpoint Tools\n",
    "\n",
    "Create an OpenAPIEndpointChain for each of the API's HTTP methods. For larger OpenAPI specs, you may find it easier to select a subset of the operations that work well together. Then we can package these chains up as tools to pass to a conversational agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46ffd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_to_tool(chain: OpenAPIEndpointChain, domain_title: str) -> Tool:\n",
    "    \"\"\"Convert an endpoint chain to a tool.\"\"\"\n",
    "    expanded_name = f'{domain_title.replace(\" \", \"_\")}.{chain.api_operation.operation_id}'\n",
    "    return Tool(\n",
    "        name=expanded_name,\n",
    "        func=chain,\n",
    "        description=chain.api_operation.description\n",
    "    )\n",
    "\n",
    "# Headers can be passed in for user authentication to the endpoint.\n",
    "def make_endpoint_tools(spec: OpenAPISpec, headers: Optional[dict] = None) -> List[Tool]:\n",
    "    \"\"\"Create a chain for each endpoint in the OpenAPI spec.\"\"\"\n",
    "    http_operation_tools = []\n",
    "    for path in spec.paths:\n",
    "        for method in spec.get_methods_for_path(path):\n",
    "            api_operation = APIOperation.from_openapi_spec(spec, path, method)\n",
    "            chain = OpenAPIEndpointChain.from_api_operation(\n",
    "                api_operation, \n",
    "                llm, \n",
    "                requests=Requests(headers=headers), \n",
    "                verbose=False,\n",
    "                return_intermediate_steps=False,\n",
    "                max_text_length=2000 # Truncate large request responses\n",
    "            )\n",
    "            endpoint_tool = chain_to_tool(chain, spec.info.title)\n",
    "            http_operation_tools.append(endpoint_tool)\n",
    "    return http_operation_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad372b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "klarna_tools = make_endpoint_tools(klarna_spec)\n",
    "speak_tools = make_endpoint_tools(speak_spec)\n",
    "open_api_tools = klarna_tools + speak_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7336f",
   "metadata": {},
   "source": [
    "### Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db7384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly tweak the action input from the default instructions to pass more context to the endpoints\n",
    "openapi_format_instructions = \"\"\"Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: fully specify what the action should do or answer\n",
    "Observation: The tool's reply\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a979c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrkl = initialize_agent(open_api_tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                        verbose=True, format_instructions=openapi_format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "794380ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what Italian clothes are available\n",
      "Action: Open_AI_Klarna_product_Api.productsUsingGET\n",
      "Action Input: Italian clothes\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'instructions': 'Italian clothes', 'output': 'We have two Italian-style clothing items available: Alé Colour Block Short Sleeve Jersey Men - Italian Blue and Alé Dolid Flash Jersey Men - Italian Blue. Both are available for purchase on our website.'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know what Italian clothes are available\n",
      "Final Answer: We have two Italian-style clothing items available: Alé Colour Block Short Sleeve Jersey Men - Italian Blue and Alé Dolid Flash Jersey Men - Italian Blue. Both are available for purchase on our website.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We have two Italian-style clothing items available: Alé Colour Block Short Sleeve Jersey Men - Italian Blue and Alé Dolid Flash Jersey Men - Italian Blue. Both are available for purchase on our website.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.run(\"I have an end of year party for my Italian class and have to buy some Italian clothes for it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d92a8",
   "metadata": {},
   "source": [
    "### Adding more Endpoints\n",
    "\n",
    "Since each OpenAPIEndpoint tool exposes a natural language interface, the conversational agent has an easier job planning each step. Let's add another API to the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d132cc",
   "metadata": {},
   "source": [
    "Adding the Spoonacular endpoints.\n",
    "\n",
    "1. Go to the [Spoonacular API Console](https://spoonacular.com/food-api/console#Profile) and make a free account.\n",
    "2. Click on `Profile` and copy your API key below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2368b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    }
   ],
   "source": [
    "spoonacular_spec = OpenAPISpec.from_url(\"https://spoonacular.com/application/frontend/downloads/spoonacular-openapi-3.json\")\n",
    "spoonacular_api_key = \"\" # Copy from the API Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a6edac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Accept. Valid values are ['path', 'query'] Ignoring optional parameter\n",
      "Unsupported APIPropertyLocation \"header\" for parameter Content-Type. Valid values are ['path', 'query'] Ignoring optional parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 tools loaded.\n"
     ]
    }
   ],
   "source": [
    "spoonacular_tools = make_endpoint_tools(spoonacular_spec, headers={\"x-api-key\": spoonacular_api_key})\n",
    "open_api_tools = klarna_tools + speak_tools + spoonacular_tools\n",
    "print(f\"{len(open_api_tools)} tools loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0385e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the query more complex!\n",
    "user_input = (\n",
    "    \"I'm learning Italian, and my language class is having an end of year party... \"\n",
    "    \" Could you help me find an Italian outfit to wear and\"\n",
    "    \" an appropriate recipe to prepare so I can present for the class in Italian?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ebd3f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find a product and a recipe in Italian.\n",
      "Action: Open_AI_Klarna_product_Api.productsUsingGET\n",
      "Action Input: Italian outfit\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'instructions': 'Italian outfit', 'output': 'We have several Italian-style products available, including the Italian Gold Sparkle Perfectina Necklace - Gold, Italian Gold Claddagh Ring - Gold, and Italian Gold Herringbone Necklace - Gold. Please click on the links to view more information about each product.'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find a recipe in Italian.\n",
      "Action: Speak.translate\n",
      "Action Input: Italian recipe\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'instructions': 'Italian recipe', 'output': \"You can try making an Italian dish using a recipe for Italian cuisine, or you can try cooking Italian dishes without a recipe. You can also say 'Cuciniamo all'italiana!' which means 'Let's cook like the Italians do!'\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: You can find an Italian outfit to wear by using Open_AI_Klarna_product_Api.productsUsingGET and you can find an appropriate recipe to prepare by using Speak.translate.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You can find an Italian outfit to wear by using Open_AI_Klarna_product_Api.productsUsingGET and you can find an appropriate recipe to prepare by using Speak.translate.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.run(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2959462",
   "metadata": {},
   "source": [
    "## Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcda5f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mangia bene!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_api_tools[1].run(\"Tell the LangChain audience to 'enjoy the meal' in Italian, please!\")['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab366dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
