{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Weights & Biasee Tracking\n",
        "\n",
        "This notebook goes over how to track your LangChain experiments into one centralized dashboard. To learn more about prompt engineering and the callback please refer to this Report which explains both alongside the resultant dashboards you can expect to see.\n",
        "\n",
        "Run in Colab: https://colab.research.google.com/drive/1DXH4beT4HFaRKy_Vm4PoxhXVDRf7Ym8L?usp=sharing\n",
        "\n",
        "View Report: https://wandb.ai/a-sh0ts/langchain_callback_demo/reports/Prompt-Engineering-LLMs-with-LangChain-and-W-B--VmlldzozNjk1NTUw#ðŸ‘‹-how-to-build-a-callback-in-langchain-for-better-prompt-engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvw5vmrkc0p1"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1bSmKd6V2If"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass(\"WANDB_API_KEY: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OPENAI_API_KEY: \")\n",
        "os.environ[\n",
        "    \"SERPAPI_API_KEY\"\n",
        "] = getpass(\"SERPAPI_API_KEY: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WAGnTWpUUnD"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from langchain.callbacks import WandbCallbackHandler, StdOutCallbackHandler\n",
        "from langchain.callbacks.base import CallbackManager\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Callback Handler that logs to Weights and Biases.\n",
        "\n",
        "Parameters:\n",
        "    job_type (str): The type of job.\n",
        "    project (str): The project to log to.\n",
        "    entity (str): The entity to log to.\n",
        "    tags (list): The tags to log.\n",
        "    group (str): The group to log to.\n",
        "    name (str): The name of the run.\n",
        "    notes (str): The notes to log.\n",
        "    visualize (bool): Whether to visualize the run.\n",
        "    complexity_metrics (bool): Whether to log complexity metrics.\n",
        "    stream_logs (bool): Whether to stream callback actions to W&B\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cxBFfZR8d9FC"
      },
      "source": [
        "```\n",
        "Default values for WandbCallbackHandler(...)\n",
        "\n",
        "visualize: bool = False,\n",
        "complexity_metrics: bool = False,\n",
        "stream_logs: bool = False,\n",
        "```\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE: For beta workflows we have made the default analysis based on textstat and the visualizations based on spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAz8weWuUeXF"
      },
      "outputs": [],
      "source": [
        "\"\"\"Main function.\n",
        "\n",
        "This function is used to try the callback handler.\n",
        "Scenarios:\n",
        "1. OpenAI LLM\n",
        "2. Chain with multiple SubChains on multiple generations\n",
        "3. Agent with Tools\n",
        "\"\"\"\n",
        "session_group = datetime.now().strftime(\"%m.%d.%Y_%H.%M.%S\")\n",
        "wandb_callback = WandbCallbackHandler(\n",
        "    job_type=\"inference\",\n",
        "    project=\"langchain_callback_demo\",\n",
        "    group=f\"minimal_{session_group}\",\n",
        "    name=\"llm\",\n",
        "    tags=[\"test\"],\n",
        ")\n",
        "manager = CallbackManager([StdOutCallbackHandler(), wandb_callback])\n",
        "llm = OpenAI(temperature=0, callback_manager=manager, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-65jwrDeK6w"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Defaults for WandbCallbackHandler.flush_tracker(...)\n",
        "\n",
        "reset: bool = True,\n",
        "finish: bool = False,\n",
        "```\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `flush_tracker` function is used to log LangChain sessions to Weights & Biases. It takes in the LangChain module or agent, and logs at minimum the prompts and generations alongside the serialized form of the LangChain module to the specified Weights & Biases project. By default we reset the session as opposed to concluding the session outright."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_VmneyIUyx8"
      },
      "outputs": [],
      "source": [
        "# SCENARIO 1 - LLM\n",
        "llm_result = llm.generate([\"Tell me a joke\", \"Tell me a poem\"] * 3)\n",
        "wandb_callback.flush_tracker(llm, name=\"simple_sequential\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trxslyb1U28Y"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uauQk10SUzF6"
      },
      "outputs": [],
      "source": [
        "# SCENARIO 2 - Chain\n",
        "template = \"\"\"You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
        "Title: {title}\n",
        "Playwright: This is a synopsis for the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callback_manager=manager)\n",
        "\n",
        "template = \"\"\"You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\n",
        "Play Synopsis:\n",
        "{synopsis}\n",
        "Review from a New York Times play critic of the above play:\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"synopsis\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template, callback_manager=manager)\n",
        "\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[synopsis_chain, review_chain], verbose=True, callback_manager=manager\n",
        ")\n",
        "\n",
        "test_prompts = [\n",
        "    {\n",
        "        \"input\": \"documentary about good video games that push the boundary of game design\"\n",
        "    },\n",
        "    {\"input\": \"cocaine bear vs heroin wolf\"},\n",
        "    {\"input\": \"the best in class mlops tooling\"},\n",
        "]\n",
        "overall_chain.apply(test_prompts)\n",
        "wandb_callback.flush_tracker(overall_chain, name=\"agent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jN73xcPVEpI"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, load_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpq4rk6VT9cu"
      },
      "outputs": [],
      "source": [
        "# SCENARIO 3 - Agent with Tools\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, callback_manager=manager)\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    callback_manager=manager,\n",
        "    verbose=True,\n",
        ")\n",
        "agent.run(\n",
        "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
        ")\n",
        "wandb_callback.flush_tracker(agent, reset=False, finish=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
