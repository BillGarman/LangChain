{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec573bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain, SelfAskWithSearchChain, OpenAI, Prompt, LLMChain, SerpAPIChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4baef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "Search: useful for when you need to answer questions about current events. The input to this should be in the form of question.\n",
    "Calculator: useful for when you need to answer questions about math\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of Search/Calculator\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7254b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = Prompt(input_variables=[\"question\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427a255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "llm_math_chain = LLMMathChain(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23baf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "search = SerpAPIChain()\n",
    "\n",
    "self_ask_with_search = SelfAskWithSearchChain(llm=llm, search_chain=search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37da08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is thirty seven raised to the 0.23 power?\"\n",
    "question = \"Who is Kim Kardashian dating?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202b9373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.294491200736535"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37**0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "033b2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nKim Kardashian is currently dating Kanye West.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45753772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 2.294491200736535\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_math_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be591056",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = prompt.format(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20d755c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = llm(p1, stop=[\"\\nObservation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff1ae2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [p for p in o1.split('\\n') if p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59f3f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ps[-1].startswith('Action Input: ')\n",
    "assert ps[-2].startswith('Action: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "acfbebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = ps[-2][len('Action: '):]\n",
    "action_input = ps[-1][len('Action Input: '):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7653287",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = {\"Calculator\": llm_math_chain}[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "698eb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = chain.run(action_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3931534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = question + o1 + f\"\\nObservation: {ca}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17820efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThought: I now know the final answer.\\nFinal Answer: 2.294491200736535'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = prompt.format(question=question1)\n",
    "llm(p2, stop=[\"\\nObservation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8617f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the age of the person Kim Kardashian is dating raised to the 0.23 power?\"\n",
    "#question = \"What is thirty seven raised to the 0.23 power?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82563db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I need to find the age of the person Kim Kardashian is dating\n",
      "Action: Search\n",
      "Action Input: \"Kim Kardashian boyfriend\"\n",
      "Kim Kardashian's boyfriend Pete Davidson has revealed his hopes to one day become a dad, admitting he's 'so excited' to have children.\n",
      " I need to find the age of Pete Davidson\n",
      "Action: Search\n",
      "Action Input: \"Pete Davidson age\"\n",
      "28 years\n",
      " I need to calculate 28 to the 0.23 power\n",
      "Action: Calculator\n",
      "Action Input: 28^0.23\n",
      "Answer: 2.1520202182226886\n",
      "\n",
      " I now know the final answer\n",
      "Final Answer: 2.1520202182226886\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "document = None\n",
    "_input = f\"{question}\\nThought:\"\n",
    "while True:\n",
    "    observation = llm_chain.predict(question=_input, stop=[\"\\nObservation\"])\n",
    "    print(observation)\n",
    "    ps = [p for p in observation.split('\\n') if p]\n",
    "    if ps[-1].startswith(\"Final Answer\"):\n",
    "        break\n",
    "    assert ps[-1].startswith('Action Input: ')\n",
    "    assert ps[-2].startswith('Action: ')\n",
    "    action = ps[-2][len('Action: '):]\n",
    "    action_input = ps[-1][len('Action Input: '):]\n",
    "    chain = {\"Calculator\": llm_math_chain.run, 'Search': SerpAPIChain().search}[action]\n",
    "    ca = chain(action_input)\n",
    "    print(ca)\n",
    "    _input = _input + observation + f\"\\nObservation: {ca}\\nThought:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df04051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is Kim Kardashian dating?\\n\\nThought: I should look up who Kim Kardashian is dating.\\nAction: Search\\nAction Input: Kim Kardashian dating\\nObservation:  Kim Kardashian and Pete Davidson'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f269be93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' are dating.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdb4d3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1520202182226886"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28**.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac561cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
