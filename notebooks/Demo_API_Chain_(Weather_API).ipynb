{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T3ggVFrL0FWE"
      },
      "outputs": [],
      "source": [
        "#!pip install openai\n",
        "#!pip install langchain==0.0.29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_sHMIkD80KIx"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../')\n",
        "\n",
        "from langchain.chains import APIChain\n",
        "from langchain import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ed5VjvT71LT9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Wfns6AhE1BGs"
      },
      "outputs": [],
      "source": [
        "docs = \"\"\"BASE URL: https://api.open-meteo.com/\n",
        "\n",
        "API Documentation\n",
        "The API endpoint /v1/forecast accepts a geographical coordinate, a list of weather variables and responds with a JSON hourly weather forecast for 7 days. Time always starts at 0:00 today and contains 168 hours. All URL parameters are listed below:\n",
        "\n",
        "Parameter\tFormat\tRequired\tDefault\tDescription\n",
        "latitude, longitude\tFloating point\tYes\t\tGeographical WGS84 coordinate of the location\n",
        "hourly\tString array\tNo\t\tA list of weather variables which should be returned. Values can be comma separated, or multiple &hourly= parameter in the URL can be used.\n",
        "daily\tString array\tNo\t\tA list of daily weather variable aggregations which should be returned. Values can be comma separated, or multiple &daily= parameter in the URL can be used. If daily weather variables are specified, parameter timezone is required.\n",
        "current_weather\tBool\tNo\tfalse\tInclude current weather conditions in the JSON output.\n",
        "temperature_unit\tString\tNo\tcelsius\tIf fahrenheit is set, all temperature values are converted to Fahrenheit.\n",
        "windspeed_unit\tString\tNo\tkmh\tOther wind speed speed units: ms, mph and kn\n",
        "precipitation_unit\tString\tNo\tmm\tOther precipitation amount units: inch\n",
        "timeformat\tString\tNo\tiso8601\tIf format unixtime is selected, all time values are returned in UNIX epoch time in seconds. Please note that all timestamp are in GMT+0! For daily values with unix timestamps, please apply utc_offset_seconds again to get the correct date.\n",
        "timezone\tString\tNo\tGMT\tIf timezone is set, all timestamps are returned as local-time and data is returned starting at 00:00 local-time. Any time zone name from the time zone database is supported. If auto is set as a time zone, the coordinates will be automatically resolved to the local time zone.\n",
        "past_days\tInteger (0-2)\tNo\t0\tIf past_days is set, yesterday or the day before yesterday data are also returned.\n",
        "start_date\n",
        "end_date\tString (yyyy-mm-dd)\tNo\t\tThe time interval to get weather data. A day must be specified as an ISO8601 date (e.g. 2022-06-30).\n",
        "models\tString array\tNo\tauto\tManually select one or more weather models. Per default, the best suitable weather models will be combined.\n",
        "\n",
        "Hourly Parameter Definition\n",
        "The parameter &hourly= accepts the following values. Most weather variables are given as an instantaneous value for the indicated hour. Some variables like precipitation are calculated from the preceding hour as an average or sum.\n",
        "\n",
        "Variable\tValid time\tUnit\tDescription\n",
        "temperature_2m\tInstant\t°C (°F)\tAir temperature at 2 meters above ground\n",
        "snowfall\tPreceding hour sum\tcm (inch)\tSnowfall amount of the preceding hour in centimeters. For the water equivalent in millimeter, divide by 7. E.g. 7 cm snow = 10 mm precipitation water equivalent\n",
        "rain\tPreceding hour sum\tmm (inch)\tRain from large scale weather systems of the preceding hour in millimeter\n",
        "showers\tPreceding hour sum\tmm (inch)\tShowers from convective precipitation in millimeters from the preceding hour\n",
        "weathercode\tInstant\tWMO code\tWeather condition as a numeric code. Follow WMO weather interpretation codes. See table below for details.\n",
        "snow_depth\tInstant\tmeters\tSnow depth on the ground\n",
        "freezinglevel_height\tInstant\tmeters\tAltitude above sea level of the 0°C level\n",
        "visibility\tInstant\tmeters\tViewing distance in meters. Influenced by low clouds, humidity and aerosols. Maximum visibility is approximately 24 km.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CNep6xcg1RsR"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "f_HGYkam1T9s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get_request_chain memory=None verbose=False prompt=PromptTemplate(input_variables=['api_docs', 'question'], output_parser=None, template='You are given the below API Documentation:\\n\\n{api_docs}\\n\\nUsing this documentation, generate the full API url to call for answering this question: {question}\\n\\nAPI url: ', template_format='f-string') llm=OpenAI(cache=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, batch_size=20) output_key='text'\n",
            "get_answer_chain memory=None verbose=False prompt=PromptTemplate(input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, template='You are given the below API Documentation:\\n\\n{api_docs}\\n\\nUsing this documentation, generate the full API url to call for answering this question: {question}\\n\\nAPI url:  {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string') llm=OpenAI(cache=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, batch_size=20) output_key='text'\n"
          ]
        }
      ],
      "source": [
        "chain = APIChain.from_llm_and_api_docs(llm, docs, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'memory': None,\n",
              " 'verbose': False,\n",
              " 'prompt': {'input_variables': ['api_docs', 'question'],\n",
              "  'output_parser': None,\n",
              "  'template': 'You are given the below API Documentation:\\n\\n{api_docs}\\n\\nUsing this documentation, generate the full API url to call for answering this question: {question}\\n\\nAPI url: ',\n",
              "  'template_format': 'f-string'},\n",
              " 'llm': {'cache': None,\n",
              "  'client': openai.api_resources.completion.Completion,\n",
              "  'model_name': 'text-davinci-003',\n",
              "  'temperature': 0.0,\n",
              "  'max_tokens': 256,\n",
              "  'top_p': 1,\n",
              "  'frequency_penalty': 0,\n",
              "  'presence_penalty': 0,\n",
              "  'n': 1,\n",
              "  'best_of': 1,\n",
              "  'model_kwargs': {},\n",
              "  'openai_api_key': None,\n",
              "  'batch_size': 20},\n",
              " 'output_key': 'text'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.api_request_chain.dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'memory': None,\n",
              " 'verbose': False,\n",
              " 'prompt': {'input_variables': ['api_docs',\n",
              "   'question',\n",
              "   'api_url',\n",
              "   'api_response'],\n",
              "  'output_parser': None,\n",
              "  'template': 'You are given the below API Documentation:\\n\\n{api_docs}\\n\\nUsing this documentation, generate the full API url to call for answering this question: {question}\\n\\nAPI url:  {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:',\n",
              "  'template_format': 'f-string'},\n",
              " 'llm': {'cache': None,\n",
              "  'client': openai.api_resources.completion.Completion,\n",
              "  'model_name': 'text-davinci-003',\n",
              "  'temperature': 0.0,\n",
              "  'max_tokens': 256,\n",
              "  'top_p': 1,\n",
              "  'frequency_penalty': 0,\n",
              "  'presence_penalty': 0,\n",
              "  'n': 1,\n",
              "  'best_of': 1,\n",
              "  'model_kwargs': {},\n",
              "  'openai_api_key': None,\n",
              "  'batch_size': 20},\n",
              " 'output_key': 'text'}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.api_answer_chain.dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6RT38WIn1ZBC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m https://api.open-meteo.com/v1/forecast?latitude=37.7749&longitude=-122.4194&hourly=snowfall\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m{\"latitude\":37.763283,\"longitude\":-122.41286,\"generationtime_ms\":0.2859830856323242,\"utc_offset_seconds\":0,\"timezone\":\"GMT\",\"timezone_abbreviation\":\"GMT\",\"elevation\":18.0,\"hourly_units\":{\"time\":\"iso8601\",\"snowfall\":\"cm\"},\"hourly\":{\"time\":[\"2022-12-22T00:00\",\"2022-12-22T01:00\",\"2022-12-22T02:00\",\"2022-12-22T03:00\",\"2022-12-22T04:00\",\"2022-12-22T05:00\",\"2022-12-22T06:00\",\"2022-12-22T07:00\",\"2022-12-22T08:00\",\"2022-12-22T09:00\",\"2022-12-22T10:00\",\"2022-12-22T11:00\",\"2022-12-22T12:00\",\"2022-12-22T13:00\",\"2022-12-22T14:00\",\"2022-12-22T15:00\",\"2022-12-22T16:00\",\"2022-12-22T17:00\",\"2022-12-22T18:00\",\"2022-12-22T19:00\",\"2022-12-22T20:00\",\"2022-12-22T21:00\",\"2022-12-22T22:00\",\"2022-12-22T23:00\",\"2022-12-23T00:00\",\"2022-12-23T01:00\",\"2022-12-23T02:00\",\"2022-12-23T03:00\",\"2022-12-23T04:00\",\"2022-12-23T05:00\",\"2022-12-23T06:00\",\"2022-12-23T07:00\",\"2022-12-23T08:00\",\"2022-12-23T09:00\",\"2022-12-23T10:00\",\"2022-12-23T11:00\",\"2022-12-23T12:00\",\"2022-12-23T13:00\",\"2022-12-23T14:00\",\"2022-12-23T15:00\",\"2022-12-23T16:00\",\"2022-12-23T17:00\",\"2022-12-23T18:00\",\"2022-12-23T19:00\",\"2022-12-23T20:00\",\"2022-12-23T21:00\",\"2022-12-23T22:00\",\"2022-12-23T23:00\",\"2022-12-24T00:00\",\"2022-12-24T01:00\",\"2022-12-24T02:00\",\"2022-12-24T03:00\",\"2022-12-24T04:00\",\"2022-12-24T05:00\",\"2022-12-24T06:00\",\"2022-12-24T07:00\",\"2022-12-24T08:00\",\"2022-12-24T09:00\",\"2022-12-24T10:00\",\"2022-12-24T11:00\",\"2022-12-24T12:00\",\"2022-12-24T13:00\",\"2022-12-24T14:00\",\"2022-12-24T15:00\",\"2022-12-24T16:00\",\"2022-12-24T17:00\",\"2022-12-24T18:00\",\"2022-12-24T19:00\",\"2022-12-24T20:00\",\"2022-12-24T21:00\",\"2022-12-24T22:00\",\"2022-12-24T23:00\",\"2022-12-25T00:00\",\"2022-12-25T01:00\",\"2022-12-25T02:00\",\"2022-12-25T03:00\",\"2022-12-25T04:00\",\"2022-12-25T05:00\",\"2022-12-25T06:00\",\"2022-12-25T07:00\",\"2022-12-25T08:00\",\"2022-12-25T09:00\",\"2022-12-25T10:00\",\"2022-12-25T11:00\",\"2022-12-25T12:00\",\"2022-12-25T13:00\",\"2022-12-25T14:00\",\"2022-12-25T15:00\",\"2022-12-25T16:00\",\"2022-12-25T17:00\",\"2022-12-25T18:00\",\"2022-12-25T19:00\",\"2022-12-25T20:00\",\"2022-12-25T21:00\",\"2022-12-25T22:00\",\"2022-12-25T23:00\",\"2022-12-26T00:00\",\"2022-12-26T01:00\",\"2022-12-26T02:00\",\"2022-12-26T03:00\",\"2022-12-26T04:00\",\"2022-12-26T05:00\",\"2022-12-26T06:00\",\"2022-12-26T07:00\",\"2022-12-26T08:00\",\"2022-12-26T09:00\",\"2022-12-26T10:00\",\"2022-12-26T11:00\",\"2022-12-26T12:00\",\"2022-12-26T13:00\",\"2022-12-26T14:00\",\"2022-12-26T15:00\",\"2022-12-26T16:00\",\"2022-12-26T17:00\",\"2022-12-26T18:00\",\"2022-12-26T19:00\",\"2022-12-26T20:00\",\"2022-12-26T21:00\",\"2022-12-26T22:00\",\"2022-12-26T23:00\",\"2022-12-27T00:00\",\"2022-12-27T01:00\",\"2022-12-27T02:00\",\"2022-12-27T03:00\",\"2022-12-27T04:00\",\"2022-12-27T05:00\",\"2022-12-27T06:00\",\"2022-12-27T07:00\",\"2022-12-27T08:00\",\"2022-12-27T09:00\",\"2022-12-27T10:00\",\"2022-12-27T11:00\",\"2022-12-27T12:00\",\"2022-12-27T13:00\",\"2022-12-27T14:00\",\"2022-12-27T15:00\",\"2022-12-27T16:00\",\"2022-12-27T17:00\",\"2022-12-27T18:00\",\"2022-12-27T19:00\",\"2022-12-27T20:00\",\"2022-12-27T21:00\",\"2022-12-27T22:00\",\"2022-12-27T23:00\",\"2022-12-28T00:00\",\"2022-12-28T01:00\",\"2022-12-28T02:00\",\"2022-12-28T03:00\",\"2022-12-28T04:00\",\"2022-12-28T05:00\",\"2022-12-28T06:00\",\"2022-12-28T07:00\",\"2022-12-28T08:00\",\"2022-12-28T09:00\",\"2022-12-28T10:00\",\"2022-12-28T11:00\",\"2022-12-28T12:00\",\"2022-12-28T13:00\",\"2022-12-28T14:00\",\"2022-12-28T15:00\",\"2022-12-28T16:00\",\"2022-12-28T17:00\",\"2022-12-28T18:00\",\"2022-12-28T19:00\",\"2022-12-28T20:00\",\"2022-12-28T21:00\",\"2022-12-28T22:00\",\"2022-12-28T23:00\"],\"snowfall\":[0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00]}}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished APIChain chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' It did not snow in SF today, as the snowfall amount for each hour is 0.00 cm.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(\"How much did it snow in SF today?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXiXlR_C2Jgy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "4dcacae4b209be26253afbad938ed606d8633cbdbf64a21e50a3f0fad9ec4373"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
