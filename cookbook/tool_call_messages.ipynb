{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48812ed-35bd-4fbe-9a2c-6c7335e5645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bagatur/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `bind_tools` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' times 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the 'y'.\"\"\"\n",
    "    return x**y\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "tools = [multiply, exponentiate, add]\n",
    "\n",
    "gpt35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0).bind_tools(tools)\n",
    "claude3 = ChatAnthropic(model=\"claude-3-sonnet-20240229\").bind_tools(tools)\n",
    "llm_with_tools = gpt35.configurable_alternatives(\n",
    "    ConfigurableField(id=\"llm\"), default_key=\"gpt35\", claude3=claude3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4719ebdb-ad50-468e-9b30-fb5fb086e140",
   "metadata": {},
   "source": [
    "# AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98feaa5-8c2d-4125-9519-67114a1fef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolAgentAction\n",
    "from langchain_core.agents import AgentFinish, _convert_agent_action_to_messages\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIToolCallsMessage,\n",
    "    BaseMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def actions_observations_to_messages(\n",
    "    steps: List[Tuple[OpenAIToolAgentAction, str]],\n",
    ") -> List[BaseMessage]:\n",
    "    messages = []\n",
    "    for action, observation in steps:\n",
    "        messages.extend([m for m in action.message_log if m not in messages])\n",
    "        messages.append(ToolMessage(observation, tool_call_id=action.tool_call_id))\n",
    "    return messages\n",
    "\n",
    "\n",
    "def messages_to_action(\n",
    "    msg: AIMessage,\n",
    ") -> Union[List[OpenAIToolAgentAction], AgentFinish]:\n",
    "    if isinstance(msg, AIToolCallsMessage):\n",
    "        actions = []\n",
    "        for tool_call in msg.tool_calls:\n",
    "            actions.append(\n",
    "                OpenAIToolAgentAction(\n",
    "                    tool=tool_call.name,\n",
    "                    tool_input=tool_call.args,\n",
    "                    tool_call_id=tool_call.id,\n",
    "                    message_log=[msg],\n",
    "                    log=\"\",\n",
    "                )\n",
    "            )\n",
    "        return actions\n",
    "    else:\n",
    "        return AgentFinish(return_values={\"output\": msg.content}, log=\"\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You're a helpful assistant with access to tools\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: actions_observations_to_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    )\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | messages_to_action\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c0fc7a-80bb-4bb8-a87b-7388291ae8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[33;1m\u001b[1;3m300.03770462067547\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[38;5;200m\u001b[1;3m-900.8841\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\",\n",
       " 'output': 'The result of \\\\(3 + 5^{2.743}\\\\) is approximately 300.04, and the result of \\\\(17.24 - 918.1241\\\\) is approximately -900.88.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"input\": \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a3a3c8-185d-4861-b6f0-7592668feb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:338: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[38;5;200m\u001b[1;3m8.0\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:338: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[33;1m\u001b[1;3m300.03770462067547\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:338: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[38;5;200m\u001b[1;3m-900.8841\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:338: UserWarning: stream: Tool use is not yet supported in streaming mode.\n",
      "  warnings.warn(\"stream: Tool use is not yet supported in streaming mode.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\",\n",
       " 'output': 'Therefore, 17.24 - 918.1241 = -900.8841'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent.with_config(configurable={\"llm\": \"claude3\"}), tools=tools, verbose=True\n",
    ")\n",
    "agent_executor.invoke(\n",
    "    {\"input\": \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c186263-1b98-4cb2-b6d1-71f65eb0d811",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28fc2c60-7dbc-428a-8983-1a6a15ea30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import AIToolCallsMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    return (\n",
    "        \"continue\" if isinstance(state[\"messages\"][-1], AIToolCallsMessage) else \"end\"\n",
    "    )\n",
    "\n",
    "\n",
    "def call_model(state, config):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"], config=config)]}\n",
    "\n",
    "\n",
    "def _invoke_tool(tool_call):\n",
    "    tool = {tool.name: tool for tool in tools}[tool_call.name]\n",
    "    return ToolMessage(tool.invoke(tool_call.args), tool_call_id=tool_call.id)\n",
    "\n",
    "\n",
    "tool_executor = RunnableLambda(_invoke_tool)\n",
    "\n",
    "\n",
    "def call_tools(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    return {\"messages\": tool_executor.batch(last_message.tool_calls)}\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tools)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24463798-74e6-4c39-8092-7a1524d83225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"),\n",
       "  AIToolCallsMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_LXipeLCqBDSMFv2q9yDhZhvW', 'function': {'arguments': '{\"x\": 8, \"y\": 2.743}', 'name': 'exponentiate'}, 'type': 'function'}, {'id': 'call_Mifo9oH3dyLxzSPTN36MHSCz', 'function': {'arguments': '{\"x\": 17.24, \"y\": -918.1241}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 168, 'total_tokens': 226}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-93882566-f41f-46b1-946d-fc95a6876225-0', tool_calls=[ToolCall(name='exponentiate', args={'x': 8, 'y': 2.743}, id='call_LXipeLCqBDSMFv2q9yDhZhvW'), ToolCall(name='add', args={'x': 17.24, 'y': -918.1241}, id='call_Mifo9oH3dyLxzSPTN36MHSCz')]),\n",
       "  ToolMessage(content='300.03770462067547', tool_call_id='call_LXipeLCqBDSMFv2q9yDhZhvW'),\n",
       "  ToolMessage(content='-900.8841', tool_call_id='call_Mifo9oH3dyLxzSPTN36MHSCz'),\n",
       "  AIMessage(content='The result of \\\\(3 + 5^{2.743}\\\\) is approximately 300.04, and the result of \\\\(17.24 - 918.1241\\\\) is approximately -900.88.', response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 251, 'total_tokens': 295}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-8afa740b-dfb5-4c3b-992c-e0c6dc093d50-0')]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "073c074e-d722-42e0-85ec-c62c079207e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"),\n",
       "  AIToolCallsMessage(content=[{'text': 'Here is how we can calculate those expressions using the available tools:', 'type': 'text'}, {'id': 'toolu_01Qx73e5ksi1TeKg2SMe5rNP', 'input': {'x': 3, 'y': 5}, 'name': 'add', 'type': 'tool_use'}], response_metadata={'id': 'msg_014N9K6533PLQ88Ah5mn5MmG', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 450, 'output_tokens': 82}}, id='run-ca245eb2-6d94-4afb-affc-c3913e748240-0', tool_calls=[ToolCall(name='add', args={'x': 3, 'y': 5}, id='toolu_01Qx73e5ksi1TeKg2SMe5rNP', index=1)]),\n",
       "  ToolMessage(content='8.0', tool_call_id='toolu_01Qx73e5ksi1TeKg2SMe5rNP'),\n",
       "  AIToolCallsMessage(content=[{'id': 'toolu_01JQ6VWLSg7iEoqpTYohrycT', 'input': {'x': 8, 'y': 2.743}, 'name': 'exponentiate', 'type': 'tool_use'}], response_metadata={'id': 'msg_013BEUowXXFDZaVHuWcAread', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 546, 'output_tokens': 73}}, id='run-fddd148e-3f0f-430f-a290-245e9da4645e-0', tool_calls=[ToolCall(name='exponentiate', args={'x': 8, 'y': 2.743}, id='toolu_01JQ6VWLSg7iEoqpTYohrycT', index=0)]),\n",
       "  ToolMessage(content='300.03770462067547', tool_call_id='toolu_01JQ6VWLSg7iEoqpTYohrycT'),\n",
       "  AIToolCallsMessage(content=[{'text': 'So 3 + 5 raised to 2.743 power is 300.04.', 'type': 'text'}, {'id': 'toolu_01G7HVTMbj5wzU5MBjyHbeEG', 'input': {'x': 17.24, 'y': -918.1241}, 'name': 'add', 'type': 'tool_use'}], response_metadata={'id': 'msg_013qrJXC8MCzUSRRfSSCuEk2', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 637, 'output_tokens': 98}}, id='run-6f424e04-6596-4fee-92df-92dcd1e3ac33-0', tool_calls=[ToolCall(name='add', args={'x': 17.24, 'y': -918.1241}, id='toolu_01G7HVTMbj5wzU5MBjyHbeEG', index=1)]),\n",
       "  ToolMessage(content='-900.8841', tool_call_id='toolu_01G7HVTMbj5wzU5MBjyHbeEG'),\n",
       "  AIMessage(content='So 17.24 - 918.1241 is -900.8841.', response_metadata={'id': 'msg_01Ss5MzHPpETbaBi7uxdtkmq', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 751, 'output_tokens': 24}}, id='run-3cc2699c-9b31-4b5b-acce-215ae5d6e51e-0')]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                \"what's 3 plus 5 raised to the 2.743. also what's 17.24 - 918.1241\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config={\"configurable\": {\"llm\": \"claude3\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv-2",
   "language": "python",
   "name": "poetry-venv-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
