{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f970f757-ec76-4bf0-90cd-a2fb68b945e3",
   "metadata": {},
   "source": [
    "# Exploring OpenAI V1 functionality\n",
    "\n",
    "On 11.06.23 OpenAI released a number of new features, and along with it bumped their Python SDK to 1.0.0. This notebook shows off the new features and how to use them with LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee897729-263a-4073-898f-bb4cf01ed829",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"openai>=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e067ce-7a43-47a7-bc89-41f1de4cf136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e7e95-90a1-4f73-98fe-10c4b4e0951b",
   "metadata": {},
   "source": [
    "## [Vision](https://platform.openai.com/docs/guides/vision)\n",
    "\n",
    "OpenAI released multi-modal models, which can take a sequence of text and images as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8c3965-d3c9-4186-b5f3-5e67855ef916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The image appears to be a diagram representing the architecture or components of a software platform named \"LangChain.\" This diagram outlines various layers and elements of the platform, which seems to be related to language processing or computational linguistics, as suggested by the context clues in the names of the components.\\n\\nHere\\'s a breakdown of the components shown:\\n\\n- **LangSmith**: This seems to be a tool or suite related to testing, evaluation, monitoring, feedback, and annotation within the platform.\\n\\n- **LangServe**: This could represent a service layer that exposes the platform\\'s capabilities as REST API endpoints.\\n\\n- **Templates**: These are likely reference applications provided as starting points or examples for users of the platform.\\n\\n- **Chains, agents, agent executors**: This section describes the common application logic, perhaps indicating that the platform uses a chain of agents or processes to execute tasks.\\n\\n- **Model I/O**: This includes the components related to input/output processing for a model, like prompt, example selector, model, and output parser.\\n\\n- **Retrieval**: These components are involved in retrieving documents, splitting text, and managing embeddings and vector stores, which are important for tasks like search and information retrieval.\\n\\n- **Agent tooling**: This might refer to the tools used for creating,')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=256)\n",
    "chat.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"What is this image showing\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://python.langchain.com/assets/images/langchain_stack-da369071b058555da3d491a695651f15.jpg\",\n",
    "                        \"detail\": \"auto\",\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f8248-fcf3-4052-a4a3-0684e08f8785",
   "metadata": {},
   "source": [
    "## [OpenAI assistants](https://platform.openai.com/docs/assistants/overview)\n",
    "\n",
    "> The Assistants API allows you to build AI assistants within your own applications. An Assistant has instructions and can leverage models, tools, and knowledge to respond to user queries. The Assistants API currently supports three types of tools: Code Interpreter, Retrieval, and Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9064bbe-d9f7-4a29-a7b3-73933b3197e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.openai_assistant.base import OpenAIAssistantRunnable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a20a008-49ac-46d2-aa26-b270118af5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ThreadMessage(id='msg_bG50eUX5DhIKSTLKV7EgaHMM', assistant_id='asst_p9qkGkw1FfYEd90HLvPalaox', content=[MessageContentText(text=Text(annotations=[], value='The value of \\\\( 10 - 4^{2.7} \\\\) is approximately -32.224.'), type='text')], created_at=1699379844, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_2cc89e4VYnxBOhPQsR5pgcPE', thread_id='thread_ugmxDTcETSsM52k4NBsRB6tR')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4-1106-preview\"\n",
    ")\n",
    "output = interpreter_assistant.invoke({\"content\": \"What's 10 - 4 raised to the 2.7\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddd181-ac63-4ab6-a40d-a236120379c1",
   "metadata": {},
   "source": [
    "### As a LangChain agent with arbitrary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48681ac7-b267-48d4-972c-8a7df8393a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import E2BDataAnalysisTool\n",
    "\n",
    "tools = [E2BDataAnalysisTool(api_key=\"...\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c01dd79-dd3e-4509-a2e2-009a7f99f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant e2b tool\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=tools,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac71d8b-4b4b-4f98-b826-6b3c57a34166",
   "metadata": {},
   "source": [
    "#### Using AgentExecutor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f137f94-801f-4766-9ff5-2de9df5e8079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"What's 10 - 4 raised to the 2.7\",\n",
       " 'output': 'The result of \\\\( 10 - 4^{2.7} \\\\) is approximately \\\\(-32.224\\\\).'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "agent_executor.invoke({\"content\": \"What's 10 - 4 raised to the 2.7\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a0b1d-c1b3-4b50-9dce-1189b51a6206",
   "metadata": {},
   "source": [
    "#### Custom execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0475fa7-b6c1-4331-b8e2-55407466c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant e2b tool\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    tools=tools,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76cb669-6aba-4827-868f-00aa960026f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2b_data_analysis {'python_code': \"result = 10 - 4**2.7\\nprint('The result of 10 - 4 raised to the 2.7 is:', result)\"} {\"stdout\": \"The result of 10 - 4 raised to the 2.7 is: -32.22425314473263\", \"stderr\": \"\", \"artifacts\": []}\n",
      "\n",
      "return_values={'output': 'The result of \\\\(10 - 4\\\\) raised to the \\\\(2.7\\\\) is approximately \\\\(-32.22425314473263\\\\).'} log='' run_id='run_ORbUDQ9DELkjjPcxP4arCoBA' thread_id='thread_Kaou0OV59KmtQpqR9e49jt8q'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "tool_map = {tool.name: tool for tool in tools}\n",
    "response = agent.invoke({\"content\": \"What's 10 - 4 raised to the 2.7\"})\n",
    "while not isinstance(response, AgentFinish):\n",
    "    tool_outputs = []\n",
    "    for action in response:\n",
    "        tool_output = tool_map[action.tool].invoke(action.tool_input)\n",
    "        print(action.tool, action.tool_input, tool_output, end=\"\\n\\n\")\n",
    "        tool_outputs.append({\"output\": tool_output, \"tool_call_id\": action.tool_call_id})\n",
    "    response = agent.invoke({\"tool_outputs\": tool_outputs, \"run_id\": action.run_id, \"thread_id\": action.thread_id})\n",
    "    \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c34763-d1e7-4b9a-a9d7-3e4cc0dfc2c4",
   "metadata": {},
   "source": [
    "## [JSON mode](https://platform.openai.com/docs/guides/text-generation/json-mode)\n",
    "\n",
    "Constrain the model to only generate valid JSON. Note that you must include a system message with instructions to use JSON for this mode to work.\n",
    "\n",
    "Only works with certain models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6072c4-f3f3-415d-872b-71ea9f3c02bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"companies\": [\n",
      "    {\n",
      "      \"name\": \"Google\",\n",
      "      \"origin\": \"USA\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Deepmind\",\n",
      "      \"origin\": \"UK\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "output = chat.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"Extract the 'name' and 'origin' of any companies mentioned in the following statement. Return a JSON list.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"Google was founded in the USA, while Deepmind was founded in the UK\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e00ccf-b991-4249-846b-9500a0ccbfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'companies': [{'name': 'Google', 'origin': 'USA'},\n",
       "  {'name': 'Deepmind', 'origin': 'UK'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a94d9-4319-4ab7-a979-c475ce6b5f50",
   "metadata": {},
   "source": [
    "## [System fingerprint](https://platform.openai.com/docs/guides/text-generation/reproducible-outputs)\n",
    "\n",
    "OpenAI sometimes changes model configurations in a way that impacts outputs. Whenever this happens, the system_fingerprint associated with a generation will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1281883c-bf8f-4665-89cd-4f33ccde69ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_usage': {'completion_tokens': 43, 'prompt_tokens': 49, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_eeff13170a'}\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "output = chat.generate(\n",
    "    [\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Extract the 'name' and 'origin' of any companies mentioned in the following statement. Return a JSON list.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=\"Google was founded in the USA, while Deepmind was founded in the UK\"\n",
    "            ),\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "print(output.llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c637ba1-322d-4fc9-b97e-3afa83dc4d72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
